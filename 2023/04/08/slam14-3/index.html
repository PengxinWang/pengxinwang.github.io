<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="slam14讲源代码的记录（后九讲）, Ocean">
    <meta name="description" content="记录slam14讲源代码中的一些东西（后九讲）">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>slam14讲源代码的记录（后九讲） | Ocean</title>
    <link rel="icon" type="image/png" href="/favicon.png">
    


    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/css/matery.css">
<link rel="stylesheet" type="text/css" href="/css/my.css">
<link rel="stylesheet" type="text/css" href="/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/css/post.css">




    
        <link rel="stylesheet" type="text/css" href="/css/reward.css">
    



    <script src="/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 6.3.0"></head>


<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Ocean</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>关于</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/contact" class="waves-effect waves-light">
      
      <i class="fas fa-comments" style="zoom: 0.6;"></i>
      
      <span>留言板</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Ocean</div>
        <div class="logo-desc">
            
            要善良,要勇敢,要像星星一样努力发光。若是你心怀旧梦，就别再无疾而终。加油，为实现梦想努力。梦想再遥远，也要笑着走去，毕竟沿途有很多美景等着去欣赏。
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			关于
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/contact" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-comments"></i>
			
			留言板
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/oceanechy" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/oceanechy" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/featureimages/23.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">slam14讲源代码的记录（后九讲）</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/c/">
                                <span class="chip bg-color">c++</span>
                            </a>
                        
                            <a href="/tags/slam/">
                                <span class="chip bg-color">slam</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/slam/" class="post-category">
                                slam
                            </a>
                        
                            <a href="/categories/slam/c/" class="post-category">
                                c++
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2023-04-08
                </div>
                

                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    16.5k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    83 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        
        <!-- 是否加载使用自带的 prismjs. -->
        <link rel="stylesheet" href="/libs/prism/prism.min.css">
        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <h2 id="第六讲"><a href="#第六讲" class="headerlink" title="第六讲"></a>第六讲</h2><p>本讲只要讲解最小二乘法的含义以及处理方式，如高斯牛顿（GN）、列文伯格-马夸尔特法(L-M)等下降法策略</p>
<h3 id="在ch6-x2F-gaussNewton-cpp中，手写GN法，最小二乘估计曲线参数"><a href="#在ch6-x2F-gaussNewton-cpp中，手写GN法，最小二乘估计曲线参数" class="headerlink" title="在ch6&#x2F;gaussNewton.cpp中，手写GN法，最小二乘估计曲线参数"></a>在ch6&#x2F;gaussNewton.cpp中，手写GN法，最小二乘估计曲线参数</h3><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">&#x2F;&#x2F;求解误差项
    for (int i &#x3D; 0; i &lt; N; i++) &#123;
  double xi &#x3D; x_data[i], yi &#x3D; y_data[i];  &#x2F;&#x2F; 第i个数据点
  double error &#x3D; yi - exp(ae * xi * xi + be * xi + ce);
  Vector3d J; &#x2F;&#x2F; 雅可比矩阵
  J[0] &#x3D; -xi * xi * exp(ae * xi * xi + be * xi + ce);  &#x2F;&#x2F; de&#x2F;da
  J[1] &#x3D; -xi * exp(ae * xi * xi + be * xi + ce);  &#x2F;&#x2F; de&#x2F;db
  J[2] &#x3D; -exp(ae * xi * xi + be * xi + ce);  &#x2F;&#x2F; de&#x2F;dc

  H +&#x3D; inv_sigma * inv_sigma * J * J.transpose();
  b +&#x3D; -inv_sigma * inv_sigma * error * J;

  cost +&#x3D; error * error;
&#125;

&#x2F;&#x2F; 求解线性方程 Hx&#x3D;b
&#x2F;&#x2F;对于正定矩阵，可以使用cholesky分解来解方程
Vector3d dx &#x3D; H.ldlt().solve(b);

&#x2F;&#x2F;也可以使用QR分解
Vector3d dx &#x3D; H.colPivHouseholderQr().solve(b);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="ch6-x2F-ceresCurveFitting-cpp"><a href="#ch6-x2F-ceresCurveFitting-cpp" class="headerlink" title="ch6&#x2F;ceresCurveFitting.cpp"></a>ch6&#x2F;ceresCurveFitting.cpp</h3><p>使用ceres拟合曲线</p>
<p><img src="/pic/%E9%80%89%E5%8C%BA_131.png" alt="Ceres简介"></p>
<pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">
&#x2F;&#x2F; 代价函数的计算模型,结构体
struct CURVE_FITTING_COST &#123;
  CURVE_FITTING_COST(double x, double y) : _x(x), _y(y) &#123;&#125;&#x2F;&#x2F;构造函数初始化方式，给_x赋值x,_y赋值y

  &#x2F;&#x2F; 残差的计算
  template&lt;typename T&gt;&#x2F;&#x2F;函数模板
  bool operator()(          &#x2F;&#x2F;括号运算符重载
    const T *const abc, &#x2F;&#x2F; 模型参数，有3维
    T *residual) const &#123;
    residual[0] &#x3D; T(_y) - ceres::exp(abc[0] * T(_x) * T(_x) + abc[1] * T(_x) + abc[2]); &#x2F;&#x2F; y-exp(ax^2+bx+c)
    return true;
  &#125;

  const double _x, _y;    &#x2F;&#x2F; x,y数据
&#125;;

  &#x2F;&#x2F; 构建最小二乘问题
  ceres::Problem problem;
  for (int i &#x3D; 0; i &lt; N; i++) &#123;
    problem.AddResidualBlock(     &#x2F;&#x2F; 向问题中添加误差项
      &#x2F;&#x2F; 使用自动求导，模板参数：误差类型，输出维度，输入维度，维数要与前面struct中一致
      new ceres::AutoDiffCostFunction&lt;CURVE_FITTING_COST, 1, 3&gt;(
        new CURVE_FITTING_COST(x_data[i], y_data[i])
      ),
      nullptr,            &#x2F;&#x2F; 核函数，这里不使用，为空
      abc                 &#x2F;&#x2F; 待估计参数
    );
  &#125;


  &#x2F;&#x2F; 配置求解器
  ceres::Solver::Options options;     &#x2F;&#x2F; 这里有很多配置项可以填
  options.linear_solver_type &#x3D; ceres::DENSE_NORMAL_CHOLESKY;  &#x2F;&#x2F; 增量方程如何求解
  options.minimizer_progress_to_stdout &#x3D; true;   &#x2F;&#x2F; 输出到cout

  ceres::Solver::Summary summary;                &#x2F;&#x2F; 优化信息
  chrono::steady_clock::time_point t1 &#x3D; chrono::steady_clock::now();
  ceres::Solve(options, &amp;problem, &amp;summary);  &#x2F;&#x2F; 开始优化
  chrono::steady_clock::time_point t2 &#x3D; chrono::steady_clock::now();
  chrono::duration&lt;double&gt; time_used &#x3D; chrono::duration_cast&lt;chrono::duration&lt;double&gt;&gt;(t2 - t1);
  cout &lt;&lt; &quot;solve time cost &#x3D; &quot; &lt;&lt; time_used.count() &lt;&lt; &quot; seconds. &quot; &lt;&lt; endl;

<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p><a target="_blank" rel="noopener" href="http://www.ceres-solver.org/tutorial.html">ceres官方教程</a></p>
<h3 id="ch6-x2F-g2oCurveFitting-cpp"><a href="#ch6-x2F-g2oCurveFitting-cpp" class="headerlink" title="ch6&#x2F;g2oCurveFitting.cpp"></a>ch6&#x2F;g2oCurveFitting.cpp</h3><p>待更新</p>
<h2 id="第七讲"><a href="#第七讲" class="headerlink" title="第七讲"></a>第七讲</h2><p>视觉里程计1,vo,特征提取与匹配，对极几何，PnP，ICP,三角化,BA,SVD,直接法，光流法，光度误差</p>
<h3 id="ch7-x2F-orb-cv-cpp"><a href="#ch7-x2F-orb-cv-cpp" class="headerlink" title="ch7&#x2F;orb_cv.cpp"></a>ch7&#x2F;orb_cv.cpp</h3><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/345482379">ORB特征匹配、手写ORB特征代码详解</a></p>
<pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">#include &lt;iostream&gt;
#include &lt;opencv2&#x2F;core&#x2F;core.hpp&gt;
#include &lt;opencv2&#x2F;features2d&#x2F;features2d.hpp&gt;
#include &lt;opencv2&#x2F;highgui&#x2F;highgui.hpp&gt;
#include &lt;chrono&gt;

using namespace std;
using namespace cv;

int main(int argc, char **argv) &#123;
  if (argc !&#x3D; 3) &#123;
    cout &lt;&lt; &quot;usage: feature_extraction img1 img2&quot; &lt;&lt; endl;
    return 1;
  &#125;
  &#x2F;&#x2F;-- 读取图像
  Mat img_1 &#x3D; imread(argv[1], CV_LOAD_IMAGE_COLOR);
  Mat img_2 &#x3D; imread(argv[2], CV_LOAD_IMAGE_COLOR);
  assert(img_1.data !&#x3D; nullptr &amp;&amp; img_2.data !&#x3D; nullptr);

  &#x2F;&#x2F;-- 初始化
  std::vector&lt;KeyPoint&gt; keypoints_1, keypoints_2;
  Mat descriptors_1, descriptors_2;
  Ptr&lt;FeatureDetector&gt; detector &#x3D; ORB::create();        &#x2F;&#x2F;ORB
  Ptr&lt;DescriptorExtractor&gt; descriptor &#x3D; ORB::create();
  Ptr&lt;DescriptorMatcher&gt; matcher &#x3D; DescriptorMatcher::create(&quot;BruteForce-Hamming&quot;);

  &#x2F;&#x2F;-- 第一步:检测 Oriented FAST 角点位置
  chrono::steady_clock::time_point t1 &#x3D; chrono::steady_clock::now();
  detector-&gt;detect(img_1, keypoints_1);
  detector-&gt;detect(img_2, keypoints_2);

  &#x2F;&#x2F;-- 第二步:根据角点位置计算 BRIEF 描述子
  descriptor-&gt;compute(img_1, keypoints_1, descriptors_1);
  descriptor-&gt;compute(img_2, keypoints_2, descriptors_2);
  chrono::steady_clock::time_point t2 &#x3D; chrono::steady_clock::now();
  chrono::duration&lt;double&gt; time_used &#x3D; chrono::duration_cast&lt;chrono::duration&lt;double&gt;&gt;(t2 - t1);
  cout &lt;&lt; &quot;extract ORB cost &#x3D; &quot; &lt;&lt; time_used.count() &lt;&lt; &quot; seconds. &quot; &lt;&lt; endl;

  Mat outimg1,outimg2;
  drawKeypoints(img_1, keypoints_1, outimg1, Scalar::all(-1), DrawMatchesFlags::DEFAULT);
  drawKeypoints(img_2, keypoints_2, outimg2, Scalar::all(-1), DrawMatchesFlags::DEFAULT);
  imshow(&quot;pic1_ORB features&quot;, outimg1);
  imshow(&quot;pic2_ORB features&quot;, outimg2);

  &#x2F;&#x2F;-- 第三步:对两幅图像中的BRIEF描述子进行匹配，使用 Hamming 距离
  vector&lt;DMatch&gt; matches;
  t1 &#x3D; chrono::steady_clock::now();
  matcher-&gt;match(descriptors_1, descriptors_2, matches);
  t2 &#x3D; chrono::steady_clock::now();
  time_used &#x3D; chrono::duration_cast&lt;chrono::duration&lt;double&gt;&gt;(t2 - t1);
  cout &lt;&lt; &quot;match ORB cost &#x3D; &quot; &lt;&lt; time_used.count() &lt;&lt; &quot; seconds. &quot; &lt;&lt; endl;

  &#x2F;&#x2F;-- 第四步:匹配点对筛选
  &#x2F;&#x2F; 计算最小距离和最大距离
  auto min_max &#x3D; minmax_element(matches.begin(), matches.end(),
                                [](const DMatch &amp;m1, const DMatch &amp;m2) &#123; return m1.distance &lt; m2.distance; &#125;);
  double min_dist &#x3D; min_max.first-&gt;distance;
  double max_dist &#x3D; min_max.second-&gt;distance;

  printf(&quot;-- Max dist : %f \n&quot;, max_dist);
  printf(&quot;-- Min dist : %f \n&quot;, min_dist);

  &#x2F;&#x2F;当描述子之间的距离大于两倍的最小距离时,即认为匹配有误.但有时候最小距离会非常小,设置一个经验值30作为下限.
  std::vector&lt;DMatch&gt; good_matches;
  for (int i &#x3D; 0; i &lt; descriptors_1.rows; i++) &#123;
    if (matches[i].distance &lt;&#x3D; max(2 * min_dist, 30.0)) &#123;
      good_matches.push_back(matches[i]);
    &#125;
  &#125;

  &#x2F;&#x2F;-- 第五步:绘制匹配结果
  Mat img_match;
  Mat img_goodmatch;
  drawMatches(img_1, keypoints_1, img_2, keypoints_2, matches, img_match);
  drawMatches(img_1, keypoints_1, img_2, keypoints_2, good_matches, img_goodmatch);
  imshow(&quot;all matches&quot;, img_match);
  imshow(&quot;good matches&quot;, img_goodmatch);
  waitKey(0);

  return 0;
&#125;
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p><a target="_blank" rel="noopener" href="https://vimsky.com/examples/usage/cpp-algorithm-minmax_element-function-01.html">C++ Algorithm minmax_element()用法及代码示例</a></p>
<p><img src="/pic/%E9%80%89%E5%8C%BA_133.png" alt="两图特征点"></p>
<p><img src="/pic/%E9%80%89%E5%8C%BA_134.png" alt="匹配情况"></p>
<h3 id="ch7-x2F-orb-self-cpp"><a href="#ch7-x2F-orb-self-cpp" class="headerlink" title="ch7&#x2F;orb_self.cpp"></a>ch7&#x2F;orb_self.cpp</h3><p>手写ORB特征</p>
<p><strong>(1)FAST角点检测</strong></p>
<p>opencv库函数：利用ORB特征检测器detector里的detect函数。</p>
<p>手写：利用改进的FAST算法，增加了中心像素和围绕该像素的圆的像素之间的强度差阈值以及非最大值抑制。</p>
<p>其中的FAST（）函数结构如下：</p>
<pre class="line-numbers language-C++" data-language="C++"><code class="language-C++">CV_EXPORTS void FAST( InputArray image, CV_OUT std::vector&lt;KeyPoint&gt;&amp; keypoints,
                      int threshold, bool nonmaxSuppression&#x3D;true );
&#x2F;*
image： 检测的灰度图像
keypoints: 在图像上检测到的关键点
threshold: 中心像素和围绕该像素的圆的像素之间的强度差阈值
nonmaxSuppression: 参数非最大值抑制,默认为真，对检测到的角点应用非最大值抑制。
*&#x2F;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p><strong>（2）描述子计算</strong></p>
<p>opencv库函数：构建ORB特征描述器descriptor里的compute函数</p>
<p>手写：自定义函数ComputeORB()来计算描述子，在这个函数里面首先会排除一些靠近边缘的特征点。排除的坏点的判断方式如下：</p>
<ul>
<li><p>当kp.pt.x &lt; half_boundary时，边长为boundary的图像块将在-x轴上超出图像。</p>
</li>
<li><p>当kp.pt.y &lt; half_boundary时，边长为boundary的图像块将在-y轴上超出图像。</p>
</li>
<li><p>当kp.pt.x &gt;&#x3D; img.cols - half_boundary（kp.pt.x&gt;&#x3D; 640-16）时，边长为boundary(32)的图像块将在+x轴上超出图像。</p>
</li>
<li><p>当kp.pt.y &gt;&#x3D; img.rows - half_boundary（kp.pt.y&gt;&#x3D; 480-16）时，边长为boundary(32)的图像块将在+y轴上超出图像。</p>
</li>
</ul>
<p>同时，在手写代码中，按照灰度质心法定义了图像块的矩和质心，最后求出了特征点的角度。</p>
<p>在求描述子时，事先准备了256*4个数据集，这些数据集表示以关键点为中心，[-13,12]的范围内,随机选点对p,q。选取两个点p,q，这两个点的坐标从数据集选取，然后乘上之前求的角度再加上关键点，以此找到关键点附近的两个随机像素，然后比较像素值。最终形成描述子。</p>
<p><strong>（3）BRIEF描述子匹配函数</strong></p>
<p>opencv下：利用自带的match函数，比较两副图像的描述子的汉明距离，并从小到大排序在matches容器中，然后在容器中挑选好的描述子，这些描述子满足描述子之间的距离小于两倍的最小距离和经验阈值的最小值，因为最小距离可能是0；</p>
<p>手写：描述子是采用256位二进制描述，对应到8个32位的unsigned int 数据，并利用SSE指令集计算每个unsigned int变量中1的个数，从而计算汉明距离。手写的暴力匹配代码中输入三个参数，分别是第一副和第二副图像的描述子，和存放输出匹配对的容器；这里的暴力匹配的思路为：取第一副图片中的一个描述子，分别计算与第二副图片每个描述子的汉明距离，然后选取最近的距离以及所对应的匹配对，然后多次选取图片1中的描述子重复上述操作，分别找到最短距离和相应的匹配对。最后再将比较得到的最小距离与设定的经验阈值作比较，如果小于经验阈值则保留并输出该匹配对。</p>
<p>具体代码如下：</p>
<pre class="line-numbers language-C++" data-language="C++"><code class="language-C++"> 
&#x2F;&#x2F; compute the descriptor
&#x2F;&#x2F;(1)计算角点的方向；(2)计算描述子。
void ComputeORB(const cv::Mat &amp;img, vector&lt;cv::KeyPoint&gt; &amp;keypoints, vector&lt;DescType&gt; &amp;descriptors) &#123;
  const int half_patch_size &#x3D; 8; &#x2F;&#x2F;计算特征点方向时，选取的图像块，16*16
  const int half_boundary &#x3D; 16;&#x2F;&#x2F;计算描述子时在32*32的图像块中选点
  int bad_points &#x3D; 0; &#x2F;&#x2F;计算描述子时，在32*32的区域块选择两个点比较，所选择的点超出图像范围的。出现这种情况下的FAST角点的数目。
    &#x2F;&#x2F;遍历所有FAST角点
  for (auto &amp;kp: keypoints) 
  &#123;
    &#x2F;&#x2F;超出图像边界的角点的描述子设为空
    if (kp.pt.x &lt; half_boundary || kp.pt.y &lt; half_boundary ||
        kp.pt.x &gt;&#x3D; img.cols - half_boundary || kp.pt.y &gt;&#x3D; img.rows - half_boundary) &#123;
      &#x2F;&#x2F; outside
      bad_points++; &#x2F;&#x2F;bad_points的描述子设为空
      descriptors.push_back(&#123;&#125;);
      continue;
    &#125;
    &#x2F;&#x2F;计算16*16图像块的灰度质心
    &#x2F;&#x2F;可参照下面的图片帮助理解
    float m01 &#x3D; 0, m10 &#x3D; 0;&#x2F;&#x2F;图像块的矩 视觉slam十四讲中p157
    for (int dx &#x3D; -half_patch_size; dx &lt; half_patch_size; ++dx) 
    &#123;
      for (int dy &#x3D; -half_patch_size; dy &lt; half_patch_size; ++dy) 
      &#123;
        uchar pixel &#x3D; img.at&lt;uchar&gt;(kp.pt.y + dy, kp.pt.x + dx);
        m10 +&#x3D; dx * pixel; &#x2F;&#x2F;pixel表示灰度值 视觉slam十四讲中p157最上面的公式
        m01 +&#x3D; dy * pixel;&#x2F;&#x2F;pixel表示灰度值 视觉slam十四讲中p157最上面的公式
      &#125;
    &#125;
 
    &#x2F;&#x2F; angle should be arc tan(m01&#x2F;m10);参照下面第三章图片帮助理解
    float m_sqrt &#x3D; sqrt(m01 * m01 + m10 * m10) + 1e-18; &#x2F;&#x2F; avoid divide by zero  1e-18避免了m_sqrt的值为0（图像块全黑）将m01 * m01 + m10 * m10进行开根
    float sin_theta &#x3D; m01 &#x2F; m_sqrt;&#x2F;&#x2F;sin_theta &#x3D; m01 &#x2F; 根号下（m01 * m01 + m10 * m10））
    float cos_theta &#x3D; m10 &#x2F; m_sqrt;&#x2F;&#x2F;cos_theta &#x3D; m10 &#x2F; 根号下（m01 * m01 + m10 * m10））
    &#x2F;&#x2F;因为tan_theta &#x3D; m01&#x2F;m10 即为tan_theta &#x3D; sin_theta &#x2F; cos_theta &#x3D; [m01 &#x2F; 根号下（m01 * m01 + m10 * m10] &#x2F; [m10 &#x2F; 根号下（m01 * m01 + m10 * m10]
    &#x2F;&#x2F;目的是求出特征点的方向  视觉slam十四讲中p157第三个公式
    &#x2F;&#x2F; compute the angle of this point
    DescType desc(8, 0); &#x2F;&#x2F;8个元素，它们的值初始化为0
    
    for (int i &#x3D; 0; i &lt; 8; i++) &#123;
      uint32_t d &#x3D; 0;
      for (int k &#x3D; 0; k &lt; 32; k++) 
      &#123;
        int idx_pq &#x3D; i * 32 + k;&#x2F;&#x2F;idx_pq表示二进制描述子中的第几位
        cv::Point2f p(ORB_pattern[idx_pq * 4], ORB_pattern[idx_pq * 4 + 1]);
        cv::Point2f q(ORB_pattern[idx_pq * 4 + 2], ORB_pattern[idx_pq * 4 + 3]);
 
        &#x2F;&#x2F; rotate with theta
        &#x2F;&#x2F;p,q绕原点旋转theta得到pp,qq
        cv::Point2f pp &#x3D; cv::Point2f(cos_theta * p.x - sin_theta * p.y, sin_theta * p.x + cos_theta * p.y)
                         + kp.pt;
        cv::Point2f qq &#x3D; cv::Point2f(cos_theta * q.x - sin_theta * q.y, sin_theta * q.x + cos_theta * q.y)
                         + kp.pt;
        if (img.at&lt;uchar&gt;(pp.y, pp.x) &lt; img.at&lt;uchar&gt;(qq.y, qq.x)) &#123;
          d |&#x3D; 1 &lt;&lt; k;
        &#125;
      &#125;
      desc[i] &#x3D; d;
    &#125;
    descriptors.push_back(desc);&#x2F;&#x2F;desc表示该Oriented_FAST角点的描述子
  &#125;
 
  cout &lt;&lt; &quot;bad&#x2F;total: &quot; &lt;&lt; bad_points &lt;&lt; &quot;&#x2F;&quot; &lt;&lt; keypoints.size() &lt;&lt; endl;
&#125;
 
&#x2F;&#x2F; brute-force matching
void BfMatch(const vector&lt;DescType&gt; &amp;desc1, const vector&lt;DescType&gt; &amp;desc2, vector&lt;cv::DMatch&gt; &amp;matches) &#123;
  const int d_max &#x3D; 40;&#x2F;&#x2F;描述子之间的距离小于这个值，才被认为是正确匹配
 
  for (size_t i1 &#x3D; 0; i1 &lt; desc1.size(); ++i1)  &#x2F;&#x2F;size_t相当于int，便于代码移植
  &#123;
    if (desc1[i1].empty()) continue;
    cv::DMatch m&#123;i1, 0, 256&#125;; &#x2F;&#x2F;定义了一个匹配对m
    for (size_t i2 &#x3D; 0; i2 &lt; desc2.size(); ++i2)&#x2F;&#x2F;计算描述子desc1[i1]和描述子desc2[i2]的距离，即不同位数的数目
     &#123;
      if (desc2[i2].empty()) continue;
      int distance &#x3D; 0;
      for (int k &#x3D; 0; k &lt; 8; k++) &#123;
        distance +&#x3D; _mm_popcnt_u32(desc1[i1][k] ^ desc2[i2][k]);
      &#125;
      if (distance &lt; d_max &amp;&amp; distance &lt; m.distance) &#123;
        m.distance &#x3D; distance;
        m.trainIdx &#x3D; i2;
      &#125;
    &#125;
    if (m.distance &lt; d_max) &#123;
      matches.push_back(m);
    &#125;
  &#125;
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<blockquote>
<p>参考<a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_53660567/article/details/121095677">视觉SLAM十四讲CH7代码解析及课后习题详解</a></p>
</blockquote>
<h3 id="ch7-x2F-pose-estimation-2d2d-cpp"><a href="#ch7-x2F-pose-estimation-2d2d-cpp" class="headerlink" title="ch7&#x2F;pose_estimation_2d2d.cpp"></a>ch7&#x2F;pose_estimation_2d2d.cpp</h3><p>本程序演示了如何使用2D-2D的特征匹配估计相机运动,对极约束求解相机运动</p>
<pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">&#x2F;&#x2F;
&#x2F;&#x2F;
#include &lt;iostream&gt;
#include &lt;opencv2&#x2F;core&#x2F;core.hpp&gt;
#include &lt;opencv2&#x2F;features2d&#x2F;features2d.hpp&gt;
#include &lt;opencv2&#x2F;highgui&#x2F;highgui.hpp&gt;
#include &lt;opencv2&#x2F;calib3d&#x2F;calib3d.hpp&gt;

using namespace std;
using namespace cv;
&#x2F;&#x2F;声明特征匹配函数
void find_feature_matches(const Mat &amp;img1,const Mat &amp;img2,
                          std::vector&lt;KeyPoint&gt; &amp;keypoints_1,
                          std::vector&lt;KeyPoint&gt; &amp;keypoints_2,
                          std::vector&lt;DMatch&gt; &amp;matches);

&#x2F;&#x2F;声明位姿估计函数
void pose_estimated_2d2d( std::vector&lt;KeyPoint&gt; keypoints_1,
                          std::vector&lt;KeyPoint&gt; keypoints_2,
                          std::vector&lt;DMatch&gt; matches,
                          Mat &amp;R, Mat &amp;t);

&#x2F;&#x2F;声明 像素坐标转归一化坐标 p99页 公式5.5 变换一下就好啦！
&#x2F;&#x2F;这里的函数我改了一下，书上的只是得到二维点，主程序中，还把二维点转换为三维点，我觉得多此一举，一个函数实现不就好了么
&#x2F;&#x2F;下面是我实现的坐标变换函数 返回的是Mat类型，其实照片也是矩阵
Mat pixel2cam(const Point2d &amp;p,const Mat &amp;K);&#x2F;&#x2F;p是像素坐标，K是相机内参矩阵

int main(int argc,char** argv)
&#123;
    &#x2F;&#x2F;运行可执行文件+图片1的路径+图片2的路径
    if(argc!&#x3D;3)
    &#123;
        cout&lt;&lt;&quot;usage: .&#x2F;pose_estimated_2d2d img1 img2&quot;&lt;&lt;endl;
        return 1;
    &#125;
    &#x2F;*argv[1]&#x3D;&quot;&#x2F;home&#x2F;nnz&#x2F;data&#x2F;slam_pratice&#x2F;pratice_pose_estimated&#x2F;1.png&quot;;
    argv[2]&#x3D;&quot;&#x2F;home&#x2F;nnz&#x2F;data&#x2F;slam_pratice&#x2F;pratice_pose_estimated&#x2F;2.png&quot;;*&#x2F;
    &#x2F;&#x2F;读取图片
    Mat img1&#x3D;imread(argv[1],CV_LOAD_IMAGE_COLOR);&#x2F;&#x2F;彩色图
    Mat img2&#x3D;imread(argv[2],CV_LOAD_IMAGE_COLOR);
    &#x2F;&#x2F;定义要用到的变量啊，比如 keypoints_1,keypoints_2,matches
    vector&lt;KeyPoint&gt; keypoints_1, keypoints_2;
    vector&lt;DMatch&gt; matches;
    &#x2F;&#x2F;计算两个keypoints的matches
    find_feature_matches(img1,img2,keypoints_1,keypoints_2,matches);
    &#x2F;&#x2F;这样就得到matche啦！
    cout &lt;&lt; &quot;一共找到了&quot; &lt;&lt; matches.size() &lt;&lt; &quot;组匹配点&quot; &lt;&lt; endl;
    &#x2F;&#x2F;重点来了
    &#x2F;&#x2F;估计两组图片之间的运动
    Mat R,t;&#x2F;&#x2F;定义一下旋转和平移
    pose_estimated_2d2d(keypoints_1,keypoints_2,matches,R,t);
    &#x2F;&#x2F;这样就算出R ,t啦
    &#x2F;&#x2F;当然我们还需要验证一下对极约束 准不准了
    &#x2F;&#x2F;验证 E&#x3D;t^R*scale;
    &#x2F;&#x2F;t_x是t的反对称矩阵
    Mat t_x &#x3D;
            (Mat_&lt;double&gt;(3, 3) &lt;&lt; 0, -t.at&lt;double&gt;(2, 0), t.at&lt;double&gt;(1, 0),
                    t.at&lt;double&gt;(2, 0), 0, -t.at&lt;double&gt;(0, 0),
                    -t.at&lt;double&gt;(1, 0), t.at&lt;double&gt;(0, 0), 0);

    cout &lt;&lt; &quot;t^R&#x3D;&quot; &lt;&lt; endl &lt;&lt; t_x * R &lt;&lt; endl;
    &#x2F;&#x2F;验证对极约束 对应P167 页公式7.10 x2TEx1&#x3D;0  E&#x3D;t^*R
    &#x2F;&#x2F;定义内参矩阵
    Mat K &#x3D; (Mat_&lt;double&gt;(3, 3) &lt;&lt; 520.9, 0, 325.1,
                                                 0, 521.0,249.7,
                                                 0, 0, 1);
    for(DMatch m: matches)
    &#123;
        Mat x1&#x3D;pixel2cam(keypoints_1[m.queryIdx].pt,K);
        Mat x2&#x3D;pixel2cam(keypoints_2[m.queryIdx].pt,K);
        Mat d&#x3D;x2.t()*t_x*R*x1;&#x2F;&#x2F;若d很趋近于零，则说明没啥问题
        cout &lt;&lt; &quot;epipolar constraint &#x3D; &quot; &lt;&lt; d &lt;&lt; endl;
    &#125;
    return 0;

&#125;
&#x2F;&#x2F;最复杂的地方来咯
&#x2F;&#x2F;函数的实现
&#x2F;&#x2F;匹配函数
void find_feature_matches(const Mat &amp;img1,const Mat &amp;img2,
                          std::vector&lt;KeyPoint&gt; &amp;keypoints_1,
                          std::vector&lt;KeyPoint&gt; &amp;keypoints_2,
                          std::vector&lt;DMatch&gt; &amp;matches)
&#123;
    &#x2F;&#x2F;先初始化，创建咱们要用到的对象
    &#x2F;&#x2F;定义两个关键点对应的描述子，同时创建检测keypoints的检测器
    Mat descriptors_1, descriptors_2;
    vector&lt;DMatch&gt; match;&#x2F;&#x2F;暂时存放匹配点,因为后面还要进行筛选
    Ptr&lt;FeatureDetector&gt; detector&#x3D;ORB::create();&#x2F;&#x2F;keypoints检测器
    Ptr&lt;DescriptorExtractor&gt; descriptor &#x3D;ORB::create();&#x2F;&#x2F;描述子提取器
    Ptr&lt;DescriptorMatcher&gt; matcher &#x3D;DescriptorMatcher::create(
            &quot;BruteForce-Hamming&quot;);&#x2F;&#x2F;描述子匹配器（方法：暴力匹配）
    &#x2F;&#x2F;step1:找到角点
    detector-&gt;detect(img1,keypoints_1);&#x2F;&#x2F;得到图1的关键点（keypoints_1）
    detector-&gt;detect(img2,keypoints_2);&#x2F;&#x2F;得到图2的关键点（keypoints_2）
    &#x2F;&#x2F;step2:计算关键点所对应的描述子
    descriptor-&gt;compute(img1,keypoints_1,descriptors_1);&#x2F;&#x2F;得到descriptors_1
    descriptor-&gt;compute(img2,keypoints_2,descriptors_2);&#x2F;&#x2F;得到descriptors_2
    &#x2F;&#x2F;step3:进行暴力匹配
    matcher-&gt;match(descriptors_1,descriptors_2,match);
    &#x2F;&#x2F;step4:对match进行筛选，得到好的匹配点，把好的匹配点放在matches中
    &#x2F;&#x2F;先定义两个变量，一个是最大距离，一个是最小距离
    double min_dist&#x3D;1000, max_dist&#x3D;0;
    &#x2F;&#x2F;找出所有匹配之间的最小距离和最大距离, 即是最相似的和最不相似的两组点之间的距离
    for(int i&#x3D;0;i&lt;descriptors_1.rows;i++) &#x2F;&#x2F;描述子本质是由 0,1 组成的向量
    &#123;
        double dist &#x3D;match[i].distance;
        &#x2F;&#x2F;还记得orb_cv中如何找最大距离和最远距离的吗，那里面的程序是用下面的函数实现的，下面的函数得到的是pair first 里面是最小距离，second里面是最大距离
        &#x2F;&#x2F; minmax_element(matches.begin(),matched.end,[](const DMatch &amp;m1,const DMatch &amp;m2)&#123;return m1.distance&lt;m2.distance;&#125;);
        &#x2F;&#x2F;本程序用下面的if语句得到距离
        if (dist &lt; min_dist) min_dist &#x3D; dist;
        if (dist &gt; max_dist) max_dist &#x3D; dist;
    &#125;
    printf(&quot;-- Max dist : %f \n&quot;, max_dist);
    printf(&quot;-- Min dist : %f \n&quot;, min_dist);
    &#x2F;&#x2F;当描述子之间的距离大于两倍的最小距离时,即认为匹配有误.
    &#x2F;&#x2F; 但有时候最小距离会非常小,设置一个经验值30作为下限.
    for(int i&#x3D;0;i&lt;descriptors_1.rows;i++)
    &#123;
        if(match[i].distance&lt;&#x3D;max(2*min_dist,30.0))
        &#123;
            matches.push_back(match[i]);
        &#125;
    &#125;
&#125;
&#x2F;&#x2F;像素到归一化坐标
Mat pixel2cam(const Point2d &amp;p,const Mat &amp;K)&#x2F;&#x2F;p是像素坐标，K是相机内参矩阵
&#123;
    Mat t;
    t&#x3D;(Mat_&lt;double&gt;(3,1)&lt;&lt;(p.x - K.at&lt;double&gt;(0, 2)) &#x2F; K.at&lt;double&gt;(0, 0),
            (p.y - K.at&lt;double&gt;(1, 2)) &#x2F; K.at&lt;double&gt;(1, 1),1);
    return t;
&#125;

&#x2F;&#x2F;实现位姿估计函数
void pose_estimated_2d2d( std::vector&lt;KeyPoint&gt; keypoints_1,
                          std::vector&lt;KeyPoint&gt; keypoints_2,
                          std::vector&lt;DMatch&gt; matches,
                          Mat &amp;R, Mat &amp;t)
&#123;
    &#x2F;&#x2F; 相机内参来源于 TUM Freiburg2
    Mat K &#x3D; (Mat_&lt;double&gt;(3, 3) &lt;&lt; 520.9, 0, 325.1,
                                                 0, 521.0, 249.7,
                                                 0, 0, 1);

    &#x2F;&#x2F;咱们要把关键点的像素点拿出来 ,定义两个容器接受两个图关键点的像素位置
    vector&lt;Point2d&gt; points1;
    vector&lt;Point2d&gt; points2;
    for(int i&#x3D;0;i&lt;(int)matches.size();i++)
    &#123;
        &#x2F;&#x2F;queryIdx是图1中匹配的关键点的对应编号
        &#x2F;&#x2F;trainIdx是图2中匹配的关键点的对应编号
        &#x2F;&#x2F;pt可以把关键点的像素位置取出来
        points1.push_back(keypoints_1[matches[i].queryIdx].pt);
        points2.push_back(keypoints_2[matches[i].trainIdx].pt);
    &#125;
    &#x2F;&#x2F;-- 计算基础矩阵
    Mat fundamental_matrix;
    fundamental_matrix &#x3D; findFundamentalMat(points1, points2, CV_FM_8POINT);
    cout &lt;&lt; &quot;fundamental_matrix is &quot; &lt;&lt; endl &lt;&lt; fundamental_matrix &lt;&lt; endl;


    &#x2F;&#x2F;计算本质矩阵 E
    &#x2F;&#x2F;把cx ,cy放进一个向量里面 &#x3D;相机的光心
    Point2d principal_point(325.1, 249.7);
    double focal_length&#x3D;521;&#x2F;&#x2F;相机的焦距
    &#x2F;&#x2F;之所以取上面的principal_point、focal_length是因为计算本质矩阵的函数要用
    &#x2F;&#x2F;得到本质矩阵essential_matrix
    Mat essential_matrix&#x3D;findEssentialMat(points1,points2,focal_length,principal_point);
    cout&lt;&lt;&quot; essential_matrix &#x3D;\n&quot;&lt;&lt; essential_matrix &lt;&lt;endl;

    &#x2F;&#x2F;-- 计算单应矩阵 homography_matrix
    &#x2F;&#x2F;-- 但是本例中场景不是平面，单应矩阵意义不大
    Mat homography_matrix;
    homography_matrix &#x3D; findHomography(points1, points2, RANSAC, 3);
    cout &lt;&lt; &quot;homography_matrix is &quot; &lt;&lt; endl &lt;&lt; homography_matrix &lt;&lt; endl;
    &#x2F;&#x2F;通过本质矩阵恢复咱们的 R  t
    recoverPose(essential_matrix,points1,points2,R,t,focal_length,principal_point);
    &#x2F;&#x2F;输出咱们的 R t
    cout&lt;&lt;&quot; 得到图1到图2 的位姿变换:\n &quot;&lt;&lt;endl;
    cout&lt;&lt;&quot;R&#x3D; \n&quot;&lt;&lt; R &lt;&lt;endl;
    cout&lt;&lt;&quot;t&#x3D; \n&quot;&lt;&lt; t &lt;&lt;endl;
&#125;
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/joun772/article/details/109466153?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_baidulandingword~default-12-109466153-blog-116243451.235%5Ev28%5Epc_relevant_recovery_v2&spm=1001.2101.3001.4242.7&utm_relevant_index=15">SLAM十四讲-ch7(2)-位姿估计(包含2d-2d、3d-2d、3d-3d、以及三角化实现代码的注释)</a></p>
<h3 id="ch7-x2F-triangulation-cpp"><a href="#ch7-x2F-triangulation-cpp" class="headerlink" title="ch7&#x2F;triangulation.cpp"></a>ch7&#x2F;triangulation.cpp</h3><p>在上面的2d2d位姿估计的基础上，利用三角化来获得特征匹配点的深度信息(通过画图，验证三维点与特征点的重投影关系)</p>
<pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">&#x2F;&#x2F;
&#x2F;&#x2F; Created by wenbo on 2020&#x2F;11&#x2F;3.
&#x2F;&#x2F;
&#x2F;&#x2F;该程序在pose_estimated_2d2d的基础上加上三角化，以求得匹配的特征点在世界下的三维点
&#x2F;&#x2F;
&#x2F;&#x2F;
#include &lt;iostream&gt;
#include &lt;opencv2&#x2F;opencv.hpp&gt;
&#x2F;&#x2F; #include &quot;extra.h&quot; &#x2F;&#x2F; used in opencv2
using namespace std;
using namespace cv;
&#x2F;&#x2F;声明特征匹配函数
void find_feature_matches(const Mat &amp;img1,const Mat &amp;img2,
                          std::vector&lt;KeyPoint&gt; &amp;keypoints_1,
                          std::vector&lt;KeyPoint&gt; &amp;keypoints_2,
                          std::vector&lt;DMatch&gt; &amp;matches);

&#x2F;&#x2F;声明位姿估计函数
void pose_estimated_2d2d( std::vector&lt;KeyPoint&gt; &amp;keypoints_1,
                          std::vector&lt;KeyPoint&gt; &amp;keypoints_2,
                          std::vector&lt;DMatch&gt; &amp;matches,
                          Mat &amp;R, Mat &amp;t);

&#x2F;&#x2F;声明 像素坐标转归一化坐标 p99页 公式5.5 变换一下就好啦！
&#x2F;&#x2F;这里的函数我改了一下，书上的只是得到二维点，主程序中，还把二维点转换为三维点，我觉得多此一举，一个函数实现不就好了么
&#x2F;&#x2F;下面是我实现的坐标变换函数 返回的是Mat类型，其实照片也是矩阵
Point2f pixel2cam(const Point2d &amp;p, const Mat &amp;K);&#x2F;&#x2F;p是像素坐标，K是相机内参矩阵

&#x2F;&#x2F;声明三角化函数
void triangulation(
        const vector&lt;KeyPoint&gt; &amp;keypoint_1,
        const vector&lt;KeyPoint&gt; &amp;keypoint_2,
        const std::vector&lt;DMatch&gt; &amp;matches,
        const Mat &amp;R, const Mat &amp;t,
        vector&lt;Point3d&gt; &amp;points
);

&#x2F;&#x2F;&#x2F; 作图用
inline cv::Scalar get_color(float depth) &#123;
    float up_th &#x3D; 50, low_th &#x3D; 10, th_range &#x3D; up_th - low_th;
    if (depth &gt; up_th) depth &#x3D; up_th;
    if (depth &lt; low_th) depth &#x3D; low_th;
    return cv::Scalar(255 * depth &#x2F; th_range, 0, 255 * (1 - depth &#x2F; th_range));
&#125;

int main(int argc,char** argv)
&#123;
    &#x2F;&#x2F;运行可执行文件+图片1的路径+图片2的路径
    if(argc!&#x3D;3)
    &#123;
        cout&lt;&lt;&quot;usage: .&#x2F;triangulation img1 img2&quot;&lt;&lt;endl;
        return 1;
    &#125;

    &#x2F;&#x2F;读取图片
    Mat img1&#x3D;imread(argv[1],CV_LOAD_IMAGE_COLOR);&#x2F;&#x2F;彩色图
    Mat img2&#x3D;imread(argv[2],CV_LOAD_IMAGE_COLOR);
    &#x2F;&#x2F;定义要用到的变量啊，比如 keypoints_1,keypoints_2,matches
    vector&lt;KeyPoint&gt; keypoints_1, keypoints_2;
    vector&lt;DMatch&gt; matches;
    &#x2F;&#x2F;计算两个keypoints的matches
    find_feature_matches(img1,img2,keypoints_1,keypoints_2,matches);
    &#x2F;&#x2F;这样就得到matches啦！
    cout &lt;&lt; &quot;一共找到了&quot; &lt;&lt; matches.size() &lt;&lt; &quot;组匹配点&quot; &lt;&lt; endl;
    &#x2F;&#x2F;重点来了
    &#x2F;&#x2F;估计两组图片之间的运动
    Mat R,t;&#x2F;&#x2F;定义一下旋转和平移
    pose_estimated_2d2d(keypoints_1,keypoints_2,matches,R,t);
    &#x2F;&#x2F;这样就算出R ,t啦

    &#x2F;&#x2F;三角化
    &#x2F;&#x2F;定义一个容器 points 用来存放特征匹配点在世界坐标系下的3d点
    vector&lt;Point3d&gt; points;
    triangulation(keypoints_1,keypoints_2,matches,R,t,points);
    &#x2F;&#x2F;得到三维点

    &#x2F;&#x2F;验证三维点与特征点的重投影关系
    Mat K &#x3D; (Mat_&lt;double&gt;(3, 3) &lt;&lt; 520.9, 0, 325.1,
                                                 0, 521.0, 249.7,
                                                 0, 0, 1);
    Mat img_plot1&#x3D;img1.clone();
    Mat img_plot2&#x3D;img2.clone();
    &#x2F;&#x2F;利用循环找到图1和图2特征点在图上的位置，并圈出来
    for(int i&#x3D;0;i&lt;matches.size();i++)
    &#123;
        &#x2F;&#x2F;先画图1中特征点
        &#x2F;&#x2F;在这里，为什么从一个世界坐标系下的3d点，就可以得到，图1相机坐标下的深度点呢？
        &#x2F;&#x2F;我觉得是因为 图1的位姿: R是单位矩阵，t为0（在三角化函数中有写到） 所以可以把图1的相机坐标看成是世界坐标
        float  depth1&#x3D;points[i].z;&#x2F;&#x2F;取出图1各个特征点的深度信息
        cout&lt;&lt;&quot;depth: &quot;&lt;&lt;depth1&lt;&lt;endl;
        Point2d pt1_cam&#x3D;pixel2cam(keypoints_1[matches[i].queryIdx].pt,K);
        cv::circle(img_plot1, keypoints_1[matches[i].queryIdx].pt, 2, get_color(depth1), 2);

        &#x2F;&#x2F;画图2
        &#x2F;&#x2F;得到图2坐标系下的3d点，得到图2的深度信息
        Mat pt2_trans&#x3D;R*(Mat_&lt;double&gt;(3, 1) &lt;&lt;points[i].x,points[i].y,points[i].z)+t;
        float depth2 &#x3D; pt2_trans.at&lt;double&gt;(2, 0);
        cv::circle(img_plot2, keypoints_2[matches[i].trainIdx].pt, 2, get_color(depth2), 2);
    &#125;
&#x2F;&#x2F;画图
    cv::imshow(&quot;img 1&quot;, img_plot1);
    cv::imshow(&quot;img 2&quot;, img_plot2);
    cv::waitKey();


    return 0;

&#125;

void triangulation(
        const vector&lt;KeyPoint&gt; &amp;keypoint_1,
        const vector&lt;KeyPoint&gt; &amp;keypoint_2,
        const std::vector&lt;DMatch&gt; &amp;matches,
        const Mat &amp;R, const Mat &amp;t,
        vector&lt;Point3d&gt; &amp;points
)
&#123;
    &#x2F;&#x2F;定义图1在世界坐标系下的位姿
    Mat T1 &#x3D; (Mat_&lt;float&gt;(3, 4) &lt;&lt;
                                1, 0, 0, 0,
                                0, 1, 0, 0,
                                0, 0, 1, 0);

    &#x2F;&#x2F;定义图2在世界坐标系下的位姿
    Mat T2 &#x3D; (Mat_&lt;float&gt;(3, 4) &lt;&lt;
                                R.at&lt;double&gt;(0, 0), R.at&lt;double&gt;(0, 1), R.at&lt;double&gt;(0, 2), t.at&lt;double&gt;(0, 0),
            R.at&lt;double&gt;(1, 0), R.at&lt;double&gt;(1, 1), R.at&lt;double&gt;(1, 2), t.at&lt;double&gt;(1, 0),
            R.at&lt;double&gt;(2, 0), R.at&lt;double&gt;(2, 1), R.at&lt;double&gt;(2, 2), t.at&lt;double&gt;(2, 0)
    );
    Mat K &#x3D; (Mat_&lt;double&gt;(3, 3) &lt;&lt; 520.9, 0, 325.1, 0, 521.0, 249.7, 0, 0, 1);
    &#x2F;&#x2F;容器 pts_1、pts_2分别存放图1和图2中特征点对应的自己相机归一化坐标中的 x与 y
    vector&lt;Point2f&gt; pts_1,pts_2;
    for(DMatch m:matches)&#x2F;&#x2F;这样的遍历写起来比较快
    &#123;
        &#x2F;&#x2F;将像素坐标变为相机下的归一化坐标
        pts_1.push_back(pixel2cam(keypoint_1[m.queryIdx].pt,K));
        pts_2.push_back(pixel2cam(keypoint_2[m.trainIdx].pt,K));
    &#125;
    Mat pts_4d;
    cv::triangulatePoints(T1,T2,pts_1,pts_2,pts_4d);
    &#x2F;*
    传入两个图像对应相机的变化矩阵，各自相机坐标系下归一化相机坐标，
    输出的3D坐标是齐次坐标，共四个维度，因此需要将前三个维度除以第四个维度以得到非齐次坐标xyz
    *&#x2F;
    &#x2F;&#x2F;转换为非齐次坐标
    for(int i&#x3D;0;i&lt;pts_4d.cols;i++)&#x2F;&#x2F;遍历所有的点，列数表述点的数量
    &#123;
        &#x2F;&#x2F;定义x来接收每一个三维点
        Mat x&#x3D;pts_4d.col(i); &#x2F;&#x2F;x为4x1维度
        x&#x2F;&#x3D;x.at&lt;float&gt;(3,0);&#x2F;&#x2F;归一化
        Point3d p(x.at&lt;float&gt;(0, 0),
                  x.at&lt;float&gt;(1, 0),
                  x.at&lt;float&gt;(2, 0));
        points.push_back(p);&#x2F;&#x2F;将图1测得的目标相对相机实际位置（Xc,Yc,Zc）存入points
    &#125;

&#125;
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p><img src="/pic/%E9%80%89%E5%8C%BA_135.png"></p>
<p><a target="_blank" rel="noopener" href="https://www.codenong.com/cs105088833/">对极约束和三角测量</a></p>
<h3 id="ch7-x2F-pose-estimation-3d2d-cpp"><a href="#ch7-x2F-pose-estimation-3d2d-cpp" class="headerlink" title="ch7&#x2F;pose_estimation_3d2d.cpp"></a>ch7&#x2F;pose_estimation_3d2d.cpp</h3><p>本程序使用Opencv的EPnP求解pnp问题，并手写了一个高斯牛顿法的PnP,然后调用g2o来求解</p>
<pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">&#x2F;&#x2F;
&#x2F;&#x2F; Created by nnz on 2020&#x2F;11&#x2F;5.
&#x2F;&#x2F;
&#x2F;&#x2F;
&#x2F;&#x2F; Created by nnz on 2020&#x2F;11&#x2F;4.
&#x2F;&#x2F;
#include &lt;iostream&gt;
#include &lt;opencv2&#x2F;core&#x2F;core.hpp&gt;
#include &lt;opencv2&#x2F;features2d&#x2F;features2d.hpp&gt;
#include &lt;opencv2&#x2F;highgui&#x2F;highgui.hpp&gt;
#include &lt;opencv2&#x2F;calib3d&#x2F;calib3d.hpp&gt;
#include &lt;Eigen&#x2F;Core&gt;
#include &lt;g2o&#x2F;core&#x2F;base_vertex.h&gt;
#include &lt;g2o&#x2F;core&#x2F;base_unary_edge.h&gt;
#include &lt;g2o&#x2F;core&#x2F;sparse_optimizer.h&gt;
#include &lt;g2o&#x2F;core&#x2F;block_solver.h&gt;
#include &lt;g2o&#x2F;core&#x2F;solver.h&gt;
#include &lt;g2o&#x2F;core&#x2F;optimization_algorithm_gauss_newton.h&gt;
#include &lt;g2o&#x2F;solvers&#x2F;dense&#x2F;linear_solver_dense.h&gt;
#include &lt;sophus&#x2F;se3.hpp&gt;
#include &lt;chrono&gt;
&#x2F;&#x2F;该程序用了三种方法实现位姿估计
&#x2F;&#x2F;第一种，调用cv的函数pnp求解 R ,t
&#x2F;&#x2F;第二种，手写高斯牛顿进行位姿优化
&#x2F;&#x2F;第三种，利用g2o进行位姿优化
using namespace std;
using namespace cv;

typedef vector&lt;Eigen::Vector2d, Eigen::aligned_allocator&lt;Eigen::Vector2d&gt;&gt; VecVector2d;&#x2F;&#x2F;VecVector2d可以定义存放二维向量的容器
typedef vector&lt;Eigen::Vector3d, Eigen::aligned_allocator&lt;Eigen::Vector3d&gt;&gt; VecVector3d;&#x2F;&#x2F;VecVector3d可以定义存放三维向量的容器

void find_feature_matches(
        const Mat &amp;img_1, const Mat &amp;img_2,
        std::vector&lt;KeyPoint&gt; &amp;keypoints_1,
        std::vector&lt;KeyPoint&gt; &amp;keypoints_2,
        std::vector&lt;DMatch&gt; &amp;matches);

&#x2F;&#x2F; 像素坐标转相机归一化坐标
Point2d pixel2cam(const Point2d &amp;p, const Mat &amp;K);

&#x2F;&#x2F; BA by gauss-newton 手写高斯牛顿进行位姿优化
void bundleAdjustmentGaussNewton(
        const VecVector3d &amp;points_3d,
        const VecVector2d &amp;points_2d,
        const Mat &amp;K,
        Sophus::SE3d &amp;pose
);

&#x2F;&#x2F;利用g2o优化pose
void bundleAdjustmentG2O(
        const VecVector3d &amp;points_3d,
        const VecVector2d &amp;points_2d,
        const Mat &amp;K,
        Sophus::SE3d &amp;pose);

int main(int argc ,char** argv)
&#123;


    &#x2F;&#x2F;读取图片
    if (argc !&#x3D; 5) &#123;
        cout &lt;&lt; &quot;usage: pose_estimation_3d2d img1 img2 depth1 depth2&quot; &lt;&lt; endl;
        return 1;
    &#125;
    &#x2F;&#x2F;读取图片
    Mat img_1&#x3D;imread(argv[1],CV_LOAD_IMAGE_COLOR);&#x2F;&#x2F;读取彩色图
    Mat img_2&#x3D;imread(argv[2],CV_LOAD_IMAGE_COLOR);
    assert(img_1.data &amp;&amp; img_2.data &amp;&amp; &quot;Can Not load images!&quot;);&#x2F;&#x2F;若读取的图片没有内容，就终止程序
    vector&lt;KeyPoint&gt; keypoints_1, keypoints_2;
    vector&lt;DMatch&gt; matches;
    find_feature_matches(img_1,img_2,keypoints_1,keypoints_2,matches);&#x2F;&#x2F;得到两个图片的特征匹配点
    cout &lt;&lt; &quot;一共找到了&quot; &lt;&lt; matches.size() &lt;&lt; &quot;组匹配点&quot; &lt;&lt; endl;



    &#x2F;&#x2F;建立3d点，把深度图信息读进来，构造三维点
    Mat d1 &#x3D; imread(argv[3], CV_LOAD_IMAGE_UNCHANGED);       &#x2F;&#x2F; 深度图为16位无符号数，单通道图像
    Mat K &#x3D; (Mat_&lt;double&gt;(3, 3) &lt;&lt; 520.9, 0, 325.1, 0, 521.0, 249.7, 0, 0, 1);
    vector&lt;Point3d&gt; pts_3d;&#x2F;&#x2F;创建容器pts_3d存放3d点（图1对应的特征点的相机坐标下的3d点）
    vector&lt;Point2d&gt; pts_2d;&#x2F;&#x2F;创建容器pts_2d存放图2的特征点
    for(DMatch m:matches)
    &#123;
        &#x2F;&#x2F;把对应的图1的特征点的深度信息拿出来
        ushort d &#x3D; d1.ptr&lt;unsigned short&gt;(int(keypoints_1[m.queryIdx].pt.y))[int(keypoints_1[m.queryIdx].pt.x)];
        if(d&#x3D;&#x3D;0) &#x2F;&#x2F;深度有问题
            continue;
        float dd&#x3D;d&#x2F;5000.0;&#x2F;&#x2F;用dd存放换算过尺度的深度信息
        Point2d p1&#x3D;pixel2cam(keypoints_1[m.queryIdx].pt,K);&#x2F;&#x2F;p1里面放的是图1特征点在相机坐标下的归一化坐标（只包含 x,y）
        pts_3d.push_back(Point3d(p1.x*dd,p1.y*dd,dd));&#x2F;&#x2F;得到图1特征点在相机坐标下的3d坐标
        pts_2d.push_back(keypoints_2[m.trainIdx].pt);&#x2F;&#x2F;得到图2特张点的像素坐标
    &#125;

    cout&lt;&lt;&quot;3d-2d pairs:&quot;&lt;&lt; pts_3d.size() &lt;&lt;endl;&#x2F;&#x2F;3d-2d配对个数得用pts_3d的size
    cout&lt;&lt;&quot;使用cv求解 位姿&quot;&lt;&lt;endl;
    cout&lt;&lt;&quot;***********************************opencv***********************************&quot;&lt;&lt;endl;
    chrono::steady_clock::time_point t1 &#x3D; chrono::steady_clock::now();
    Mat r, t;
    &#x2F;&#x2F;Mat()这个参数指的是畸变系数向量？
    solvePnP(pts_3d, pts_2d, K, Mat(), r, t, false); &#x2F;&#x2F; 调用OpenCV 的 PnP 求解，可选择EPNP，DLS等方法
    Mat R;
    cv::Rodrigues(r,R);&#x2F;&#x2F;r是旋转向量，利用cv的Rodrigues()函数将旋转向量转换为旋转矩阵

    chrono::steady_clock::time_point t2 &#x3D; chrono::steady_clock::now();
    chrono::duration&lt;double&gt; time_used &#x3D; chrono::duration_cast&lt;chrono::duration&lt;double&gt;&gt;(t2 - t1);
    cout &lt;&lt; &quot;solve pnp in opencv cost time: &quot; &lt;&lt; time_used.count() &lt;&lt; &quot; seconds.&quot; &lt;&lt; endl;

    cout &lt;&lt; &quot;R&#x3D;&quot; &lt;&lt; endl &lt;&lt; R &lt;&lt; endl;
    cout &lt;&lt; &quot;t&#x3D;&quot; &lt;&lt; endl &lt;&lt; t &lt;&lt; endl;
    cout&lt;&lt;&quot;***********************************opencv***********************************&quot;&lt;&lt;endl;
    cout&lt;&lt;&quot;手写高斯牛顿优化位姿&quot;&lt;&lt;endl;
    cout&lt;&lt;&quot;***********************************手写高斯牛顿***********************************&quot;&lt;&lt;endl;
    VecVector3d pts_3d_eigen;&#x2F;&#x2F;存放3d点（图1对应的特征点的相机坐标下的3d点）
    VecVector2d pts_2d_eigen;&#x2F;&#x2F;存放图2的特征点
    for(size_t i&#x3D;0;i&lt;pts_3d.size();i++)&#x2F;&#x2F;size_t
    &#123;
        pts_3d_eigen.push_back(Eigen::Vector3d(pts_3d[i].x,pts_3d[i].y,pts_3d[i].z));
        pts_2d_eigen.push_back(Eigen::Vector2d(pts_2d[i].x,pts_2d[i].y));
    &#125;
    Sophus::SE3d pose_gn;&#x2F;&#x2F;位姿（李群）
    t1 &#x3D; chrono::steady_clock::now();
    bundleAdjustmentGaussNewton(pts_3d_eigen, pts_2d_eigen, K, pose_gn);
    t2 &#x3D; chrono::steady_clock::now();
    time_used &#x3D; chrono::duration_cast&lt;chrono::duration&lt;double&gt;&gt;(t2 - t1);
    cout &lt;&lt; &quot;solve pnp by gauss newton cost time: &quot; &lt;&lt; time_used.count() &lt;&lt; &quot; seconds.&quot; &lt;&lt; endl;
    cout&lt;&lt;&quot;R &#x3D; \n&quot;&lt;&lt;pose_gn.rotationMatrix()&lt;&lt;endl;
    cout&lt;&lt;&quot;t &#x3D; &quot;&lt;&lt;pose_gn.translation().transpose()&lt;&lt;endl;
    cout&lt;&lt;&quot;***********************************手写高斯牛顿***********************************&quot;&lt;&lt;endl;

    cout&lt;&lt;&quot;g2o优化位姿&quot;&lt;&lt;endl;
    cout &lt;&lt; &quot;***********************************g2o***********************************&quot; &lt;&lt; endl;
    Sophus::SE3d pose_g2o;
    t1 &#x3D; chrono::steady_clock::now();
    bundleAdjustmentG2O(pts_3d_eigen, pts_2d_eigen, K, pose_g2o);
    t2 &#x3D; chrono::steady_clock::now();
    time_used &#x3D; chrono::duration_cast&lt;chrono::duration&lt;double&gt;&gt;(t2 - t1);
    cout &lt;&lt; &quot;solve pnp by g2o cost time: &quot; &lt;&lt; time_used.count() &lt;&lt; &quot; seconds.&quot; &lt;&lt; endl;
    cout &lt;&lt; &quot;***********************************g2o***********************************&quot; &lt;&lt; endl;
    return 0;

&#125;
&#x2F;&#x2F;实现特征匹配
void find_feature_matches(const Mat &amp;img_1, const Mat &amp;img_2,
                          std::vector&lt;KeyPoint&gt; &amp;keypoints_1,
                          std::vector&lt;KeyPoint&gt; &amp;keypoints_2,
                          std::vector&lt;DMatch&gt; &amp;matches) &#123;
    &#x2F;&#x2F;-- 初始化
    Mat descriptors_1, descriptors_2;
    &#x2F;&#x2F; used in OpenCV3
    Ptr&lt;FeatureDetector&gt; detector &#x3D; ORB::create();
    Ptr&lt;DescriptorExtractor&gt; descriptor &#x3D; ORB::create();
    &#x2F;&#x2F; use this if you are in OpenCV2
    &#x2F;&#x2F; Ptr&lt;FeatureDetector&gt; detector &#x3D; FeatureDetector::create ( &quot;ORB&quot; );
    &#x2F;&#x2F; Ptr&lt;DescriptorExtractor&gt; descriptor &#x3D; DescriptorExtractor::create ( &quot;ORB&quot; );
    Ptr&lt;DescriptorMatcher&gt; matcher &#x3D; DescriptorMatcher::create(&quot;BruteForce-Hamming&quot;);
    &#x2F;&#x2F;-- 第一步:检测 Oriented FAST 角点位置
    detector-&gt;detect(img_1, keypoints_1);
    detector-&gt;detect(img_2, keypoints_2);

    &#x2F;&#x2F;-- 第二步:根据角点位置计算 BRIEF 描述子
    descriptor-&gt;compute(img_1, keypoints_1, descriptors_1);
    descriptor-&gt;compute(img_2, keypoints_2, descriptors_2);

    &#x2F;&#x2F;-- 第三步:对两幅图像中的BRIEF描述子进行匹配，使用 Hamming 距离
    vector&lt;DMatch&gt; match;
    &#x2F;&#x2F; BFMatcher matcher ( NORM_HAMMING );
    matcher-&gt;match(descriptors_1, descriptors_2, match);

    &#x2F;&#x2F;-- 第四步:匹配点对筛选
    double min_dist &#x3D; 10000, max_dist &#x3D; 0;

    &#x2F;&#x2F;找出所有匹配之间的最小距离和最大距离, 即是最相似的和最不相似的两组点之间的距离
    for (int i &#x3D; 0; i &lt; descriptors_1.rows; i++) &#123;
        double dist &#x3D; match[i].distance;
        if (dist &lt; min_dist) min_dist &#x3D; dist;
        if (dist &gt; max_dist) max_dist &#x3D; dist;
    &#125;

    printf(&quot;-- Max dist : %f \n&quot;, max_dist);
    printf(&quot;-- Min dist : %f \n&quot;, min_dist);

    &#x2F;&#x2F;当描述子之间的距离大于两倍的最小距离时,即认为匹配有误.但有时候最小距离会非常小,设置一个经验值30作为下限.
    for (int i &#x3D; 0; i &lt; descriptors_1.rows; i++) &#123;
        if (match[i].distance &lt;&#x3D; max(2 * min_dist, 30.0)) &#123;
            matches.push_back(match[i]);
        &#125;
    &#125;
&#125;

&#x2F;&#x2F;实现像素坐标到相机坐标的转换（求出来的只是包含相机坐标下的x,y的二维点）
Point2d pixel2cam(const Point2d &amp;p, const Mat &amp;K) &#123;
    return Point2d
            (
                    (p.x - K.at&lt;double&gt;(0, 2)) &#x2F; K.at&lt;double&gt;(0, 0),
                    (p.y - K.at&lt;double&gt;(1, 2)) &#x2F; K.at&lt;double&gt;(1, 1)
            );
&#125;

&#x2F;&#x2F;手写高斯牛顿
void bundleAdjustmentGaussNewton(
        const VecVector3d &amp;points_3d,
        const VecVector2d &amp;points_2d,
        const Mat &amp;K,
        Sophus::SE3d &amp;pose
)
&#123;
    typedef Eigen::Matrix&lt;double,6,1&gt; Vector6d;
    const int iters&#x3D;10;&#x2F;&#x2F;迭代次数
    double cost&#x3D;0,lastcost&#x3D;0;&#x2F;&#x2F;代价函数（目标函数）
    &#x2F;&#x2F;拿出内参
    double fx &#x3D; K.at&lt;double&gt;(0, 0);
    double fy &#x3D; K.at&lt;double&gt;(1, 1);
    double cx &#x3D; K.at&lt;double&gt;(0, 2);
    double cy &#x3D; K.at&lt;double&gt;(1, 2);
    &#x2F;&#x2F;进入迭代
    for (int iter &#x3D; 0; iter &lt;iters ; iter++)
    &#123;
        Eigen::Matrix&lt;double,6,6&gt; H &#x3D; Eigen::Matrix&lt;double,6,6&gt;::Zero();&#x2F;&#x2F;初始化H矩阵
        Vector6d b &#x3D; Vector6d::Zero();&#x2F;&#x2F;对b矩阵初始化

        cost &#x3D; 0;
        &#x2F;&#x2F; 遍历所有的特征点  计算cost
        for(int i&#x3D;0;i&lt;points_3d.size();i++)
        &#123;
            Eigen::Vector3d pc&#x3D;pose*points_3d[i];&#x2F;&#x2F;利用待优化的pose得到图2的相机坐标下的3d点
            double inv_z&#x3D;1.0&#x2F;pc[2];&#x2F;&#x2F;得到图2的相机坐标下的3d点的z的倒数，也就是1&#x2F;z
            double inv_z2 &#x3D; inv_z * inv_z;&#x2F;&#x2F;(1&#x2F;z)^2
            &#x2F;&#x2F;定义投影
            Eigen::Vector2d proj(fx * pc[0] &#x2F; pc[2] + cx, fy * pc[1] &#x2F; pc[2] + cy);
            &#x2F;&#x2F;定义误差
            Eigen::Vector2d e&#x3D;points_2d[i]-proj;
            cost +&#x3D; e.squaredNorm();&#x2F;&#x2F;cost&#x3D;e*e
            &#x2F;&#x2F;定义雅克比矩阵J
            Eigen::Matrix&lt;double, 2, 6&gt; J;
            J &lt;&lt; -fx * inv_z,
                    0,
                    fx * pc[0] * inv_z2,
                    fx * pc[0] * pc[1] * inv_z2,
                    -fx - fx * pc[0] * pc[0] * inv_z2,
                    fx * pc[1] * inv_z,
                    0,
                    -fy * inv_z,
                    fy * pc[1] * inv_z2,
                    fy + fy * pc[1] * pc[1] * inv_z2,
                    -fy * pc[0] * pc[1] * inv_z2,
                    -fy * pc[0] * inv_z;

            H +&#x3D; J.transpose() * J;
            b +&#x3D; -J.transpose() * e;
        &#125;
        &#x2F;&#x2F;出了这个内循环，表述结束一次迭代的计算，接下来，要求pose了
        Vector6d dx;&#x2F;&#x2F;P129页 公式6.33 计算增量方程 Hdx&#x3D;b
        dx &#x3D; H.ldlt().solve(b);&#x2F;&#x2F;算出增量dx
        &#x2F;&#x2F;判断dx这个数是否有效
        if (isnan(dx[0]))
        &#123;
            cout &lt;&lt; &quot;result is nan!&quot; &lt;&lt; endl;
            break;
        &#125;
        &#x2F;&#x2F;如果我们进行了迭代，且最后的cost&gt;&#x3D;lastcost的话，那就表明满足要求了，可以停止迭代了
        if (iter &gt; 0 &amp;&amp; cost &gt;&#x3D; lastcost)
        &#123;
            &#x2F;&#x2F; cost increase, update is not good
            cout &lt;&lt; &quot;cost: &quot; &lt;&lt; cost &lt;&lt; &quot;, last cost: &quot; &lt;&lt; lastcost &lt;&lt; endl;
            break;
        &#125;
        &#x2F;&#x2F;优化pose 也就是用dx更新pose
        pose&#x3D;Sophus::SE3d::exp(dx) * pose;&#x2F;&#x2F;dx是李代数，要转换为李群
        lastcost&#x3D;cost;
        cout &lt;&lt; &quot;iteration &quot; &lt;&lt; iter &lt;&lt; &quot; cost&#x3D;&quot;&lt;&lt; std::setprecision(12) &lt;&lt; cost &lt;&lt; endl;
        &#x2F;&#x2F;std::setprecision(12)浮点数控制位数为12位
        &#x2F;&#x2F;如果误差特别小了，也结束迭代
        if (dx.norm() &lt; 1e-6)
        &#123;
            &#x2F;&#x2F; converge
            break;
        &#125;
    &#125;
    cout&lt;&lt;&quot;pose by g-n \n&quot;&lt;&lt;pose.matrix()&lt;&lt;endl;
&#125;

&#x2F;&#x2F;对于用g2o来进行优化的话，首先要定义顶点和边的模板
&#x2F;&#x2F;顶点，也就是咱们要优化的pose 用李代数表示它 6维
class Vertexpose: public g2o::BaseVertex&lt;6,Sophus::SE3d&gt;L
&#123;
public:
    EIGEN_MAKE_ALIGNED_OPERATOR_NEW;&#x2F;&#x2F;必须写，我也不知道为什么
    &#x2F;&#x2F;重载setToOriginImpl函数 这个应该就是把刚开的待优化的pose放进去
    virtual void setToOriginImpl() override
    &#123;
        _estimate &#x3D; Sophus::SE3d();
    &#125;
    &#x2F;&#x2F;重载oplusImpl函数，用来更新pose（待优化的系数）
    virtual void oplusImpl(const double *update) override
    &#123;
        Eigen::Matrix&lt;double,6,1&gt; update_eigen;&#x2F;&#x2F;更新的量，就是增量呗，dx
        update_eigen &lt;&lt; update[0], update[1], update[2], update[3], update[4], update[5];
        _estimate&#x3D;Sophus::SE3d::exp(update_eigen)* _estimate;&#x2F;&#x2F;更新pose 李代数要转换为李群，这样才可以左乘
    &#125;
    &#x2F;&#x2F;存盘 读盘 ：留空
    virtual bool read(istream &amp;in) override &#123;&#125;

    virtual bool write(ostream &amp;out) const override &#123;&#125;
&#125;;
&#x2F;&#x2F;定义边模板 边也就是误差，二维 并且把顶点也放进去
class EdgeProjection : public g2o::BaseUnaryEdge&lt;2,Eigen::Vector2d,Vertexpose&gt;
&#123;
public:
    EIGEN_MAKE_ALIGNED_OPERATOR_NEW;&#x2F;&#x2F;必须写，我也不知道为什么
    &#x2F;&#x2F;有参构造，初始化 图1中的3d点 以及相机内参K
    EdgeProjection(const Eigen::Vector3d &amp;pos, const Eigen::Matrix3d &amp;K) : _pos3d(pos),_K(K) &#123;&#125;
    &#x2F;&#x2F;计算误差
    virtual void computeError() override
    &#123;
        const Vertexpose *v&#x3D;static_cast&lt;const Vertexpose *&gt;(_vertices[0]);
        Sophus::SE3d T&#x3D;v-&gt;estimate();
        Eigen::Vector3d pos_pixel &#x3D; _K * (T * _pos3d);&#x2F;&#x2F;T * _pos3d是图2的相机坐标下的3d点
        pos_pixel &#x2F;&#x3D; pos_pixel[2];&#x2F;&#x2F;得到了像素坐标的齐次形式
        _error &#x3D; _measurement - pos_pixel.head&lt;2&gt;();
    &#125;
    &#x2F;&#x2F;计算雅克比矩阵
    virtual void linearizeOplus() override
    &#123;
        const Vertexpose *v &#x3D; static_cast&lt;Vertexpose *&gt; (_vertices[0]);
        Sophus::SE3d T &#x3D; v-&gt;estimate();
        Eigen::Vector3d pos_cam&#x3D;T*_pos3d;&#x2F;&#x2F;图2的相机坐标下的3d点
        double fx &#x3D; _K(0, 0);
        double fy &#x3D; _K(1, 1);
        double cx &#x3D; _K(0, 2);
        double cy &#x3D; _K(1, 2);
        double X &#x3D; pos_cam[0];
        double Y &#x3D; pos_cam[1];
        double Z &#x3D; pos_cam[2];
        double Z2 &#x3D; Z * Z;
        &#x2F;&#x2F;雅克比矩阵见 书 p187 公式7.46
        _jacobianOplusXi
                &lt;&lt; -fx &#x2F; Z, 0, fx * X &#x2F; Z2, fx * X * Y &#x2F; Z2, -fx - fx * X * X &#x2F; Z2, fx * Y &#x2F; Z,
                0, -fy &#x2F; Z, fy * Y &#x2F; (Z * Z), fy + fy * Y * Y &#x2F; Z2, -fy * X * Y &#x2F; Z2, -fy * X &#x2F; Z;


    &#125;
    &#x2F;&#x2F;存盘 读盘 ：留空
    virtual bool read(istream &amp;in) override &#123;&#125;

    virtual bool write(ostream &amp;out) const override &#123;&#125;
private:
    Eigen::Vector3d _pos3d;
    Eigen::Matrix3d _K;
&#125;;


&#x2F;&#x2F;利用g2o优化pose
void bundleAdjustmentG2O(
        const VecVector3d &amp;points_3d,
        const VecVector2d &amp;points_2d,
        const Mat &amp;K,
        Sophus::SE3d &amp;pose)
&#123;
    &#x2F;&#x2F; 构建图优化，先设定g2o
    typedef g2o::BlockSolver&lt;g2o::BlockSolverTraits&lt;6, 3&gt;&gt; BlockSolverType;  &#x2F;&#x2F;  优化系数pose is 6, 数据点 landmark is 3
    typedef g2o::LinearSolverDense&lt;BlockSolverType::PoseMatrixType&gt; LinearSolverType; &#x2F;&#x2F; 线性求解器类型
    &#x2F;&#x2F; 梯度下降方法，可以从GN, LM, DogLeg 中选
    auto solver &#x3D; new g2o::OptimizationAlgorithmGaussNewton(
            g2o::make_unique&lt;BlockSolverType&gt;
                    (g2o::make_unique&lt;LinearSolverType&gt;()));&#x2F;&#x2F;把设定的类型都放进求解器

    g2o::SparseOptimizer optimizer;     &#x2F;&#x2F; 图模型
    optimizer.setAlgorithm(solver);   &#x2F;&#x2F; 设置求解器 算法g-n
    optimizer.setVerbose(true);       &#x2F;&#x2F; 打开调试输出
    &#x2F;&#x2F;加入顶点
    Vertexpose *v&#x3D;new Vertexpose();
    v-&gt;setEstimate(Sophus::SE3d());
    v-&gt;setId(0);
    optimizer.addVertex(v);
    &#x2F;&#x2F;K
    &#x2F;&#x2F; K
    Eigen::Matrix3d K_eigen;
    K_eigen &lt;&lt;
            K.at&lt;double&gt;(0, 0), K.at&lt;double&gt;(0, 1), K.at&lt;double&gt;(0, 2),
            K.at&lt;double&gt;(1, 0), K.at&lt;double&gt;(1, 1), K.at&lt;double&gt;(1, 2),
            K.at&lt;double&gt;(2, 0), K.at&lt;double&gt;(2, 1), K.at&lt;double&gt;(2, 2);

    &#x2F;&#x2F;加入边
    int index&#x3D;1;
    for(size_t i&#x3D;0;i&lt;points_2d.size();++i)
    &#123;
        &#x2F;&#x2F;遍历 把3d点和像素点拿出来
        auto p2d &#x3D; points_2d[i];
        auto p3d &#x3D; points_3d[i];
        EdgeProjection *edge &#x3D; new EdgeProjection(p3d, K_eigen);&#x2F;&#x2F;有参构造
        edge-&gt;setId(index);
        edge-&gt;setVertex(0,v);
        edge-&gt;setMeasurement(p2d);&#x2F;&#x2F;设置观测值，其实就是图2 里的匹配特征点的像素位置
        edge-&gt;setInformation(Eigen::Matrix2d::Identity());&#x2F;&#x2F;信息矩阵是二维方阵，因为误差是二维
        optimizer.addEdge(edge);&#x2F;&#x2F;加入边
        index++;&#x2F;&#x2F;边的编号++
    &#125;
    chrono::steady_clock::time_point t1 &#x3D; chrono::steady_clock::now();
    optimizer.setVerbose(true);
    optimizer.initializeOptimization();&#x2F;&#x2F;开始  初始化
    optimizer.optimize(10);&#x2F;&#x2F;迭代次数
    chrono::steady_clock::time_point t2 &#x3D; chrono::steady_clock::now();
    chrono::duration&lt;double&gt; time_used &#x3D; chrono::duration_cast&lt;chrono::duration&lt;double&gt;&gt;(t2 - t1);
    cout &lt;&lt; &quot;optimization costs time: &quot; &lt;&lt; time_used.count() &lt;&lt; &quot; seconds.&quot; &lt;&lt; endl;
    cout &lt;&lt; &quot;pose estimated by g2o &#x3D;\n&quot; &lt;&lt; v-&gt;estimate().matrix() &lt;&lt; endl;
    pose &#x3D; v-&gt;estimate();

&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/joun772/article/details/109466153?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_baidulandingword~default-12-109466153-blog-116243451.235%5Ev28%5Epc_relevant_recovery_v2&spm=1001.2101.3001.4242.7&utm_relevant_index=15">SLAM十四讲-ch7(2)-位姿估计(包含2d-2d、3d-2d、3d-3d、以及三角化实现代码的注释)</a></p>
<h3 id="ch7-x2F-pose-estimation-3d3d-cpp"><a href="#ch7-x2F-pose-estimation-3d3d-cpp" class="headerlink" title="ch7&#x2F;pose_estimation_3d3d.cpp"></a>ch7&#x2F;pose_estimation_3d3d.cpp</h3><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">&#x2F;&#x2F;
&#x2F;&#x2F; Created by nnz on 2020&#x2F;11&#x2F;5.
&#x2F;&#x2F;
#include &lt;iostream&gt;
#include &lt;opencv2&#x2F;core&#x2F;core.hpp&gt;
#include &lt;opencv2&#x2F;features2d&#x2F;features2d.hpp&gt;
#include &lt;opencv2&#x2F;highgui&#x2F;highgui.hpp&gt;
#include &lt;opencv2&#x2F;calib3d&#x2F;calib3d.hpp&gt;
#include &lt;Eigen&#x2F;Core&gt;
#include &lt;g2o&#x2F;core&#x2F;base_vertex.h&gt;
#include &lt;g2o&#x2F;core&#x2F;base_unary_edge.h&gt;
#include &lt;g2o&#x2F;core&#x2F;sparse_optimizer.h&gt;
#include &lt;g2o&#x2F;core&#x2F;block_solver.h&gt;
#include &lt;g2o&#x2F;core&#x2F;solver.h&gt;
#include &lt;g2o&#x2F;core&#x2F;optimization_algorithm_gauss_newton.h&gt;
#include &lt;g2o&#x2F;solvers&#x2F;dense&#x2F;linear_solver_dense.h&gt;
#include &lt;sophus&#x2F;se3.hpp&gt;
#include &lt;chrono&gt;
using namespace std;
using namespace cv;

void find_feature_matches(
        const Mat &amp;img_1, const Mat &amp;img_2,
        std::vector&lt;KeyPoint&gt; &amp;keypoints_1,
        std::vector&lt;KeyPoint&gt; &amp;keypoints_2,
        std::vector&lt;DMatch&gt; &amp;matches);

&#x2F;&#x2F; 像素坐标转相机归一化坐标
Point2d pixel2cam(const Point2d &amp;p, const Mat &amp;K);

void pose_estimation_3d3d(
        const vector&lt;Point3f&gt; &amp;pts1,
        const vector&lt;Point3f&gt; &amp;pts2,
        Mat &amp;R, Mat &amp;t
);

&#x2F;&#x2F;
void bundleAdjustment(
        const vector&lt;Point3f&gt; &amp;pts1,
        const vector&lt;Point3f&gt; &amp;pts2,
        Mat &amp;R, Mat &amp;t);
int main(int argc,char** argv)
&#123;
    if(argc!&#x3D;5)
    &#123;
        cout&lt;&lt;&quot; usage: pose_estimation_3d3d img1 img2 depth1 depth2 &quot;&lt;&lt;endl;
        return 1;
    &#125;
    &#x2F;&#x2F;读取图片
    Mat img_1&#x3D;imread(argv[1],CV_LOAD_IMAGE_COLOR);&#x2F;&#x2F;读取彩色图
    Mat img_2&#x3D;imread(argv[2],CV_LOAD_IMAGE_COLOR);
    vector&lt;KeyPoint&gt; keypoints_1, keypoints_2;&#x2F;&#x2F;容器keypoints_1, keypoints_2分别存放图1和图2的特征点
    vector&lt;DMatch&gt; matches;
    find_feature_matches(img_1, img_2, keypoints_1, keypoints_2, matches);&#x2F;&#x2F;得到图1与图2的特征匹配点
    cout &lt;&lt; &quot;一共找到了&quot; &lt;&lt; matches.size() &lt;&lt; &quot;组匹配点&quot; &lt;&lt; endl;
    &#x2F;&#x2F;接下来的是建立3d点 利用深度图可以获取深度信息
    &#x2F;&#x2F;depth1是图1对应的深度图 depth2是图2对应的深度图
    Mat depth1 &#x3D; imread(argv[3], CV_LOAD_IMAGE_UNCHANGED);       &#x2F;&#x2F; 深度图为16位无符号数，单通道图像
    Mat depth2 &#x3D; imread(argv[4], CV_LOAD_IMAGE_UNCHANGED);

    &#x2F;&#x2F;内参矩阵
    Mat K &#x3D;(Mat_&lt;double&gt;(3, 3) &lt;&lt; 520.9, 0, 325.1, 0, 521.0, 249.7, 0, 0, 1);
    vector&lt;Point3f&gt; pts1, pts2;

    for(DMatch m:matches)
    &#123;
        &#x2F;&#x2F;先把两图特征匹配点对应的深度拿出来
        ushort d1&#x3D;depth1.ptr&lt;unsigned short &gt;(int(keypoints_1[m.queryIdx].pt.y))[int(keypoints_1[m.queryIdx].pt.x)];
        ushort d2&#x3D;depth2.ptr&lt;unsigned short &gt;(int(keypoints_2[m.trainIdx].pt.y))[int(keypoints_2[m.trainIdx].pt.x)];
        if(d1&#x3D;&#x3D;0 || d2&#x3D;&#x3D;0)&#x2F;&#x2F;深度无效
            continue;
        Point2d p1&#x3D;pixel2cam(keypoints_1[m.queryIdx].pt,K);&#x2F;&#x2F;得到图1的特征匹配点在其相机坐标下的x ,y
        Point2d p2&#x3D;pixel2cam(keypoints_2[m.trainIdx].pt,K);&#x2F;&#x2F;得到图2的特征匹配点在其相机坐标下的x ,y
        &#x2F;&#x2F;对深度进行尺度变化得到真正的深度
        float dd1 &#x3D; float(d1) &#x2F; 5000.0;
        float dd2 &#x3D; float(d2) &#x2F; 5000.0;
        &#x2F;&#x2F;容器 pts_1与pts_2分别存放 图1中的特征匹配点其相机坐标下的3d点 和 图2中的特征匹配点其相机坐标下的3d点
        pts1.push_back(Point3f(p1.x * dd1, p1.y * dd1, dd1));
        pts2.push_back(Point3f(p2.x * dd2, p2.y * dd2, dd2));
    &#125;
    &#x2F;&#x2F;这样就可以得到 3d-3d的匹配点
    cout &lt;&lt; &quot;3d-3d pairs: &quot; &lt;&lt; pts1.size() &lt;&lt; endl;
    Mat R, t;
    cout&lt;&lt;&quot; ************************************ICP 3d-3d by SVD**************************************** &quot;&lt;&lt;endl;
    pose_estimation_3d3d(pts1, pts2, R, t);
    cout &lt;&lt; &quot;ICP via SVD results: &quot; &lt;&lt; endl;
    cout &lt;&lt; &quot;R &#x3D; &quot; &lt;&lt; R &lt;&lt; endl;
    cout &lt;&lt; &quot;t &#x3D; &quot; &lt;&lt; t &lt;&lt; endl;
    cout &lt;&lt; &quot;R^T &#x3D; &quot; &lt;&lt; R.t() &lt;&lt; endl;
    cout &lt;&lt; &quot;t^T &#x3D; &quot; &lt;&lt; -R.t() * t &lt;&lt; endl;
    cout&lt;&lt;&quot; ************************************ICP 3d-3d by SVD**************************************** &quot;&lt;&lt;endl;
    cout&lt;&lt;endl;
    cout&lt;&lt;&quot; ************************************ICP 3d-3d by g2o**************************************** &quot;&lt;&lt;endl;
    bundleAdjustment(pts1, pts2, R, t);
    cout&lt;&lt;&quot;R&#x3D; \n&quot;&lt;&lt;R&lt;&lt;endl;
    cout&lt;&lt;&quot;t &#x3D; &quot;&lt;&lt; t.t() &lt;&lt;endl;
    cout&lt;&lt;&quot;验证 p2 &#x3D; R*P1 +t &quot;&lt;&lt;endl;
    for (int i &#x3D; 0; i &lt; 5; i++) &#123;
        cout &lt;&lt; &quot;p1 &#x3D; &quot; &lt;&lt; pts1[i] &lt;&lt; endl;
        cout &lt;&lt; &quot;p2 &#x3D; &quot; &lt;&lt; pts2[i] &lt;&lt; endl;
        cout &lt;&lt; &quot;(R*p1+t) &#x3D; &quot; &lt;&lt;
             R * (Mat_&lt;double&gt;(3, 1) &lt;&lt; pts1[i].x, pts1[i].y, pts1[i].z) + t
             &lt;&lt; endl;
        cout &lt;&lt; endl;
    &#125;
    cout&lt;&lt;&quot; ************************************ICP 3d-3d by g2o**************************************** &quot;&lt;&lt;endl;

    return 0;
&#125;

void find_feature_matches(const Mat &amp;img_1, const Mat &amp;img_2,
                          std::vector&lt;KeyPoint&gt; &amp;keypoints_1,
                          std::vector&lt;KeyPoint&gt; &amp;keypoints_2,
                          std::vector&lt;DMatch&gt; &amp;matches) &#123;
    &#x2F;&#x2F;-- 初始化
    Mat descriptors_1, descriptors_2;
    &#x2F;&#x2F; used in OpenCV3
    Ptr&lt;FeatureDetector&gt; detector &#x3D; ORB::create();
    Ptr&lt;DescriptorExtractor&gt; descriptor &#x3D; ORB::create();
    &#x2F;&#x2F; use this if you are in OpenCV2
    &#x2F;&#x2F; Ptr&lt;FeatureDetector&gt; detector &#x3D; FeatureDetector::create ( &quot;ORB&quot; );
    &#x2F;&#x2F; Ptr&lt;DescriptorExtractor&gt; descriptor &#x3D; DescriptorExtractor::create ( &quot;ORB&quot; );
    Ptr&lt;DescriptorMatcher&gt; matcher &#x3D; DescriptorMatcher::create(&quot;BruteForce-Hamming&quot;);
    &#x2F;&#x2F;-- 第一步:检测 Oriented FAST 角点位置
    detector-&gt;detect(img_1, keypoints_1);
    detector-&gt;detect(img_2, keypoints_2);

    &#x2F;&#x2F;-- 第二步:根据角点位置计算 BRIEF 描述子
    descriptor-&gt;compute(img_1, keypoints_1, descriptors_1);
    descriptor-&gt;compute(img_2, keypoints_2, descriptors_2);

    &#x2F;&#x2F;-- 第三步:对两幅图像中的BRIEF描述子进行匹配，使用 Hamming 距离
    vector&lt;DMatch&gt; match;
    &#x2F;&#x2F; BFMatcher matcher ( NORM_HAMMING );
    matcher-&gt;match(descriptors_1, descriptors_2, match);

    &#x2F;&#x2F;-- 第四步:匹配点对筛选
    double min_dist &#x3D; 10000, max_dist &#x3D; 0;

    &#x2F;&#x2F;找出所有匹配之间的最小距离和最大距离, 即是最相似的和最不相似的两组点之间的距离
    for (int i &#x3D; 0; i &lt; descriptors_1.rows; i++) &#123;
        double dist &#x3D; match[i].distance;
        if (dist &lt; min_dist) min_dist &#x3D; dist;
        if (dist &gt; max_dist) max_dist &#x3D; dist;
    &#125;

    printf(&quot;-- Max dist : %f \n&quot;, max_dist);
    printf(&quot;-- Min dist : %f \n&quot;, min_dist);

    &#x2F;&#x2F;当描述子之间的距离大于两倍的最小距离时,即认为匹配有误.但有时候最小距离会非常小,设置一个经验值30作为下限.
    for (int i &#x3D; 0; i &lt; descriptors_1.rows; i++) &#123;
        if (match[i].distance &lt;&#x3D; max(2 * min_dist, 30.0)) &#123;
            matches.push_back(match[i]);
        &#125;
    &#125;
&#125;

&#x2F;&#x2F;实现像素坐标到相机坐标的转换（求出来的只是包含相机坐标下的x,y的二维点）
Point2d pixel2cam(const Point2d &amp;p, const Mat &amp;K) &#123;
    return Point2d
            (
                    (p.x - K.at&lt;double&gt;(0, 2)) &#x2F; K.at&lt;double&gt;(0, 0),
                    (p.y - K.at&lt;double&gt;(1, 2)) &#x2F; K.at&lt;double&gt;(1, 1)
            );
&#125;

&#x2F;&#x2F;参考书上的p197页
void pose_estimation_3d3d(
        const vector&lt;Point3f&gt; &amp;pts1,
        const vector&lt;Point3f&gt; &amp;pts2,
        Mat &amp;R, Mat &amp;t
)
&#123;
    int N&#x3D;pts1.size();&#x2F;&#x2F;匹配的3d点个数
    Point3f p1,p2;&#x2F;&#x2F;质心
    for(int i&#x3D;0;i&lt;N;i++)
    &#123;
        p1+&#x3D;pts1[i];
        p2+&#x3D;pts2[i];
    &#125;
    p1 &#x3D; Point3f(Vec3f(p1)&#x2F;N);&#x2F;&#x2F;得到质心
    p2 &#x3D; Point3f(Vec3f(p2) &#x2F; N);
    vector&lt;Point3f&gt; q1(N),q2(N);
    for(int i&#x3D;0;i&lt;N;i++)
    &#123;
        &#x2F;&#x2F;去质心
        q1[i]&#x3D;pts1[i]-p1;
        q2[i]&#x3D;pts2[i]-p2;
    &#125;
    &#x2F;&#x2F;计算 W+&#x3D;q1*q2^T(求和)
    Eigen::Matrix3d W&#x3D;Eigen::Matrix3d::Zero();&#x2F;&#x2F;初始化
    for(int i&#x3D;0;i&lt;N;i++)
    &#123;
        W+&#x3D; Eigen::Vector3d (q1[i].x,q1[i].y,q1[i].z)*(Eigen::Vector3d (q2[i].x,q2[i].y,q2[i].z).transpose());
    &#125;
    cout&lt;&lt;&quot;W &#x3D; &quot;&lt;&lt;endl&lt;&lt;W&lt;&lt;endl;
    &#x2F;&#x2F;利用svd分解 W&#x3D;U*sigema*V
    Eigen::JacobiSVD&lt;Eigen::Matrix3d&gt; svd(W,Eigen::ComputeFullU | Eigen::ComputeFullV);
    Eigen::Matrix3d U&#x3D;svd.matrixU();&#x2F;&#x2F;得到U矩阵
    Eigen::Matrix3d V&#x3D;svd.matrixV();&#x2F;&#x2F;得到V矩阵
    cout &lt;&lt; &quot;U&#x3D;&quot; &lt;&lt; U &lt;&lt; endl;
    cout &lt;&lt; &quot;V&#x3D;&quot; &lt;&lt; V &lt;&lt; endl;
    Eigen::Matrix3d R_&#x3D;U*(V.transpose());
    if (R_.determinant() &lt; 0)&#x2F;&#x2F;若旋转矩阵R_的行列式&lt;0 则取负号
    &#123;
        R_ &#x3D; -R_;
    &#125;
    Eigen::Vector3d t_&#x3D;Eigen::Vector3d (p1.x,p1.y,p1.z)-R_*Eigen::Vector3d (p2.x,p2.y,p2.z);&#x2F;&#x2F;得到平移向量
    &#x2F;&#x2F;把 Eigen形式的 r 和 t_ 转换为CV 中的Mat格式
    R &#x3D; (Mat_&lt;double&gt;(3, 3) &lt;&lt;
                            R_(0, 0), R_(0, 1), R_(0, 2),
            R_(1, 0), R_(1, 1), R_(1, 2),
            R_(2, 0), R_(2, 1), R_(2, 2)
    );
    t &#x3D; (Mat_&lt;double&gt;(3, 1) &lt;&lt; t_(0, 0), t_(1, 0), t_(2, 0));
&#125;

&#x2F;&#x2F;对于用g2o来进行优化的话，首先要定义顶点和边的模板
&#x2F;&#x2F;顶点，也就是咱们要优化的pose 用李代数表示它 6维
class Vertexpose: public g2o::BaseVertex&lt;6,Sophus::SE3d&gt;
&#123;
public:
    EIGEN_MAKE_ALIGNED_OPERATOR_NEW;&#x2F;&#x2F;必须写，我也不知道为什么
    &#x2F;&#x2F;重载setToOriginImpl函数 这个应该就是把刚开的待优化的pose放进去
    virtual void setToOriginImpl() override
    &#123;
        _estimate &#x3D; Sophus::SE3d();
    &#125;
    &#x2F;&#x2F;重载oplusImpl函数，用来更新pose（待优化的系数）
    virtual void oplusImpl(const double *update) override
    &#123;
        Eigen::Matrix&lt;double,6,1&gt; update_eigen;&#x2F;&#x2F;更新的量，就是增量呗，dx
        update_eigen &lt;&lt; update[0], update[1], update[2], update[3], update[4], update[5];
        _estimate&#x3D;Sophus::SE3d::exp(update_eigen)* _estimate;&#x2F;&#x2F;更新pose 李代数要转换为李群，这样才可以左乘
    &#125;
    &#x2F;&#x2F;存盘 读盘 ：留空
    virtual bool read(istream &amp;in) override &#123;&#125;

    virtual bool write(ostream &amp;out) const override &#123;&#125;
&#125;;
&#x2F;&#x2F;定义边
class EdgeProjectXYZRGBD: public g2o::BaseUnaryEdge&lt;3,Eigen::Vector3d,Vertexpose&gt;
&#123;
public:
    EdgeProjectXYZRGBD(const Eigen::Vector3d &amp;point) : _point(point) &#123;&#125;&#x2F;&#x2F;赋值这个是图1坐标下的3d点
    &#x2F;&#x2F;计算误差
    virtual void computeError() override
    &#123;
        const Vertexpose *v&#x3D;static_cast&lt;const Vertexpose *&gt;(_vertices[0]);&#x2F;&#x2F;顶点v
        _error &#x3D; _measurement - v-&gt;estimate() * _point;


    &#125;
    &#x2F;&#x2F;计算雅克比
    virtual void linearizeOplus() override
    &#123;
        const Vertexpose *v&#x3D;static_cast&lt;const Vertexpose *&gt;(_vertices[0]);&#x2F;&#x2F;顶点v
        Sophus::SE3d T&#x3D;v-&gt;estimate();&#x2F;&#x2F;把顶点的待优化系数拿出来
        Eigen::Vector3d xyz_trans&#x3D;T*_point;&#x2F;&#x2F;变换到图2下的坐标点
        &#x2F;&#x2F;下面的雅克比没看懂
        _jacobianOplusXi.block&lt;3, 3&gt;(0, 0) &#x3D; -Eigen::Matrix3d::Identity();
        _jacobianOplusXi.block&lt;3, 3&gt;(0, 3) &#x3D; Sophus::SO3d::hat(xyz_trans);

    &#125;

    bool read(istream &amp;in) &#123;&#125;

    bool write(ostream &amp;out) const &#123;&#125;
protected:
    Eigen::Vector3d _point;
&#125;;
&#x2F;&#x2F;利用g2o
void bundleAdjustment(const vector&lt;Point3f&gt; &amp;pts1,
                      const vector&lt;Point3f&gt; &amp;pts2,
                      Mat &amp;R, Mat &amp;t)
&#123;
&#x2F;&#x2F; 构建图优化，先设定g2o
    typedef g2o::BlockSolver&lt;g2o::BlockSolverTraits&lt;6, 3&gt;&gt; BlockSolverType;  &#x2F;&#x2F;  优化系数pose is 6, 数据点 landmark is 3
    typedef g2o::LinearSolverDense&lt;BlockSolverType::PoseMatrixType&gt; LinearSolverType; &#x2F;&#x2F; 线性求解器类型
    &#x2F;&#x2F; 梯度下降方法，可以从GN, LM, DogLeg 中选
    auto solver &#x3D; new g2o::OptimizationAlgorithmGaussNewton(
            g2o::make_unique&lt;BlockSolverType&gt;
                    (g2o::make_unique&lt;LinearSolverType&gt;()));&#x2F;&#x2F;把设定的类型都放进求解器
    g2o::SparseOptimizer optimizer;     &#x2F;&#x2F; 图模型
    optimizer.setAlgorithm(solver);   &#x2F;&#x2F; 设置求解器 算法g-n
    optimizer.setVerbose(true);       &#x2F;&#x2F; 打开调试输出
    &#x2F;&#x2F;加入顶点
    Vertexpose *v&#x3D;new Vertexpose();
    v-&gt;setEstimate(Sophus::SE3d());
    v-&gt;setId(0);
    optimizer.addVertex(v);

    &#x2F;&#x2F;加入边
    int index&#x3D;1;
    for(size_t i&#x3D;0;i&lt;pts1.size();i++)
    &#123;
        EdgeProjectXYZRGBD *edge &#x3D; new EdgeProjectXYZRGBD(Eigen::Vector3d(pts1[i].x,pts1[i].y,pts1[i].z));
        edge-&gt;setId(index);&#x2F;&#x2F;边的编号
        edge-&gt;setVertex(0,v);&#x2F;&#x2F;设置顶点  顶点编号
        edge-&gt;setMeasurement(Eigen::Vector3d(pts2[i].x,pts2[i].y,pts2[i].z));
        edge-&gt;setInformation(Eigen::Matrix3d::Identity());&#x2F;&#x2F;set信息矩阵为单位矩阵
        optimizer.addEdge(edge);&#x2F;&#x2F;加入边
        index++;
    &#125;
    chrono::steady_clock::time_point t1 &#x3D; chrono::steady_clock::now();
    optimizer.initializeOptimization();&#x2F;&#x2F;开始
    optimizer.optimize(10);&#x2F;&#x2F;迭代次数
    chrono::steady_clock::time_point t2 &#x3D; chrono::steady_clock::now();
    chrono::duration&lt;double&gt; time_used &#x3D; chrono::duration_cast&lt;chrono::duration&lt;double&gt;&gt;(t2 - t1);
    cout &lt;&lt; &quot;optimization costs time: &quot; &lt;&lt; time_used.count() &lt;&lt; &quot; seconds.&quot; &lt;&lt; endl;

    cout &lt;&lt; endl &lt;&lt; &quot;after optimization:&quot; &lt;&lt; endl;
    cout &lt;&lt; &quot;T&#x3D;\n&quot; &lt;&lt; v-&gt;estimate().matrix() &lt;&lt; endl;

    &#x2F;&#x2F; 把位姿转换为Mat类型
    Eigen::Matrix3d R_ &#x3D; v-&gt;estimate().rotationMatrix();
    Eigen::Vector3d t_ &#x3D; v-&gt;estimate().translation();
    R &#x3D; (Mat_&lt;double&gt;(3, 3) &lt;&lt;
                            R_(0, 0), R_(0, 1), R_(0, 2),
            R_(1, 0), R_(1, 1), R_(1, 2),
            R_(2, 0), R_(2, 1), R_(2, 2)
    );
    t &#x3D; (Mat_&lt;double&gt;(3, 1) &lt;&lt; t_(0, 0), t_(1, 0), t_(2, 0));
&#125;
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/joun772/article/details/109466153?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_baidulandingword~default-12-109466153-blog-116243451.235%5Ev28%5Epc_relevant_recovery_v2&spm=1001.2101.3001.4242.7&utm_relevant_index=15">SLAM十四讲-ch7(2)-位姿估计(包含2d-2d、3d-2d、3d-3d、以及三角化实现代码的注释)</a></p>
<h2 id="第八讲"><a href="#第八讲" class="headerlink" title="第八讲"></a>第八讲</h2><p>直接法是vo的另一个主要的分支，它与特征点法有很大的不同，理解光流法跟踪特征点的原理，理解直接法估计相机位姿，实现多层直接法的计算</p>
<h3 id="ch8-x2F-optical-flow-cpp"><a href="#ch8-x2F-optical-flow-cpp" class="headerlink" title="ch8&#x2F;optical_flow.cpp"></a>ch8&#x2F;optical_flow.cpp</h3><p>光流是一种描述像素随时间在图像之间运动的方法：</p>
<p>光流法有两个假设：（1）灰度不变假设：同一个空间点的像素灰度值，在各个图像中是固定不变的；（2）假设某个窗口内的像素具有相同的运动</p>
<p>一、本讲的代码使用了三种方法来追踪图像上的特征点</p>
<ul>
<li>第一种：使用OpenCV中的LK光流；</li>
<li>第二种：用高斯牛顿实现光流：单层光流；</li>
<li>第三种：用高斯牛顿实现光流：多层光流。</li>
</ul>
<p>其中高斯牛顿法，即最小化灰度误差估计最优的像素偏移。在具体函数实现中（即calculateOpticalFlow)，求解这样一个问题：</p>
<p><img src="/pic/%E9%80%89%E5%8C%BA_136.png"></p>
<p><strong>Opencv中的LK光流</strong>：使用  cv::calculateOpticalFlowPyrLK函数：</p>
<ul>
<li>提供前后两张图像及对应的特征点，即可得到追踪后的点，以及各点的状态、误差;</li>
<li>根据status变量是否为1来确定对应的点是否被正确追踪到。</li>
<li>cv::calcOpticalFlowPyrLK(img1,img2,pt1,pt2,status,error);</li>
</ul>
<p><strong>单层光流</strong>：用高斯牛顿法实现光流，光流也可以看成一个优化问题，通过最小化灰度误差估计最优的像素偏移</p>
<p><strong>多层光流</strong>：因为单层光流在相机运动较快的情况下，容易达到一个局部极小值，因此引入图像金字塔。当原始图像的像素运动较大时，在金字塔顶层看来，运动仍然是一个小的运动范围</p>
<p>二、代码注释</p>
<pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">#include&lt;opencv2&#x2F;opencv.hpp&gt;
#include&lt;string&gt;
#include&lt;chrono&gt;
#include&lt;Eigen&#x2F;Core&gt;
#include&lt;Eigen&#x2F;Dense&gt;

using namespace std;
using namespace cv;
string file_1&#x3D;&quot;.&#x2F;LK1.png&quot;;   &#x2F;&#x2F;第一张图像的路径,可能需要写成绝对路径
string file_2&#x3D;&quot;.&#x2F;LK2.png&quot;;  &#x2F;&#x2F;第二张图像的路径
  
&#x2F;&#x2F;使用高斯牛顿法实现光流
&#x2F;&#x2F;定义一个光流追踪类
class OpticalFlowTracker
&#123;
 public:
    OpticalFlowTracker(    &#x2F;&#x2F;带参构造函数，并初始化
      const Mat &amp;img1_,
      const Mat &amp;img2_,
      const vector&lt;KeyPoint&gt;&amp;kp1_,
      vector&lt;KeyPoint&gt;&amp;kp2_,
      vector&lt;bool&gt;&amp;success_,
      bool inverse_&#x3D;true,bool has_initial_&#x3D;false):
      img1(img1_),img2(img2_),kp1(kp1_),kp2(kp2_),success(success_),inverse(inverse_),
      has_initial(has_initial_) &#123;&#125;
      
      &#x2F;&#x2F;计算光流的函数
      void calculateOpticalFlow(const Range &amp;range);  &#x2F;&#x2F;range是一个区间，应该看作一个窗口
      
  private:
    const Mat &amp;img1;
    const Mat &amp;img2;
    const vector&lt;KeyPoint&gt; &amp;kp1;
    vector&lt;KeyPoint&gt; &amp;kp2;
    vector&lt;bool&gt; &amp;success;
    bool inverse&#x3D;true;
    bool has_initial&#x3D;false;
  &#125;;
  &#x2F;&#x2F;单层光流的函数声明
  void OpticalFlowSingleLevel(
    const Mat &amp;img1,
    const Mat &amp;img2,
    const vector&lt;KeyPoint&gt;&amp;kp1,
    vector&lt;KeyPoint&gt;&amp;kp2,
    vector&lt;bool&gt;&amp;success,
    bool inverse&#x3D;false,
    bool has_initial_guess&#x3D;false
  );
  &#x2F;&#x2F;多层光流的函数声明
  void OpticalFlowMultiLevel(
    const Mat &amp;img1,
    const Mat &amp;img2,
    const vector&lt;KeyPoint&gt;&amp;kp1,
    vector&lt;KeyPoint&gt;&amp;kp2,
    vector&lt;bool&gt; &amp;success,
    bool inverse&#x3D;false
       );
  
  &#x2F;&#x2F;从图像中获取一个灰度值
  &#x2F;&#x2F;采用双线性内插法，来估计一个点的像素：
  &#x2F;&#x2F;f(x,y)&#x3D;f(0,0)(1-x)(1-y)+f(1,0)x(1-y)+f(0,1)(1-x)y+f(1,1)xy
  inline float GetPixelValue(const cv::Mat &amp;img,float x,float y)
  &#123;
    &#x2F;&#x2F;边缘检测
    if(x&lt;0)
      x&#x3D;0;
    if(y&lt;0)
      y&#x3D;0;
    if(x&gt;&#x3D;img.cols)
      x&#x3D;img.cols-1;
    if(y&gt;&#x3D;img.rows)
      y&#x3D;img.rows-1;
    uchar *data&#x3D;&amp;img.data[int(y)*img.step+int(x)];  &#x2F;&#x2F;img.step:表示图像矩阵中每行包含的字节数;int(x)将x转换为int类型
    
    float xx&#x3D;x-floor(x);   &#x2F;&#x2F;floor(x)函数：向下取整函数，即返回一个不大于x的最大整数
    float yy&#x3D;y-floor(y);
    
    return float(
      (1-xx)*(1-yy)*data[0]+
      xx*(1-yy)*data[1]+
      (1-xx)*yy*data[img.step]+
      xx*yy*data[img.step+1]
      );
  &#125;
  
  &#x2F;&#x2F;主函数
  int main(int argc,char**argv)
  &#123;
    Mat img1&#x3D;imread(file_1,0);  &#x2F;&#x2F;以灰度读取图像，重点
    Mat img2&#x3D;imread(file_2,0);
    &#x2F;&#x2F;特征点检测
    vector&lt;KeyPoint&gt;kp1;  &#x2F;&#x2F;关键点 存放在容器kp1中
    Ptr&lt;GFTTDetector&gt; detector&#x3D;GFTTDetector::create(500,0.01,20); &#x2F;&#x2F;通过GFTTD来获取角点，参数：最大角点数目500;角点可以接受的最小特征值0.01;角点之间的最小距离20
    detector-&gt;detect(img1,kp1);&#x2F;&#x2F;类似于ORB特征点的提取过程
    
    &#x2F;&#x2F;接下来实现在第二张图像中追踪这些角点，即追踪 kp1
    &#x2F;&#x2F;第一种方法：单层光流
    vector&lt;KeyPoint&gt;kp2_single;
    vector&lt;bool&gt;success_single;
    OpticalFlowSingleLevel(img1,img2,kp1,kp2_single,success_single);
    
    &#x2F;&#x2F;第二种方法：多层光流
    vector&lt;KeyPoint&gt;kp2_multi;
    vector&lt;bool&gt;success_multi;
    chrono::steady_clock::time_point t1&#x3D;chrono::steady_clock::now();
    OpticalFlowMultiLevel(img1,img2,kp1,kp2_multi,success_multi,true);
    chrono::steady_clock::time_point t2&#x3D;chrono::steady_clock::now();
    auto time_used&#x3D;chrono::duration_cast&lt;chrono::duration&lt;double&gt;&gt;(t2-t1);
     &#x2F;&#x2F;输出使用高斯牛顿法所花费的时间
    cout &lt;&lt; &quot;optical flow by gauss-newton: &quot; &lt;&lt; time_used.count() &lt;&lt; endl;

    
    &#x2F;&#x2F;使用OpenCV中的LK光流
    vector&lt;Point2f&gt;pt1,pt2;
    for(auto &amp;kp:kp1)     &#x2F;&#x2F;kp1中存放的是第一张图像中的角点，通过遍历，将kp1存放在pt1中
      pt1.push_back(kp.pt);
    vector&lt;uchar&gt;status;
    vector&lt;float&gt;error;
    t1&#x3D;chrono::steady_clock::now();
    &#x2F;&#x2F;调用cv::calculateOpticalFlowPyrLK函数：
    &#x2F;&#x2F;提供前后两张图像及对应的特征点，即可得到追踪后的点，以及各点的状态、误差;
    &#x2F;&#x2F;根据status变量是否为1来确定对应的点是否被正确追踪到。
    cv::calcOpticalFlowPyrLK(img1,img2,pt1,pt2,status,error);
    t2&#x3D;chrono::steady_clock::now();
    time_used&#x3D;chrono::duration_cast&lt;chrono::duration&lt;double&gt;&gt;(t2-t1);
    cout &lt;&lt; &quot;optical flow by opencv: &quot; &lt;&lt; time_used.count() &lt;&lt; endl;  &#x2F;&#x2F;输出使用opencv所花费的时间
    
    &#x2F;&#x2F;下面一部分代码实现绘图的功能
    &#x2F;&#x2F;第一张图像：单层光流的效果图
     Mat img2_single;
     &#x2F;&#x2F;将输入图像从一个空间转换到另一个色彩空间
     cv::cvtColor(img2,img2_single,CV_GRAY2BGR); &#x2F;&#x2F;cvtColor(）函数实现的功能：将img2灰度图转换成彩色图img2_single输出
     for(int i&#x3D;0;i&lt;kp2_single.size();i++)
     &#123;
       if(success_single[i])   &#x2F;&#x2F;判断是否追踪成功
       &#123;
	 &#x2F;&#x2F;circle():画圆：参数：源图像，画圆的圆心坐标，圆的半径，圆的颜色，线条的粗细程度
	 &#x2F;&#x2F;kp2_single[i].pt：用来取第i个角点的坐标；Scalar(0,250,0)：设置颜色，遵循B G R ，所以此图中为绿色
	 cv::circle(img2_single,kp2_single[i].pt,2,cv::Scalar(0,250,0),2);
	 &#x2F;&#x2F;line():绘制直线：参数：要画的线所在的图像，直线起点，直线终点，直线的颜色（绿色）
	 cv::line(img2_single,kp1[i].pt,kp2_single[i].pt,cv::Scalar(0,250,0));
       &#125;
     &#125;
     
     &#x2F;&#x2F;第二张图像：多层光流的效果图
     Mat img2_multi;
     cv::cvtColor(img2,img2_multi,CV_GRAY2BGR);
      for(int i&#x3D;0;i&lt;kp2_multi.size();i++)
     &#123;
       if(success_multi[i])   
       &#123;
	 cv::circle(img2_multi,kp2_multi[i].pt,2,cv::Scalar(250,0,0),2);
	  cv::line(img2_multi,kp1[i].pt,kp2_multi[i].pt,cv::Scalar(250,0,0));
       &#125;
     &#125;
     
     &#x2F;&#x2F;第三张图像：使用OpenCV中的LK光流
     Mat img2_CV;
     cv::cvtColor(img2,img2_CV,CV_GRAY2BGR);
      for(int i&#x3D;0;i&lt;pt2.size();i++)
     &#123;
       if(status[i])   
       &#123;
	  cv::circle(img2_CV,pt2[i],2,cv::Scalar(0,0,250),2);
	  cv::line(img2_CV,pt1[i],pt2[i],cv::Scalar(0,0,250));
       &#125;
     &#125;
     
     &#x2F;&#x2F;
     cv::imshow(&quot;tracked single level&quot;,img2_single);
     cv::imshow(&quot;tracked multi level&quot;,img2_multi);
     cv::imshow(&quot;tracked by opencv&quot;,img2_CV);
     cv::waitKey(0);
     return 0;
  &#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><em><strong>具体功能实现如下：</strong></em></p>
<pre class="line-numbers language-c++" data-language="c++"><code class="language-c++"> &#x2F;&#x2F;接下来这一部分：具体函数的实现
 &#x2F;&#x2F;第一个：单层光流函数的实现
 void OpticalFlowSingleLevel(
   const Mat &amp;img1,
   const Mat &amp;img2,
   const vector&lt;KeyPoint&gt;&amp;kp1,
   vector&lt;KeyPoint&gt;&amp;kp2,
   vector&lt;bool&gt;&amp;success,
   bool inverse,
   bool has_initial)
 &#123;
   &#x2F;&#x2F;resize()函数：调整图像的大小；size（）函数：获取kp1的长度
   &#x2F;&#x2F;初始化
   kp2.resize(kp1.size());
   success.resize(kp1.size());   &#x2F;&#x2F;是否追踪成功的标志
   
   OpticalFlowTracker tracker(img1,img2,kp1,kp2,success,inverse,has_initial);  &#x2F;&#x2F;创建类的对象tracker
   &#x2F;&#x2F;调用parallel_for_并行调用OpticalFlowTracker::calculateOpticalFlow，该函数计算指定范围内特征点的光流
   &#x2F;&#x2F;range():从指定的第一个值开始，并在到达指定的第二个值后终止
   parallel_for_(Range(0,kp1.size()),std::bind(&amp;OpticalFlowTracker::calculateOpticalFlow,&amp;tracker,placeholders::_1));
 &#125;
 
 &#x2F;&#x2F;类外实现成员函数
 void OpticalFlowTracker::calculateOpticalFlow(const Range &amp;range)
 &#123;
   &#x2F;&#x2F;定义参数
   int half_patch_size&#x3D;4;  &#x2F;&#x2F;窗口的大小8×8
   int iterations&#x3D;10;  &#x2F;&#x2F;每个角点迭代10次
   for(size_t i&#x3D;range.start;i&lt;range.end;i++)
   &#123;
     auto kp&#x3D;kp1[i];   &#x2F;&#x2F;将第一张图像中的第i个关键点kp1[i]存放在 kp 中
     double dx&#x3D;0,dy&#x3D;0; &#x2F;&#x2F;初始化
     if(has_initial)
     &#123;
dx&#x3D;kp2[i].pt.x-kp.pt.x;   &#x2F;&#x2F;第i个点在第二张图像中的位置与第一张图像中的位置的差值
dy&#x3D;kp2[i].pt.y-kp.pt.y;
     &#125;
     
     double cost&#x3D;0,lastCost&#x3D;0;
     bool succ&#x3D;true;
     
     &#x2F;&#x2F;高斯牛顿方程
     &#x2F;&#x2F;高斯牛顿迭代
     Eigen::Matrix2d H &#x3D; Eigen::Matrix2d::Zero();   &#x2F;&#x2F;定义H，并进行初始化。
     Eigen::Vector2d b &#x3D; Eigen::Vector2d::Zero();   &#x2F;&#x2F;定义b，并初始化.
     Eigen::Vector2d J;   &#x2F;&#x2F;定义雅克比矩阵2×1
     for(int iter&#x3D;0;iter&lt;iterations;iter++)
     &#123;
if(inverse&#x3D;&#x3D;false)
&#123;
  H&#x3D;Eigen::Matrix2d::Zero();
  b&#x3D;Eigen::Vector2d::Zero();
&#125;
else
&#123;
  b&#x3D;Eigen::Vector2d::Zero();
&#125;
cost&#x3D;0;
&#x2F;&#x2F;假设在这个8×8的窗口内像素具有同样的运动
&#x2F;&#x2F;计算cost和J
for(int x&#x3D;-half_patch_size;x&lt;half_patch_size;x++)
  for(int y&#x3D;-half_patch_size;y&lt;half_patch_size;y++)
  &#123;
    &#x2F;&#x2F;GetPixelValue（）计算某点的灰度值
    &#x2F;&#x2F;计算残差：I(x,y)-I(x+dx,y+dy)
    double error&#x3D;GetPixelValue(img1,kp.pt.x+x,kp.pt.y+y)-GetPixelValue(img2,kp.pt.x+x+dx,kp.pt.y+y+dy);;
    if(inverse&#x3D;&#x3D;false)
    &#123;
      &#x2F;&#x2F;雅克比矩阵为第二个图像在x+dx,y+dy处的梯度
      J&#x3D;-1.0*Eigen::Vector2d(0.5*(GetPixelValue(img2,kp.pt.x+dx+x+1,kp.pt.y+dy+y)-
                                 GetPixelValue(img2,kp.pt.x+dx+x-1,kp.pt.y+dy+y)),
			     0.5*(GetPixelValue(img2,kp.pt.x+dx+x,kp.pt.y+dy+y+1)-
			         GetPixelValue(img2,kp.pt.x+dx+x,kp.pt.y+dy+y-1)));
    &#125;
    else if(iter&#x3D;&#x3D;0)  &#x2F;&#x2F;如果是第一次迭代，梯度为第一个图像的梯度，反向光流法
      &#x2F;&#x2F;在反向光流中，I(x,y)的梯度是保持不变的，可以在第一次迭代时保留计算的结果，在后续的迭代中使用。
      &#x2F;&#x2F;当雅克比矩阵不变时，H矩阵不变，每次迭代只需要计算残差。
    &#123;
      J&#x3D;-1.0*Eigen::Vector2d(0.5*(GetPixelValue(img1,kp.pt.x+x+1,kp.pt.y+y)-
                                 GetPixelValue(img1,kp.pt.x+x-1,kp.pt.y+y)),
			     0.5*(GetPixelValue(img1,kp.pt.x+x,kp.pt.y+y+1)-
			         GetPixelValue(img1,kp.pt.x+x,kp.pt.y+y-1)));
    &#125;
    &#x2F;&#x2F;计算H和b
    b+&#x3D;-error*J;
    cost+&#x3D;error*error;
    if(inverse&#x3D;&#x3D;false||iter&#x3D;&#x3D;0)
    &#123;
      H+&#x3D;J*J.transpose();
    &#125;
  &#125;
  &#x2F;&#x2F;计算增量update，求解线性方程Hx&#x3D;b
  Eigen::Vector2d update&#x3D;H.ldlt().solve(b);
  if(std::isnan(update[0]))  &#x2F;&#x2F;判断增量
  &#123;
    &#x2F;&#x2F;有时当我们遇到一个黑色或白色的方块，H是不可逆的，即高斯牛顿方程无解
    cout&lt;&lt;&quot;update is nan&quot;&lt;&lt;endl;
    succ&#x3D;false;   &#x2F;&#x2F;追踪失败
    break;
  &#125;
  if(iter&gt;0&amp;&amp;cost&gt;lastCost)
  &#123;
    break;
  &#125;
  dx+&#x3D;update[0];
  dy+&#x3D;update[1];
  lastCost&#x3D;cost;
  succ&#x3D;true;
  if(update.norm()&lt;1e-2)
  &#123;
    break;
  &#125;
     &#125;
     success[i]&#x3D;succ;
     kp2[i].pt&#x3D;kp.pt+Point2f(dx,dy);
   &#125;
 &#125;&#x2F;&#x2F;迭代完成
 
 &#x2F;&#x2F;第二个：多层光流函数的实现
 void OpticalFlowMultiLevel(
   const Mat &amp;img1,
   const Mat &amp;img2,
   const vector&lt;KeyPoint&gt;&amp;kp1,
   vector&lt;KeyPoint&gt;&amp;kp2,
   vector&lt;bool&gt;&amp;success,
   bool inverse)
 &#123;
   int pyramids&#x3D;4; &#x2F;&#x2F;建立4层金字塔
   double pyramid_scale&#x3D;0.5;  &#x2F;&#x2F;金字塔每层缩小0.5
   double scales[]&#x3D;&#123;1.0,0.5,0.25,0.125&#125;;
   
   &#x2F;&#x2F;建立金字塔
   chrono::steady_clock::time_point t1&#x3D;chrono::steady_clock::now();  &#x2F;&#x2F;计算时间
   vector&lt;Mat&gt;pyr1,pyr2;
   for(int i&#x3D;0;i&lt;pyramids;i++)
   &#123;
     if(i&#x3D;&#x3D;0)
     &#123;
&#x2F;&#x2F;将两张图像存放在pyr1,pyr2中
pyr1.push_back(img1);    
pyr2.push_back(img2);
     &#125;
     else
     &#123;
Mat img1_pyr,img2_pyr;
&#x2F;&#x2F;对图像进行缩放，参数：原图，输出图像，输出图像大小，Size（宽度，高度）
cv::resize(pyr1[i-1],img1_pyr,cv::Size(pyr1[i-1].cols*pyramid_scale,pyr1[i-1].rows*pyramid_scale));
cv::resize(pyr2[i-1],img2_pyr,cv::Size(pyr2[i-1].cols*pyramid_scale,pyr2[i-1].rows*pyramid_scale));
pyr1.push_back(img1_pyr);
pyr2.push_back(img2_pyr);
     &#125;
   &#125;
   chrono::steady_clock::time_point t2&#x3D;chrono::steady_clock::now();
   auto time_used&#x3D;chrono::duration_cast&lt;chrono::duration&lt;double&gt;&gt;(t2-t1);
   cout&lt;&lt;&quot;build pyramid time:&quot;&lt;&lt;time_used.count()&lt;&lt;endl;
   
   &#x2F;&#x2F;计算光流时，先从顶层的图像开始计算
   vector&lt;KeyPoint&gt;kp1_pyr,kp2_pyr;
   for(auto &amp;kp:kp1)
   &#123;
     auto kp_top&#x3D;kp;
     kp_top.pt *&#x3D;scales[pyramids-1];   &#x2F;&#x2F;顶层
     kp1_pyr.push_back(kp_top);
     kp2_pyr.push_back(kp_top);
   &#125;
   
   for(int level&#x3D;pyramids-1;level&gt;&#x3D;0;level--)
   &#123;
     success.clear();
     t1&#x3D;chrono::steady_clock::now();
     OpticalFlowSingleLevel(pyr1[level],pyr2[level],kp1_pyr,kp2_pyr,success,inverse,true);
     t2&#x3D;chrono::steady_clock::now();
     auto time_used&#x3D;chrono::duration_cast&lt;chrono::duration&lt;double&gt;&gt;(t2-t1);
     cout&lt;&lt;&quot;track pyr&quot;&lt;&lt;level&lt;&lt;&quot;cost time:&quot;&lt;&lt;time_used.count()&lt;&lt;endl;
     if(level&gt;0)
     &#123;
for(auto &amp;kp:kp1_pyr)
  kp.pt&#x2F;&#x3D;pyramid_scale;
for(auto &amp;kp:kp2_pyr)
  kp.pt&#x2F;&#x3D;pyramid_scale;
     &#125;
   &#125;
   for(auto &amp;kp:kp2_pyr)
     kp2.push_back(kp);
 &#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_51547017/article/details/115359316?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_baidulandingword~default-0-115359316-blog-126934983.235%5Ev28%5Epc_relevant_recovery_v2&spm=1001.2101.3001.4242.1&utm_relevant_index=3">视觉SLAM第八讲视觉里程计2— LK光流—代码详细讲解</a></p>
<p><img src="/pic/%E9%80%89%E5%8C%BA_138.png" alt="运行结果"></p>
<p><img src="/pic/%E9%80%89%E5%8C%BA_137.png" alt="运行结果"></p>
<h3 id="ch8-x2F-direct-method-cpp"><a href="#ch8-x2F-direct-method-cpp" class="headerlink" title="ch8&#x2F;direct_method.cpp"></a>ch8&#x2F;direct_method.cpp</h3><p>在光流中，我们会首先追踪特征点的位置，再根据这些位置确定相机的运动。这样一种两步走的方案，很难保证全局最优。直接法通过在后一步中调整前一步的结果</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/pj18862486309/article/details/107829914?spm=1001.2101.3001.6650.6&utm_medium=distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~Rate-6-107829914-blog-126993782.235%5Ev28%5Epc_relevant_recovery_v2&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~Rate-6-107829914-blog-126993782.235%5Ev28%5Epc_relevant_recovery_v2&utm_relevant_index=10">视觉十四讲：第八讲_直接法</a></p>
<p><img src="/pic/%E9%80%89%E5%8C%BA_139.png" alt="直接法的讨论"></p>
<p>代码注释待更新~~~~</p>

                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/about" rel="external nofollow noreferrer">oceanechy</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="http://oceanechy.github.io/2023/04/08/slam14-3/">http://oceanechy.github.io/2023/04/08/slam14-3/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/about" target="_blank">oceanechy</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/c/">
                                    <span class="chip bg-color">c++</span>
                                </a>
                            
                                <a href="/tags/slam/">
                                    <span class="chip bg-color">slam</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
                <div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">你的赏识是我前进的动力</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/medias/reward/wechat.png" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>

            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/2023/04/11/c-base/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/22.jpg" class="responsive-img" alt="linux环境下c++实现通讯录系统">
                        
                        <span class="card-title">linux环境下c++实现通讯录系统</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            通讯录系统实现
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2023-04-11
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/c/" class="post-category">
                                    c++
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/c/">
                        <span class="chip bg-color">c++</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2023/04/06/slam14/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/15.jpg" class="responsive-img" alt="slam14讲源代码的记录（前五讲）">
                        
                        <span class="card-title">slam14讲源代码的记录（前五讲）</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            记录slam14讲源代码中的一些东西（前五讲）
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2023-04-06
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/slam/" class="post-category">
                                    slam
                                </a>
                            
                            <a href="/categories/slam/c/" class="post-category">
                                    c++
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/c/">
                        <span class="chip bg-color">c++</span>
                    </a>
                    
                    <a href="/tags/slam/">
                        <span class="chip bg-color">slam</span>
                    </a>
                    
                    <a href="/tags/CMake/">
                        <span class="chip bg-color">CMake</span>
                    </a>
                    
                    <a href="/tags/Sophus/">
                        <span class="chip bg-color">Sophus</span>
                    </a>
                    
                    <a href="/tags/Eigen/">
                        <span class="chip bg-color">Eigen</span>
                    </a>
                    
                    <a href="/tags/Pangolin/">
                        <span class="chip bg-color">Pangolin</span>
                    </a>
                    
                    <a href="/tags/%E5%9B%BE%E5%83%8F%E5%8E%BB%E7%95%B8%E5%8F%98/">
                        <span class="chip bg-color">图像去畸变</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>


  <!-- 是否加载使用自带的 prismjs. -->
  <script type="text/javascript" src="/libs/prism/prism.min.js"></script>


<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/libs/aplayer/APlayer.min.js"></script>
<script src="/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 0px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2019-2023</span>
            
            <a href="/about" target="_blank">oceanechy</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">51.4k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/oceanechy" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:1945942166@qq.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>







    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=1945942166" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 1945942166" data-position="top" data-delay="50">
        <i class="fab fa-qq"></i>
    </a>





    <a href="https://www.zhihu.com/people/xiao-hai-38-6-81" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/xiao-hai-38-6-81" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    

    
    
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
     
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/libs/others/star.js"><\/script>');
            }
        </script>
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

</body>

</html>
