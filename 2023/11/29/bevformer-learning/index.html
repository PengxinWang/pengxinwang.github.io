<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="BEVFormer学习总结（结合代码）, Ocean">
    <meta name="description" content="BEVFormer学习总结（结合代码）论文链接中文论文链接代码链接万字长文理解BEVFormer手撕BEVFormer视频BEVFormer代码流程梳理1BEVFormer代码流程梳理2nuscenes数据集介绍Transformer学习笔">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>BEVFormer学习总结（结合代码） | Ocean</title>
    <link rel="icon" type="image/png" href="/favicon.png">
    
    <style>
        body{
            background-image: url(/medias/ocean.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/css/matery.css">
<link rel="stylesheet" type="text/css" href="/css/my.css">
<link rel="stylesheet" type="text/css" href="/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/css/post.css">




    
        <link rel="stylesheet" type="text/css" href="/css/reward.css">
    



    <script src="/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 6.3.0"></head>


<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Ocean</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>关于</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/contact" class="waves-effect waves-light">
      
      <i class="fas fa-comments" style="zoom: 0.6;"></i>
      
      <span>留言板</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Ocean</div>
        <div class="logo-desc">
            
            要善良,要勇敢,要像星星一样努力发光。若是你心怀旧梦，就别再无疾而终。加油，为实现梦想努力。梦想再遥远，也要笑着走去，毕竟沿途有很多美景等着去欣赏。
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			关于
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/contact" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-comments"></i>
			
			留言板
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/oceanechy" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/oceanechy" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/featureimages/12.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">BEVFormer学习总结（结合代码）</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/bev/">
                                <span class="chip bg-color">bev</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/DL/" class="post-category">
                                DL
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2023-11-29
                </div>
                

                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    8.3k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    34 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        
        <!-- 是否加载使用自带的 prismjs. -->
        <link rel="stylesheet" href="/libs/prism/prism.min.css">
        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <h1 id="BEVFormer学习总结（结合代码）"><a href="#BEVFormer学习总结（结合代码）" class="headerlink" title="BEVFormer学习总结（结合代码）"></a>BEVFormer学习总结（结合代码）</h1><p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2203.17270.pdf">论文链接</a><br><a target="_blank" rel="noopener" href="https://drive.google.com/file/d/1dKnD6gUHhBXZ8gT733cIU_A7dHEEzNTP/view">中文论文链接</a><br><a target="_blank" rel="noopener" href="https://github.com/fundamentalvision/BEVFormer">代码链接</a><br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/543335939">万字长文理解BEVFormer</a><br><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1rK411o7PS/?spm_id_from=333.788&vd_source=2055b62125c0277a0d6878f41c89fec2">手撕BEVFormer视频</a><br><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_42108183/article/details/128426721?spm=1001.2014.3001.5501">BEVFormer代码流程梳理1</a><br><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_42108183/article/details/128433381?spm=1001.2014.3001.5501">BEVFormer代码流程梳理2</a><br><a target="_blank" rel="noopener" href="https://ttxsai.blog.csdn.net/article/details/123450282?spm=1001.2101.3001.6650.3&utm_medium=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-3-123450282-blog-122300131.235%5Ev38%5Epc_relevant_anti_vip_base&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-3-123450282-blog-122300131.235%5Ev38%5Epc_relevant_anti_vip_base&utm_relevant_index=6">nuscenes数据集介绍</a><br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/48508221">Transformer学习笔记</a><br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/48508221">Vistion Transformer学习笔记</a><br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/657666107">Vistion Transformer学习笔记</a><br><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_42108183/article/details/128680716?spm=1001.2014.3001.5501">DeformableDETR原理+代码解析1</a><br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/612756240">DeformableDETR原理+代码解析2</a><br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/596303361">DeformableDETR原理+代码解析3</a><br><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_52053775/article/details/126468394">DeformableDETR原理解析</a></p>
<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>该篇论文提出了一个采用纯视觉（camera）做感知任务的算法模型 BEVFormer。BEVFormer 通过提取环视相机采集到的图像特征，并将提取的环视特征通过模型学习的方式转换到 BEV 空间（模型去学习如何将特征从图像坐标系转换到BEV坐标系），从而实现 3D 目标检测和地图分割任务，并取得了 SOTA 的效果， 利用询问向量来查找空间&#x2F;时间域,并相应地聚合时空信息,因此有利于更强的感知任务表征。</p>
<h2 id="官方的模型仓库"><a href="#官方的模型仓库" class="headerlink" title="官方的模型仓库"></a>官方的模型仓库</h2><table>
<thead>
<tr>
<th align="center">Backbone</th>
<th align="center">Method</th>
<th align="center">Lr Schd</th>
<th align="center">NDS</th>
<th align="center">mAP</th>
<th align="center">memroy</th>
<th align="center">Config</th>
<th align="center">Download</th>
</tr>
</thead>
<tbody><tr>
<td align="center">R50</td>
<td align="center">BEVFormer-tiny_fp16</td>
<td align="center">24ep</td>
<td align="center">35.9</td>
<td align="center">25.7</td>
<td align="center">-</td>
<td align="center"><a href="projects/configs/bevformer_fp16/bevformer_tiny_fp16.py">config</a></td>
<td align="center"><a target="_blank" rel="noopener" href="https://github.com/zhiqi-li/storage/releases/download/v1.0/bevformer_tiny_fp16_epoch_24.pth">model</a>&#x2F;<a target="_blank" rel="noopener" href="https://github.com/zhiqi-li/storage/releases/download/v1.0/bevformer_tiny_fp16_epoch_24.log">log</a></td>
</tr>
<tr>
<td align="center">R50</td>
<td align="center">BEVFormer-tiny</td>
<td align="center">24ep</td>
<td align="center">35.4</td>
<td align="center">25.2</td>
<td align="center">6500M</td>
<td align="center"><a href="projects/configs/bevformer/bevformer_tiny.py">config</a></td>
<td align="center"><a target="_blank" rel="noopener" href="https://github.com/zhiqi-li/storage/releases/download/v1.0/bevformer_tiny_epoch_24.pth">model</a>&#x2F;<a target="_blank" rel="noopener" href="https://github.com/zhiqi-li/storage/releases/download/v1.0/bevformer_tiny_epoch_24.log">log</a></td>
</tr>
<tr>
<td align="center"><a target="_blank" rel="noopener" href="https://github.com/zhiqi-li/storage/releases/download/v1.0/r101_dcn_fcos3d_pretrain.pth">R101-DCN</a></td>
<td align="center">BEVFormer-small</td>
<td align="center">24ep</td>
<td align="center">47.9</td>
<td align="center">37.0</td>
<td align="center">10500M</td>
<td align="center"><a href="projects/configs/bevformer/bevformer_small.py">config</a></td>
<td align="center"><a target="_blank" rel="noopener" href="https://github.com/zhiqi-li/storage/releases/download/v1.0/bevformer_small_epoch_24.pth">model</a>&#x2F;<a target="_blank" rel="noopener" href="https://github.com/zhiqi-li/storage/releases/download/v1.0/bevformer_small_epoch_24.log">log</a></td>
</tr>
<tr>
<td align="center"><a target="_blank" rel="noopener" href="https://github.com/zhiqi-li/storage/releases/download/v1.0/r101_dcn_fcos3d_pretrain.pth">R101-DCN</a></td>
<td align="center">BEVFormer-base</td>
<td align="center">24ep</td>
<td align="center">51.7</td>
<td align="center">41.6</td>
<td align="center">28500M</td>
<td align="center"><a href="projects/configs/bevformer/bevformer_base.py">config</a></td>
<td align="center"><a target="_blank" rel="noopener" href="https://github.com/zhiqi-li/storage/releases/download/v1.0/bevformer_r101_dcn_24ep.pth">model</a>&#x2F;<a target="_blank" rel="noopener" href="https://github.com/zhiqi-li/storage/releases/download/v1.0/bevformer_r101_dcn_24ep.log">log</a></td>
</tr>
<tr>
<td align="center"><a target="_blank" rel="noopener" href="https://pan.baidu.com/s/1Jh5Aq2YwcD6tdj7Sl5BB3g?pwd=5rij">R50</a></td>
<td align="center">BEVformerV2-t1-base</td>
<td align="center">24ep</td>
<td align="center">42.6</td>
<td align="center">35.1</td>
<td align="center">23952M</td>
<td align="center"><a href="projects/configs/bevformerv2/bevformerv2-r50-t1-base-24ep.py">config</a></td>
<td align="center"><a target="_blank" rel="noopener" href="https://pan.baidu.com/s/1ynzlAt1DQbH8NkqmisatTw?pwd=fdcv">model&#x2F;log</a></td>
</tr>
<tr>
<td align="center"><a target="_blank" rel="noopener" href="https://pan.baidu.com/s/1Jh5Aq2YwcD6tdj7Sl5BB3g?pwd=5rij">R50</a></td>
<td align="center">BEVformerV2-t1-base</td>
<td align="center">48ep</td>
<td align="center">43.9</td>
<td align="center">35.9</td>
<td align="center">23952M</td>
<td align="center"><a href="projects/configs/bevformerv2/bevformerv2-r50-t1-base-48ep.py">config</a></td>
<td align="center"><a target="_blank" rel="noopener" href="https://pan.baidu.com/s/1ynzlAt1DQbH8NkqmisatTw?pwd=fdcv">model&#x2F;log</a></td>
</tr>
<tr>
<td align="center"><a target="_blank" rel="noopener" href="https://pan.baidu.com/s/1Jh5Aq2YwcD6tdj7Sl5BB3g?pwd=5rij">R50</a></td>
<td align="center">BEVformerV2-t1</td>
<td align="center">24ep</td>
<td align="center">45.3</td>
<td align="center">38.1</td>
<td align="center">37579M</td>
<td align="center"><a href="projects/configs/bevformerv2/bevformerv2-r50-t1-24ep.py">config</a></td>
<td align="center"><a target="_blank" rel="noopener" href="https://pan.baidu.com/s/1ynzlAt1DQbH8NkqmisatTw?pwd=fdcv">model&#x2F;log</a></td>
</tr>
<tr>
<td align="center"><a target="_blank" rel="noopener" href="https://pan.baidu.com/s/1Jh5Aq2YwcD6tdj7Sl5BB3g?pwd=5rij">R50</a></td>
<td align="center">BEVformerV2-t1</td>
<td align="center">48ep</td>
<td align="center">46.5</td>
<td align="center">39.5</td>
<td align="center">37579M</td>
<td align="center"><a href="projects/configs/bevformerv2/bevformerv2-r50-t1-48ep.py">config</a></td>
<td align="center"><a target="_blank" rel="noopener" href="https://pan.baidu.com/s/1ynzlAt1DQbH8NkqmisatTw?pwd=fdcv">model&#x2F;log</a></td>
</tr>
<tr>
<td align="center"><a target="_blank" rel="noopener" href="https://pan.baidu.com/s/1Jh5Aq2YwcD6tdj7Sl5BB3g?pwd=5rij">R50</a></td>
<td align="center">BEVformerV2-t2</td>
<td align="center">24ep</td>
<td align="center">51.8</td>
<td align="center">42.0</td>
<td align="center">38954M</td>
<td align="center"><a href="projects/configs/bevformerv2/bevformerv2-r50-t2-24ep.py">config</a></td>
<td align="center"><a target="_blank" rel="noopener" href="https://pan.baidu.com/s/1ynzlAt1DQbH8NkqmisatTw?pwd=fdcv">model&#x2F;log</a></td>
</tr>
<tr>
<td align="center"><a target="_blank" rel="noopener" href="https://pan.baidu.com/s/1Jh5Aq2YwcD6tdj7Sl5BB3g?pwd=5rij">R50</a></td>
<td align="center">BEVformerV2-t2</td>
<td align="center">48ep</td>
<td align="center">52.6</td>
<td align="center">43.1</td>
<td align="center">38954M</td>
<td align="center"><a href="projects/configs/bevformerv2/bevformerv2-r50-t2-48ep.py">config</a></td>
<td align="center"><a target="_blank" rel="noopener" href="https://pan.baidu.com/s/1ynzlAt1DQbH8NkqmisatTw?pwd=fdcv">model&#x2F;log</a></td>
</tr>
<tr>
<td align="center"><a target="_blank" rel="noopener" href="https://pan.baidu.com/s/1Jh5Aq2YwcD6tdj7Sl5BB3g?pwd=5rij">R50</a></td>
<td align="center">BEVformerV2-t8</td>
<td align="center">24ep</td>
<td align="center">55.3</td>
<td align="center">46.0</td>
<td align="center">40392M</td>
<td align="center"><a href="projects/configs/bevformerv2/bevformerv2-r50-t8-24ep.py">config</a></td>
<td align="center"><a target="_blank" rel="noopener" href="https://pan.baidu.com/s/1ynzlAt1DQbH8NkqmisatTw?pwd=fdcv">model&#x2F;log</a></td>
</tr>
</tbody></table>
<p><strong>可以看到这里也有BEVFormerV2,后续会进行讲解，下面以BEVFormer-base为例进行讲解</strong></p>
<h2 id="Pipeline"><a href="#Pipeline" class="headerlink" title="Pipeline"></a>Pipeline</h2><ul>
<li>Backbone + Neck （ResNet-101-DCN + FPN）提取环视图像的多尺度特征；</li>
<li>论文提出的 Encoder 模块（包括 Temporal Self-Attention 模块和 Spatial Cross-Attention 模块）完成环视图像特征向 BEV 特征的建模；</li>
<li>Decoder 模块使用类似 Deformable DETR 的 完成 3D 目标检测的分类和定位任务；</li>
<li>正负样本的定义（采用 Transformer 中常用的匈牙利匹配算法，Focal Loss + L1 Loss 的总损失和最小）；</li>
<li>损失的计算（Focal Loss 分类损失 + L1 Loss 回归损失）；</li>
<li>反向传播，更新网络模型参数；</li>
</ul>
<p><img src="/pic/BEVFormer1.png" alt="制作的结构图"></p>
<p><strong>接下来将从输入数据格式，网络特征提取，BEV特征产生，BEV 特征解码完成 3D 框预测、正负样本定义、损失计算这六个方面完成 BEVFormer 的解析</strong></p>
<h2 id="输入的数据格式"><a href="#输入的数据格式" class="headerlink" title="输入的数据格式"></a>输入的数据格式</h2><p>对于 BEVFormer 网络模型而言，输入的数据是一个 6 维的张量：（bs，queue，cam，C，H，W）；</p>
<ul>
<li>bs：batch size 大小；</li>
<li>queue：连续帧的个数；由于 BEVFormer 采用了时序信息的思想（我认为加入时序信息后，可以一定程度上缓解遮挡问题），所以输入到网络模型中的数据要包含除当前帧之外，之前几帧的数据；</li>
<li>cam：每帧中包含的图像数量，对于nuScenes数据集而言，由于一辆车带有六个环视相机传感器，可以实现 360° 全场景的覆盖，所以一帧会包含六个环视相机拍摄到的六张环视图片；</li>
<li>C，H，W：图片的通道数，图片的高度，图片的宽度；</li>
</ul>
<h3 id="Nuscenes数据集简介"><a href="#Nuscenes数据集简介" class="headerlink" title="Nuscenes数据集简介"></a>Nuscenes数据集简介</h3><p>NuScenes数据集是一个包含两个城市1000个驾驶场景的大规模自动驾驶数据集。850个场景用于培训&#x2F;验证，150个场景用于测试。每一场戏都有20多秒长。它有40K个关键帧和整个传感器套件，包括6个摄像头（CAM）、1个激光雷达（LIDAR）、5个雷达（RADAR）、IMU和GPS。摄像机图像分辨率为1600×900。同时，发布了相应的HD-Map和CanBus数据，以探索多个输入的辅助。由于NuScenes提供了多样化的多传感器设置，因此它在学术文献中越来越受欢迎；数据规模没有Waymo的大，这使得在这个基准上快速验证想法变得高效。</p>
<p><strong>传感器在采集车上的布置如下图所示</strong></p>
<p> <img src="/pic/BEVFormer2.png" alt="采集车的结构图"></p>
<p>可以看出，相机（CAM）有六个，分别分布在前方（Front）、右前方（Front Right）、左前方（Front Left）、后方（Back）、右后方（Back Right）、左后方（Back Left）；激光雷达（LIDAR）有1个，放置在车顶（TOP）；毫米波雷达有五个，分别放置在前方（Front）、右前方（Front Right）、左前方（Front Left）、右后方（Back Right）、左后方（Back Left）。</p>
<h3 id="transformer的一些知识"><a href="#transformer的一些知识" class="headerlink" title="transformer的一些知识"></a>transformer的一些知识</h3><h4 id="自注意力机制（self-attention）"><a href="#自注意力机制（self-attention）" class="headerlink" title="自注意力机制（self-attention）"></a>自注意力机制（self-attention）</h4><p>自注意力机制是一种用于处理序列数据的机制，它能够在序列中的每个位置上计算该位置与其他位置之间的关联程度，并根据这些关联程度来加权组合序列中的信息。</p>
<p>概念：</p>
<ul>
<li>查询(Query)：查询是你想要了解的信息或者你想要从文本中提取的特征。它类似于你对文中的某个词语提出的问题或者你想要了解的内容。</li>
<li>键(Key)：键是文本中每个词语的表示。它类似于每个词语的标识符或者关键信息，用于帮助计算查询与其他词语之间的关联程度。</li>
<li>值(Value)：值是与每个词语相关的具体信息或特征。它类似于每个词语的具体含义或者特征向量。</li>
</ul>
<p>在自注意力机制中，具体步骤是：</p>
<ul>
<li>Stp1：从输入值a乘以矩阵Wq、Wk和Wv(这三个矩阵是模型参数，需要通过训练数据来学习)获取查询(Q)、键(K)、值(V),一般可以在输入a加上位置向量后再计算对应的Q、K、V</li>
<li>Step2:通过计算查询(Q)与键(K)之间的点积，来衡量查询与其他词语之间的关联程度，然后，通过对这些关联程度进行归一化处理（一般采用softma归一化），得到每个词语的注意力权重。</li>
<li>Step3:然后，根据这些注意力权重，对每个词语的值(V)进行加权求和，得到一个新的表示，该表示会更加关注与查询相关的信息。</li>
<li>Step4:最后，把Self Attention层的输出给全连接神经网络学习更多的信息</li>
</ul>
<p>以下是Transformer完整的架构，总体来看，它由**编码器(Encoder)<strong>和</strong>解码器(Decoder)**两部分组成。</p>
<p> <img src="/pic/transformer1.png" alt="完整架构图"></p>
<ul>
<li><strong>编码器(Encoder)</strong><ul>
<li>左边是编码器部分，主要作用是将输入数据编码成计算机能理解的高维抽象表示。</li>
<li>它的结构也就是前面一节我们所说的多头注意力机制+全连接神经网络的结构。此外，这里用了残差连接Q(Residual connection)的方式，将输入和多头注意力层或全连接神经网络的输出相加，再传递给下一层，避免梯度递减的问题。</li>
</ul>
</li>
<li><strong>解码器(Decoder)</strong><ul>
<li>右边是解码器的部分，主要作用是利用高维表示信息生成目标序列。它的结构大致与编码器相同，不同的有两点：<ul>
<li>第一，采用了<strong>掩码多头自注意力(Masked-Multi-.head self attention)</strong>,即在计算注意力得分时，模型只能关注生成内容的当前位置之前的信息，避免未来信息的泄漏。比如，这里计算输出b2时，就只使用了a1、a2两个位置的注意力得分进行加权。</li>
<li>第二，中间部分，利用了Encoder的输出结果计算交叉注意力(Cross Attention)。同之前的注意力机制类似，Cross Attention通过计算<strong>解码器当前位置(Q)的表示与编码器上下文表示(K)之间</strong>的注意力权重，将编码器上下文表示(V)加权，然后将该加权表示与解码器当前位置的表示进行融合。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="Deformable-DETR"><a href="#Deformable-DETR" class="headerlink" title="Deformable DETR"></a>Deformable DETR</h4><p>在transformer中，特征点的特征向量Value可以由一个网络学习到，但是这个Value并不能表示全局的建模关系，于是就由另外两个网络为分别为每个特征点学习一个query和key，然后利用当前特征点的query与所有特征点的key做点乘，然后进行softmax，这样可以计算出每个特征点与其他特征点的权重关系，然后利用这个权重关系，将所有特征点的Value进行加权求和，得到每个特征点最终的Value。实时上，每个特征点并非需要与其他每个特征点做self-attention，比如图片上的左上角的特征点与右下角的特征点的关系是十分微弱的，甚至毫无关系。</p>
<ul>
<li>在Deformable DETR 中，每个特征点只与周围的几个特征点(默认为4)进行self-attention，也就是每个特征点的Value是由其周围4个特征点的的Value加权求和得到的。</li>
<li>相对于DETR，在Deformable DETR中，引入了多尺度的特征(能够同时兼顾大目标与小目标的识别)，因此每个特征点都能够在每个特征层上找到一个自己的采样点，然后在每个采样点周围采样4个偏移点作为self-attention的对象，即利用 4 * 4 &#x3D; 16 个偏移点特征向量Value来计算当前特征点的Value。</li>
<li>这里有个问题，在transformer中，当前特征点的Value加权求和时是将自己的Value包括在内的，而在deformable detr中，是将自己value除外的。</li>
</ul>
<p>已经基本明确在 Deformable DETR中， 特征点要与哪些偏移点怎么做self-attention了，那么后续可以分为两个部分:</p>
<ul>
<li>1、如何找到这些采偏移点，</li>
<li>2、这些偏移点的权重系数是多少。</li>
</ul>
<p>文章是利用两个网络来实现的，一个网络通过特征点的Value预测16个偏移点(四个特征层)的位置，另一个网络利用特征点的Value预测16个偏移点的权重系数，如下图所示。</p>
<p> <img src="/pic/BEVFormer3.png" alt="完整架构图"></p>
<p>图中左边所示为4种尺度的特征层，以最上方特征层中的一个特征点(0.3，0.3)为例，它在每个特征层上都有一个采样点(相对坐标一致)，正常来说每个采样点会与周围的四个点(绿色点)进行self-attention，但是这四个点最好的通过网络自己来学习，于是蓝色的点是网络学习到的偏移点，但是偏移点的坐标一般不会为整数，因此，蓝色特征点的Value就会有其附近的四个特征点(黄色)进行双线性差值得到，因此，一个特征点就采样到了16个偏移点，那么这个特征点的特征向量Value就由这16个偏移点的特征向量Value加权求和得到</p>
<h2 id="BEV特征的产生"><a href="#BEV特征的产生" class="headerlink" title="BEV特征的产生"></a>BEV特征的产生</h2><p>BEV 特征的产生用到的就是论文中最核心的部分 —— Encoder 模块</p>
<p>Encoder 模块包含两个子模块 <strong>Temporal Self-Attention模块 以及 Spatial Cross-Attention模块</strong>；接下来我会分别介绍一下这两个模块；</p>
<p>在梳理具体的代码实现之前，首先介绍下在 Temporal Self-Attention 模块和 Spatial Cross-Attention 模块中都要用到的一个组件 ——** 多尺度的可变形注意力模块**；这个模块是将 Transformer 的全局注意力变为局部注意力的一个非常关键的组件，用于减少训练时间，提高 Transformer 的收敛速度；（该思想最早出现在 Deformable DETR 中）</p>
<p>简单概括下多尺度的可变形注意力模块对数据处理的Pipeline，概括如下：</p>
<p> <img src="/pic/BEVFormer5.png" alt="Deformable Attention 模块 Pipeline"></p>
<p>通过流程图可知，输入到 Deformable Attention Module CUDA 扩展的变量主要有五个，分别是采样位置（Sample Location）、注意力权重（Attention Weights）、映射后的 Value 特征、多尺度特征每层特征起始索引位置、多尺度特征图的空间大小（便于将采样位置由归一化的值变成绝对位置）；</p>
<p>多尺度可变形注意力模块与 Transformer 中常见的先生成 Attention Map，再计算加权和的方式不同；常规而言 Attention Map &#x3D; Query 和 Key 做内积运算，将 Attention Map 再和 Value 做加权；但是由于这种方式计算量开销会比较大，所以在 Deformable DETR 中用局部注意力机制代替了全局注意力机制，只对几个采样点进行采样，而<strong>采样点的位置相对于参考点的偏移量和每个采样点在加权时的比重均是靠 Query 经过 Linear 层学习得到的</strong>。具体可以看下图</p>
<p> <img src="/pic/BEVFormer4.png" alt="Deformable Attention 模块 "></p>
<h3 id="Temporal-Self-Attention-模块"><a href="#Temporal-Self-Attention-模块" class="headerlink" title="Temporal Self-Attention 模块"></a>Temporal Self-Attention 模块</h3><h4 id="功能"><a href="#功能" class="headerlink" title="功能"></a>功能</h4><p>通过引入时序信息（插图中的 History BEV）与当前时刻的 BEV Query 进行融合，提高 BEV Query 的建模能力；</p>
<h4 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h4><p>对于 Temporal Self-Attention 模块而言，需要 bev_query、bev_pos、prev_bev、ref_point、value等参数（需要用到的参数参考 Deformable Attention Pipeline 图解）</p>
<ul>
<li>参数 bev_query<ul>
<li>一个完全 learnable parameter，通过 nn.Embedding() 函数得到，形状 shape &#x3D; (200 * 200，256)；200，200 分别代表 BEV 特征平面的长和宽；</li>
</ul>
</li>
<li>参数 bev_pose<ul>
<li>感觉也是一个完全 learnable parameter，与 2D 检测中常见的正余弦编码方式不同，感觉依旧是把不同的 grid 位置映射到一个高维的向量空间，shape &#x3D; （bs，256，200，200）代码如下：<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token triple-quoted-string string">""" bev_pose 的生成过程 """</span>
<span class="token comment"># w, h 分别代表 bev 特征的空间尺寸 200 * 200</span>
x <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>w<span class="token punctuation">,</span> device<span class="token operator">=</span>mask<span class="token punctuation">.</span>device<span class="token punctuation">)</span>
y <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>h<span class="token punctuation">,</span> device<span class="token operator">=</span>mask<span class="token punctuation">.</span>device<span class="token punctuation">)</span>

<span class="token comment"># self.col_embed 和 self.row_embed 分别是两个 Linear 层，将(200, )的坐标向高维空间做映射</span>
x_embed <span class="token operator">=</span> self<span class="token punctuation">.</span>col_embed<span class="token punctuation">(</span>x<span class="token punctuation">)</span>  <span class="token comment"># (200, 128)</span>
y_embed <span class="token operator">=</span> self<span class="token punctuation">.</span>row_embed<span class="token punctuation">(</span>y<span class="token punctuation">)</span>  <span class="token comment"># (200, 128)</span>

<span class="token comment"># pos shape: (bs, 256, 200, 200)</span>
pos <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>x_embed<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>repeat<span class="token punctuation">(</span>h<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> y_embed<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>repeat<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> w<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>repeat<span class="token punctuation">(</span>mask<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
</ul>
</li>
<li>参数 ref_point<ul>
<li>这个参数根据当前 Temporal Self-Attention 模块是否有 prev_bev 特征输入而言，会对应不同的情况，之所以会出现不同，是考虑到了前后时刻 BEV 特征存在特征不对齐的问题，BEV 特征不对齐主要体现在以下两个方面<ul>
<li>车自身是不断运动的。上一时刻和当前时刻，由于车自身的不断运动，两个时刻的 BEV 特征在空间上是不对齐的；针对这一问题，为了实现两个时刻特征的空间对齐，需要用到 can_bus 数据中有关车自身旋转角度和偏移的信息，从而对上一时刻的 BEV 特征与当前时刻的 BEV 特征在空间上实现特征对齐；</li>
<li>车周围的物体也在一定范围内运动。针对车周围的物体可能在不同时刻也有移动，这部分的特征对齐就是靠网络自身的注意力模块去学习实现修正了。</li>
</ul>
</li>
<li>综上，对于 Temporal Self-Attention 模块没有输入 prev_bev（第一帧没有前一时刻的 BEV 特征）的情况，其 ref_point &#x3D; ref_2d；对于存在输入 prev_bev 的情况，其 ref_point &#x3D; ref_2d + shift；</li>
<li>涉及到的ref_2d、shift参数，核心代码如下：</li>
</ul>
</li>
</ul>
 <pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token triple-quoted-string string">"""shift 参数的生成"""</span> 
<span class="token comment"># obtain rotation angle and shift with ego motion</span>
delta_x <span class="token operator">=</span> kwargs<span class="token punctuation">[</span><span class="token string">'img_metas'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'can_bus'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
delta_y <span class="token operator">=</span> kwargs<span class="token punctuation">[</span><span class="token string">'img_metas'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'can_bus'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
ego_angle <span class="token operator">=</span> kwargs<span class="token punctuation">[</span><span class="token string">'img_metas'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'can_bus'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">/</span> np<span class="token punctuation">.</span>pi <span class="token operator">*</span> <span class="token number">180</span>
rotation_angle <span class="token operator">=</span> kwargs<span class="token punctuation">[</span><span class="token string">'img_metas'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'can_bus'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>
grid_length_y <span class="token operator">=</span> grid_length<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
grid_length_x <span class="token operator">=</span> grid_length<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
translation_length <span class="token operator">=</span> np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>delta_x <span class="token operator">**</span> <span class="token number">2</span> <span class="token operator">+</span> delta_y <span class="token operator">**</span> <span class="token number">2</span><span class="token punctuation">)</span>
translation_angle <span class="token operator">=</span> np<span class="token punctuation">.</span>arctan2<span class="token punctuation">(</span>delta_y<span class="token punctuation">,</span> delta_x<span class="token punctuation">)</span> <span class="token operator">/</span> np<span class="token punctuation">.</span>pi <span class="token operator">*</span> <span class="token number">180</span>
<span class="token keyword">if</span> translation_angle <span class="token operator">&lt;</span> <span class="token number">0</span><span class="token punctuation">:</span>
   translation_angle <span class="token operator">+=</span> <span class="token number">360</span>
bev_angle <span class="token operator">=</span> ego_angle <span class="token operator">-</span> translation_angle
shift_y <span class="token operator">=</span> translation_length <span class="token operator">*</span> \
   np<span class="token punctuation">.</span>cos<span class="token punctuation">(</span>bev_angle <span class="token operator">/</span> <span class="token number">180</span> <span class="token operator">*</span> np<span class="token punctuation">.</span>pi<span class="token punctuation">)</span> <span class="token operator">/</span> grid_length_y <span class="token operator">/</span> bev_h
shift_x <span class="token operator">=</span> translation_length <span class="token operator">*</span> \
   np<span class="token punctuation">.</span>sin<span class="token punctuation">(</span>bev_angle <span class="token operator">/</span> <span class="token number">180</span> <span class="token operator">*</span> np<span class="token punctuation">.</span>pi<span class="token punctuation">)</span> <span class="token operator">/</span> grid_length_x <span class="token operator">/</span> bev_w
shift_y <span class="token operator">=</span> shift_y <span class="token operator">*</span> self<span class="token punctuation">.</span>use_shift
shift_x <span class="token operator">=</span> shift_x <span class="token operator">*</span> self<span class="token punctuation">.</span>use_shift
shift <span class="token operator">=</span> bev_queries<span class="token punctuation">.</span>new_tensor<span class="token punctuation">(</span><span class="token punctuation">[</span>shift_x<span class="token punctuation">,</span> shift_y<span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># shape (2,) </span>

<span class="token comment"># 通过`旋转`和`平移`变换实现 BEV 特征的对齐，对于平移部分是通过对参考点加上偏移量`shift`体现的</span>
<span class="token keyword">if</span> prev_bev <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
   <span class="token keyword">if</span> prev_bev<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">==</span> bev_h <span class="token operator">*</span> bev_w<span class="token punctuation">:</span>
      prev_bev <span class="token operator">=</span> prev_bev<span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
   <span class="token keyword">if</span> self<span class="token punctuation">.</span>rotate_prev_bev<span class="token punctuation">:</span>
      num_prev_bev <span class="token operator">=</span> prev_bev<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
      prev_bev <span class="token operator">=</span> prev_bev<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>bev_h<span class="token punctuation">,</span> bev_w<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># sequence -> grid</span>
      prev_bev <span class="token operator">=</span> rotate<span class="token punctuation">(</span>prev_bev<span class="token punctuation">,</span> rotation_angle<span class="token punctuation">,</span> center<span class="token operator">=</span>self<span class="token punctuation">.</span>rotate_center<span class="token punctuation">)</span>
      prev_bev <span class="token operator">=</span> prev_bev<span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>bev_h <span class="token operator">*</span> bev_w<span class="token punctuation">,</span> num_prev_bev<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>

<span class="token triple-quoted-string string">"""ref_2d 参数的生成，常规的 2D 网格生成的规则坐标点"""</span>
ref_y<span class="token punctuation">,</span> ref_x <span class="token operator">=</span> torch<span class="token punctuation">.</span>meshgrid<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> H <span class="token operator">-</span> <span class="token number">0.5</span><span class="token punctuation">,</span> H<span class="token punctuation">,</span> dtype<span class="token operator">=</span>dtype<span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span>
                              torch<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> W <span class="token operator">-</span> <span class="token number">0.5</span><span class="token punctuation">,</span> W<span class="token punctuation">,</span> dtype<span class="token operator">=</span>dtype<span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span>
ref_y <span class="token operator">=</span> ref_y<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">]</span> <span class="token operator">/</span> H
ref_x <span class="token operator">=</span> ref_x<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">]</span> <span class="token operator">/</span> W
ref_2d <span class="token operator">=</span> torch<span class="token punctuation">.</span>stack<span class="token punctuation">(</span><span class="token punctuation">(</span>ref_x<span class="token punctuation">,</span> ref_y<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
ref_2d <span class="token operator">=</span> ref_2d<span class="token punctuation">.</span>repeat<span class="token punctuation">(</span>bs<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<ul>
<li><p>参数 value</p>
<ul>
<li>对应着bev_query去查询的特征；<ul>
<li>对于 Temporal Self-Attention 模块输入包含 prev_bev时，value &#x3D; [prev_bev，bev_query]，对应的参考点 ref_point &#x3D; [ref_2d + shift，ref_2d]；如果输入不包含 prev_bev时，value &#x3D; [bev_query，bev_query]，对应的参考点ref_point &#x3D; [ref_2d，ref_2d]。</li>
<li>相应的，之前介绍的 bev_query 在输入包含 prev_bev时，bev_query &#x3D; [value[0]，bev_query]；输入不包含 prev_bev时，value &#x3D; [bev_query，bev_query]；</li>
<li>整体的思路还是计算在计算 self-attention，无论是否存在prev_bev，都是在计算prev_bev以及bev_query自身的相似性，最后将两组计算得到的bev_query结果做一下平均。</li>
</ul>
</li>
</ul>
</li>
<li><p>内部参数 Offset、Weights、 Sample Location</p>
<ul>
<li>参数Offset的计算是同时考虑了value[0]和bev_query的信息，在映射空间的维度上进行了concat，并基于 concat 后的特征，去计算 Offset以及attention weights ，涉及到的核心代码如下，这里解释一下为什么 level &#x3D; 1，由于 BEV 特征只有一层，所以只会对一层 200 * 200 空间大小的 BEV 特征，基于每个位置采样四个点，重新构造新的 BEV 特征；</li>
</ul>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token triple-quoted-string string">""" bev_query 按照通道维度进行 concat """</span>
query <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>value<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">:</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> query<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># (bs, 40000, 512)</span>

<span class="token triple-quoted-string string">""" value 经过 Linear 做映射 """</span>
value <span class="token operator">=</span> self<span class="token punctuation">.</span>value_proj<span class="token punctuation">(</span>value<span class="token punctuation">)</span>

<span class="token triple-quoted-string string">""" offsets 以及 attention weights 的生成过程 """</span>
<span class="token comment"># sampling_offsets: shape = (bs, num_query, 8, 1, 4, 2)</span>
<span class="token comment"># 对 query 进行维度映射得到采样点的偏移量</span>
sampling_offsets <span class="token operator">=</span> self<span class="token punctuation">.</span>sampling_offsets<span class="token punctuation">(</span>query<span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span>bs<span class="token punctuation">,</span> num_query<span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_heads<span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_levels<span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_points<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>

<span class="token comment"># 对 query 进行维度映射得到注意力权重</span>
attention_weights <span class="token operator">=</span> self<span class="token punctuation">.</span>attention_weights<span class="token punctuation">(</span>query<span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span>bs<span class="token punctuation">,</span> num_query<span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_heads<span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_levels <span class="token operator">*</span> self<span class="token punctuation">.</span>num_points<span class="token punctuation">)</span>  
attention_weights <span class="token operator">=</span> attention_weights<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>

<span class="token comment"># attention_weights: shape = (bs, num_query, 8, 1, 4)</span>
attention_weights <span class="token operator">=</span> attention_weights<span class="token punctuation">.</span>view<span class="token punctuation">(</span>bs<span class="token punctuation">,</span> num_query<span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_heads<span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_levels<span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_points<span class="token punctuation">)</span> 

<span class="token triple-quoted-string string">""" sample location 的生成过程 
通过代码可以观察到两点：
1. 通过 query 学到的 sampling_offsets 偏移量是一个绝对量，不是相对量，所以需要做 normalize；
2. 最终生成的 sampling_locations 是一个相对量；
"""</span>
offset_normalizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>stack<span class="token punctuation">(</span><span class="token punctuation">[</span>spatial_shapes<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> spatial_shapes<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
sampling_locations <span class="token operator">=</span> reference_points<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span> \
               <span class="token operator">+</span> sampling_offsets <span class="token operator">/</span> offset_normalizer<span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
</li>
<li><p>输出bev query</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token triple-quoted-string string">""" 各个参数的 shape 情况 
1. value: (2，40000，8，32） # 2: 代表前一时刻的 BEV 特征和后一时刻的 BEV 特征，两个特征在计算的过程中是互不干扰的，
                           # 40000: 代表 bev_query 200 * 200 空间大小的每个位置
                           # 8: 代表8个头，# 32: 每个头表示为 32 维的特征
2. spatial_shapes: (200, 200) # 方便将归一化的 sampling_locations 反归一化
3. level_start_index: 0 # BEV 特征只有一层
4. sampling_locations: (2, 40000, 8, 1, 4, 2)
5. attention_weights: (2, 40000, 8, 1, 4)

6. output: (2, 40000, 8, 32)
"""</span>
output <span class="token operator">=</span> MultiScaleDeformableAttnFunction<span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span>value<span class="token punctuation">,</span> 
                                                spatial_shapes<span class="token punctuation">,</span> 
                                                level_start_index<span class="token punctuation">,</span> 
                                                sampling_locations<span class="token punctuation">,</span>
                                                attention_weights<span class="token punctuation">,</span> 
                                                self<span class="token punctuation">.</span>im2col_step<span class="token punctuation">)</span>

<span class="token string">""</span>" 最后将前一时刻的 bev_query 与当前时刻的 bev_query 做平均
output <span class="token operator">=</span> output<span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>
output <span class="token operator">=</span> <span class="token punctuation">(</span>output<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token punctuation">:</span>bs<span class="token punctuation">]</span> <span class="token operator">+</span> output<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> bs<span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">/</span>self<span class="token punctuation">.</span>num_bev_queue<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
</ul>
<p>至此，Temporal Self-Attention 模块的逻辑到此结束，将生成的 bev_query 送入到后面的 Spatial Cross-Attention 模块中。</p>
<h3 id="Spatial-Cross-Attention-模块"><a href="#Spatial-Cross-Attention-模块" class="headerlink" title="Spatial Cross-Attention 模块"></a>Spatial Cross-Attention 模块</h3><h4 id="功能-1"><a href="#功能-1" class="headerlink" title="功能"></a>功能</h4><p>利用 Temporal Self-Attention 模块输出的 bev_query， 对主干网络和 Neck 网络提取到的多尺度环视图像特征进行查询，生成 BEV 空间下的BEV Embedding特征；</p>
<h4 id="代码实现-1"><a href="#代码实现-1" class="headerlink" title="代码实现"></a>代码实现</h4><p>对于 Spatial Cross-Attention 模块而言，与 Temporal Self-Attention 模块需要的参数很类似，但是并不需要 bev_pos 参数，只需要 bev_query、ref_point、value（就是 concat 到一起的多尺度特征）；虽不需要 bev_pose，但是整体流程与 Deformable Attention Pipeline 图解类似</p>
<ul>
<li><p>参数bev_query</p>
<ul>
<li>bev_query参数来自于 Temporal Self-Attention 模块的输出；</li>
</ul>
</li>
<li><p>参数value</p>
<ul>
<li>对于 Transformer 而言，由于其本身是处理文本序列的模型，而文本序列都是一组组一维的数据，所以需要将前面提取的多尺度特征做 flatten() 处理，并将所有层的特征汇聚到一起，方便之后做查询；对应的核心代码如下：<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token triple-quoted-string string">""" 首先将多尺度的特征每一层都进行 flatten() """</span>
<span class="token keyword">for</span> lvl<span class="token punctuation">,</span> feat <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>mlvl_feats<span class="token punctuation">)</span><span class="token punctuation">:</span>
   bs<span class="token punctuation">,</span> num_cam<span class="token punctuation">,</span> c<span class="token punctuation">,</span> h<span class="token punctuation">,</span> w <span class="token operator">=</span> feat<span class="token punctuation">.</span>shape
   spatial_shape <span class="token operator">=</span> <span class="token punctuation">(</span>h<span class="token punctuation">,</span> w<span class="token punctuation">)</span>
   feat <span class="token operator">=</span> feat<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>  
   <span class="token keyword">if</span> self<span class="token punctuation">.</span>use_cams_embeds<span class="token punctuation">:</span>
      feat <span class="token operator">=</span> feat <span class="token operator">+</span> self<span class="token punctuation">.</span>cams_embeds<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>feat<span class="token punctuation">.</span>dtype<span class="token punctuation">)</span>
      feat <span class="token operator">=</span> feat <span class="token operator">+</span> self<span class="token punctuation">.</span>level_embeds<span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">,</span> lvl<span class="token punctuation">:</span>lvl <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>feat<span class="token punctuation">.</span>dtype<span class="token punctuation">)</span>
      spatial_shapes<span class="token punctuation">.</span>append<span class="token punctuation">(</span>spatial_shape<span class="token punctuation">)</span>
      feat_flatten<span class="token punctuation">.</span>append<span class="token punctuation">(</span>feat<span class="token punctuation">)</span>

<span class="token triple-quoted-string string">""" 对每个 camera 的所有层级特征进行汇聚 """</span>
feat_flatten <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span>feat_flatten<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>  <span class="token comment"># (cam, bs, sum(h*w), 256)</span>
spatial_shapes <span class="token operator">=</span> torch<span class="token punctuation">.</span>as_tensor<span class="token punctuation">(</span>spatial_shapes<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">,</span> device<span class="token operator">=</span>bev_pos<span class="token punctuation">.</span>device<span class="token punctuation">)</span>

<span class="token comment"># 计算每层特征的起始索引位置</span>
level_start_index <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>spatial_shapes<span class="token punctuation">.</span>new_zeros<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> spatial_shapes<span class="token punctuation">.</span>prod<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cumsum<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># 维度变换</span>
feat_flatten <span class="token operator">=</span> feat_flatten<span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>  <span class="token comment"># (num_cam, sum(H*W), bs, embed_dims)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
</ul>
</li>
<li><p>参数ref_point</p>
<ul>
<li><p>首先说一下ref_3d坐标点，这个ref_3d是基于 BEV 空间产生的三维空间规则网格点，同时在 z 轴方向上人为的选择了 4 个坐标点。</p>
</li>
<li><p>这里要使用 z 轴，并在 z 轴方向上采样的物理意义，我的理解是为了提取每个 BEV 位置处不同高度的特征；可以理解一下，假如对于 BEV 平面上的（x，y）处有一辆汽车，它所对应的特征应该由车底、车身、车顶处等位置的特征汇聚而成，但是这些位置对应的高度是不一致的，而为了更好的获取在 BEV 空间下的（x，y）处的特征，就将（x，y）的坐标进行了 lift ，从而将 BEV 坐标系下的三维点映射回图像平面后可以去查询并融合更加准确的特征；</p>
</li>
<li><p>而在映射的过程中，论文中也提到，由于每个参考点映射回图像坐标系后，不会落到六个图像上，只可能落在其中的某些图像的某些位置上，所以只对这些参考点附近的位置进行采样，可以提高模型的收敛速度（借鉴了 Deformable DETR 的思想）如下图所示：<br><img src="/pic/BEVFormer6.png"></p>
</li>
<li><p>ref_3d参数生成、3D 坐标向图像平面转换等过程的核心代码如下，真正用在 Spatial Cross-Attention 模块中的参考点是下面代码段中的reference_points_cam 。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token triple-quoted-string string">""" ref_3d 坐标生成 """</span>
zs <span class="token operator">=</span> torch<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> Z <span class="token operator">-</span> <span class="token number">0.5</span><span class="token punctuation">,</span> num_points_in_pillar<span class="token punctuation">,</span> dtype<span class="token operator">=</span>dtype<span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>expand<span class="token punctuation">(</span>num_points_in_pillar<span class="token punctuation">,</span> H<span class="token punctuation">,</span> W<span class="token punctuation">)</span> <span class="token operator">/</span> Z
xs <span class="token operator">=</span> torch<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> W <span class="token operator">-</span> <span class="token number">0.5</span><span class="token punctuation">,</span> W<span class="token punctuation">,</span> dtype<span class="token operator">=</span>dtype<span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> W<span class="token punctuation">)</span><span class="token punctuation">.</span>expand<span class="token punctuation">(</span>num_points_in_pillar<span class="token punctuation">,</span> H<span class="token punctuation">,</span> W<span class="token punctuation">)</span> <span class="token operator">/</span> W
ys <span class="token operator">=</span> torch<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> H <span class="token operator">-</span> <span class="token number">0.5</span><span class="token punctuation">,</span> H<span class="token punctuation">,</span> dtype<span class="token operator">=</span>dtype<span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> H<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>expand<span class="token punctuation">(</span>num_points_in_pillar<span class="token punctuation">,</span> H<span class="token punctuation">,</span> W<span class="token punctuation">)</span> <span class="token operator">/</span> H
ref_3d <span class="token operator">=</span> torch<span class="token punctuation">.</span>stack<span class="token punctuation">(</span><span class="token punctuation">(</span>xs<span class="token punctuation">,</span> ys<span class="token punctuation">,</span> zs<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># (4, 200, 200, 3)  (level, bev_h, bev_w, 3) 3代表 x,y,z 坐标值</span>
ref_3d <span class="token operator">=</span> ref_3d<span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>flatten<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># (4, 200 * 200, 3)</span>
ref_3d <span class="token operator">=</span> ref_3d<span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">]</span><span class="token punctuation">.</span>repeat<span class="token punctuation">(</span>bs<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># (1, 4, 200 * 200, 3)</span>

<span class="token triple-quoted-string string">""" BEV 空间下的三维坐标点向图像空间转换的过程
代码中的`lidar2img`需要有两点需要注意
1. BEV 坐标系 这里指 lidar 坐标系
2. 这里提到的`lidar2img`是经过坐标变换的，一般分成三步
   第一步：lidar 坐标系 -> ego vehicle 坐标系
   第二步：ego vehicle 坐标系 -> camera 坐标系
   第三部：camera 坐标系 通过相机内参 得到像素坐标系
   以上这三步用到的所有平移和旋转矩阵都合并到了一起，形成了 `lidar2img` 旋转平移矩阵

同时需要注意：再与`lidar2img`矩阵乘完，还需要经过下面两步坐标系转换，才是得到了三维坐标点在二维图像平面上的点
"""</span>
<span class="token comment"># (level, bs, cam, num_query, 4)</span>
坐标系转换第一步：reference_points_cam <span class="token operator">=</span> torch<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>lidar2img<span class="token punctuation">.</span>to<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token punctuation">,</span> reference_points<span class="token punctuation">.</span>to<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>  
eps <span class="token operator">=</span> <span class="token number">1e-5</span>
bev_mask <span class="token operator">=</span> <span class="token punctuation">(</span>reference_points_cam<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">:</span><span class="token number">3</span><span class="token punctuation">]</span> <span class="token operator">></span> eps<span class="token punctuation">)</span>  <span class="token comment"># (level, bs, cam, num_query, 1)</span>
坐标系转换第二步：reference_points_cam <span class="token operator">=</span> reference_points_cam<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">/</span> torch<span class="token punctuation">.</span>maximum<span class="token punctuation">(</span>reference_points_cam<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">:</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>ones_like<span class="token punctuation">(</span>reference_points_cam<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">:</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">*</span> eps<span class="token punctuation">)</span>

<span class="token comment"># reference_points_cam = (bs, cam = 6, 40000, level = 4, xy = 2)</span>
reference_points_cam<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">/=</span> img_metas<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'img_shape'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>  <span class="token comment"># 坐标归一化</span>
reference_points_cam<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">/=</span> img_metas<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'img_shape'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>  <span class="token comment"># 坐标归一化</span>

<span class="token comment"># bev_mask 用于评判某一 三维坐标点 是否落在了 二维坐标平面上</span>
<span class="token comment"># bev_mask = (bs, cam = 6, 40000, level = 4)</span>
bev_mask <span class="token operator">=</span> <span class="token punctuation">(</span>bev_mask <span class="token operator">&amp;</span> <span class="token punctuation">(</span>reference_points_cam<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">></span> <span class="token number">0.0</span><span class="token punctuation">)</span>
                     <span class="token operator">&amp;</span> <span class="token punctuation">(</span>reference_points_cam<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">&lt;</span> <span class="token number">1.0</span><span class="token punctuation">)</span>
                     <span class="token operator">&amp;</span> <span class="token punctuation">(</span>reference_points_cam<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">:</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">&lt;</span> <span class="token number">1.0</span><span class="token punctuation">)</span>
                     <span class="token operator">&amp;</span> <span class="token punctuation">(</span>reference_points_cam<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">:</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">></span> <span class="token number">0.0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
</ul>
</li>
</ul>
<p>需要注意的是，上述得到的bev_query以及reference_points_cam参数并不是直接用在了 Spatial Cross-Attention 模块中，而是选择了有用的部分进行使用（减少模型的计算量，提高训练过程的收敛速度），这里还是根据 Deformable Attention Pipeline 中涉及的参数进行说明：</p>
<ul>
<li><p>参数queries_rebatch</p>
<ul>
<li>之前也有提到，并不是 BEV 坐标系下的每个三维坐标都会映射到环视相机的所有图像上，而只会映射到其中的某几张图片上，所以使用所有来自 Temporal Self-Attention 模块的所有bev_query会消耗很大的计算量，所以这里是对bev_query进行了重新的整合，涉及的核心代码如下：<pre class="line-numbers language-python" data-language="python"><code class="language-python">   indexes <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token comment"># 根据每张图片对应的`bev_mask`结果，获取有效query的index</span>
<span class="token keyword">for</span> i<span class="token punctuation">,</span> mask_per_img <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>bev_mask<span class="token punctuation">)</span><span class="token punctuation">:</span>
   index_query_per_img <span class="token operator">=</span> mask_per_img<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>nonzero<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
   indexes<span class="token punctuation">.</span>append<span class="token punctuation">(</span>index_query_per_img<span class="token punctuation">)</span>

queries_rebatch <span class="token operator">=</span> query<span class="token punctuation">.</span>new_zeros<span class="token punctuation">(</span><span class="token punctuation">[</span>bs <span class="token operator">*</span> self<span class="token punctuation">.</span>num_cams<span class="token punctuation">,</span> max_len<span class="token punctuation">,</span> self<span class="token punctuation">.</span>embed_dims<span class="token punctuation">]</span><span class="token punctuation">)</span>
reference_points_rebatch <span class="token operator">=</span> reference_points_cam<span class="token punctuation">.</span>new_zeros<span class="token punctuation">(</span><span class="token punctuation">[</span>bs <span class="token operator">*</span> self<span class="token punctuation">.</span>num_cams<span class="token punctuation">,</span> max_len<span class="token punctuation">,</span> D<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span> 

<span class="token keyword">for</span> i<span class="token punctuation">,</span> reference_points_per_img <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>reference_points_cam<span class="token punctuation">)</span><span class="token punctuation">:</span>
   <span class="token keyword">for</span> j <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>bs<span class="token punctuation">)</span><span class="token punctuation">:</span>
      index_query_per_img <span class="token operator">=</span> indexes<span class="token punctuation">[</span>i<span class="token punctuation">]</span>

      <span class="token comment"># 重新整合 `bev_query` 特征，记作 `query_rebatch</span>
      queries_rebatch<span class="token punctuation">[</span>j <span class="token operator">*</span> self<span class="token punctuation">.</span>num_cams <span class="token operator">+</span> i<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token builtin">len</span><span class="token punctuation">(</span>index_query_per_img<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> query<span class="token punctuation">[</span>j<span class="token punctuation">,</span> index_query_per_img<span class="token punctuation">]</span>

      <span class="token comment"># 重新整合 `reference_point`采样位置，记作`reference_points_rebatch`</span>
      reference_points_rebatch<span class="token punctuation">[</span>j <span class="token operator">*</span> self<span class="token punctuation">.</span>num_cams <span class="token operator">+</span> i<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token builtin">len</span><span class="token punctuation">(</span>index_query_per_img<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> reference_points_per_img<span class="token punctuation">[</span>j<span class="token punctuation">,</span> index_query_per_img<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
</ul>
</li>
<li><p>参数reference_points_rebatch</p>
<ul>
<li>与产生query_rebatch的原因相同，获得映射到二维图像后的有效位置，对原有的reference_points进行重新的整合reference_points_rebatch。</li>
</ul>
</li>
<li><p>内部参数Offset、Weights、Sample Locations</p>
</li>
</ul>
 <pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token triple-quoted-string string">""" 获取 sampling_offsets，依旧是对 query 做 Linear 做维度的映射，但是需要注意的是
这里的 query 指代的是上面提到的 `quries_rebatch` """</span>
<span class="token comment"># sample 8 points for single ref point in each level.</span>

<span class="token comment"># sampling_offsets: shape = (bs, max_len, 8, 4, 8, 2)</span>
sampling_offsets <span class="token operator">=</span> self<span class="token punctuation">.</span>sampling_offsets<span class="token punctuation">(</span>query<span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span>bs<span class="token punctuation">,</span> num_query<span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_heads<span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_levels<span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_points<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
attention_weights <span class="token operator">=</span> self<span class="token punctuation">.</span>attention_weights<span class="token punctuation">(</span>query<span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span>bs<span class="token punctuation">,</span> num_query<span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_heads<span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_levels <span class="token operator">*</span> self<span class="token punctuation">.</span>num_points<span class="token punctuation">)</span>

attention_weights <span class="token operator">=</span> attention_weights<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>

<span class="token comment"># attention_weights: shape = (bs, max_len, 8, 4, 8)</span>
attention_weights <span class="token operator">=</span> attention_weights<span class="token punctuation">.</span>view<span class="token punctuation">(</span>bs<span class="token punctuation">,</span> num_query<span class="token punctuation">,</span>
                                          self<span class="token punctuation">.</span>num_heads<span class="token punctuation">,</span>
                                          self<span class="token punctuation">.</span>num_levels<span class="token punctuation">,</span>
                                          self<span class="token punctuation">.</span>num_points<span class="token punctuation">)</span>

<span class="token triple-quoted-string string">""" 生成 sampling location """</span>
offset_normalizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>stack<span class="token punctuation">(</span><span class="token punctuation">[</span>spatial_shapes<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> spatial_shapes<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>

reference_points <span class="token operator">=</span> reference_points<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>
sampling_offsets <span class="token operator">=</span> sampling_offsets <span class="token operator">/</span> offset_normalizer<span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>
sampling_locations <span class="token operator">=</span> reference_points <span class="token operator">+</span> sampling_offsets<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<ul>
<li>输出bev_embedding</li>
<li>将上述处理好的参数，送入到多尺度可变形注意力模块中生成bev_embedding特征；</li>
</ul>
  <pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token triple-quoted-string string">"""
1. value: shape = (cam = 6, sum(h_i * w_i) = 30825, head = 8, dim = 32)
2. spatial_shapes = ([[116, 200], [58, 100], [29,  50], [15,  25]])
3. level_start_index= [0, 23200, 29000, 30450]
4. sampling_locations = (cam, max_len, 8, 4, 8, 2)
5. attention_weights = (cam, max_len, 8, 4, 8)

6. output = (cam, max_len, 8, 32)
"""</span>
output <span class="token operator">=</span> MultiScaleDeformableAttnFunction<span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span>value<span class="token punctuation">,</span> spatial_shapes<span class="token punctuation">,</span> level_start_index<span class="token punctuation">,</span> sampling_locations<span class="token punctuation">,</span>
               attention_weights<span class="token punctuation">,</span> self<span class="token punctuation">.</span>im2col_step<span class="token punctuation">)</span>

<span class="token triple-quoted-string string">"""最后再将六个环视相机查询到的特征整合到一起，再求一个平均值 """</span>
<span class="token keyword">for</span> i<span class="token punctuation">,</span> index_query_per_img <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>indexes<span class="token punctuation">)</span><span class="token punctuation">:</span>
   <span class="token keyword">for</span> j <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>bs<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># slots: (bs, 40000, 256)</span>
      slots<span class="token punctuation">[</span>j<span class="token punctuation">,</span> index_query_per_img<span class="token punctuation">]</span> <span class="token operator">+=</span> queries<span class="token punctuation">[</span>j <span class="token operator">*</span> self<span class="token punctuation">.</span>num_cams <span class="token operator">+</span> i<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token builtin">len</span><span class="token punctuation">(</span>index_query_per_img<span class="token punctuation">)</span><span class="token punctuation">]</span>

count <span class="token operator">=</span> bev_mask<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">></span> <span class="token number">0</span>
count <span class="token operator">=</span> count<span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
count <span class="token operator">=</span> torch<span class="token punctuation">.</span>clamp<span class="token punctuation">(</span>count<span class="token punctuation">,</span> <span class="token builtin">min</span><span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">)</span>
slots <span class="token operator">=</span> slots <span class="token operator">/</span> count<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">]</span>  <span class="token comment"># maybe normalize.</span>
slots <span class="token operator">=</span> self<span class="token punctuation">.</span>output_proj<span class="token punctuation">(</span>slots<span class="token punctuation">)</span>
  <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>以上就是 Spatial Cross-Attention 模块的整体逻辑。</p>
<p>将 Temporal Self-Attetion 模块和 Spatial Cross-Attention 模块堆叠在一起，并重复六次，最终得到的 BEV Embedding 特征作为下游 3D 目标检测和道路分割任务的 BEV 空间特征。</p>
<h2 id="Decoder模块"><a href="#Decoder模块" class="headerlink" title="Decoder模块"></a>Decoder模块</h2><p>上述产生 BEV 特征的过程是用了当前输入到网络模型中除当前帧外，之前所有帧的特征去迭代修正去获得prev_bev的特征；所以在利用 Decoder 模块进行解码之前，<strong>需要对当前时刻环视的 6 张图片同样利用 Backbone + Neck 提取多尺度的特征，然后利用上述的 Temporal Self-Attention 模块和 Spatial Cross-Attention 模块的逻辑生成当前时刻的bev_embedding</strong>，然后将这部分特征送入到 Decoder 中进行 3D 目标检测。</p>
<p>下面分析 Decoder 模块是如何获得预测框和分类得分的。</p>
<ul>
<li><p>query、query_pos </p>
<ul>
<li>首先是object_query_embed参数，该参数同样是沿用了 2D 目标检测中的 Deformable DETR 的思想。query和query_pose 全都是可学习的。模型直接用 nn.Embedding() 生成一组（900，512）维的张量。然后将 512 维的张量分成两组，分别构成了query &#x3D; (900，256)和query_pos &#x3D; (900，256) 。</li>
</ul>
</li>
<li><p>referece_points</p>
<ul>
<li>之前介绍过，对于多尺度可变形注意力模块是需要参考点的，但是在预测过程中是没有参考点的，这就需要网络学习出来，网络是靠 query_pos学习得到的，核心代码如下：<pre class="line-numbers language-python" data-language="python"><code class="language-python">reference_points <span class="token operator">=</span> self<span class="token punctuation">.</span>reference_points<span class="token punctuation">(</span>query_pos<span class="token punctuation">)</span>  <span class="token comment"># (bs, 900, 3)  3 代表 (x, y, z) 坐标</span>
reference_points <span class="token operator">=</span> reference_points<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># absolute -> relative</span>
init_reference_out <span class="token operator">=</span> reference_points <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li>
</ul>
</li>
<li><p>Decoder 逻辑</p>
<ul>
<li>在获取到需要用到的query、query_pos、reference_points参数后，后面的逻辑有些类似 Deformabe DETR 的 Decoder 过程，简单概括如下几点：<ul>
<li>利用query和query_pos去做常规的 Self-Attention 运算更新query；</li>
<li>利用 Self-Attention 得到的 query，之前获得的 bev_embedding作为value，query_pos，由 query生成的reference_points（虽然生成的x，y，z参考点位置，但是 BEV Embedding 是二维的，所以参考点只选择了前两维）仿照 Deformable Attention Module 的 pipeline 做可变形注意力；</li>
</ul>
</li>
<li>可变形注意力核心代码如下：</li>
</ul>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">   <span class="token triple-quoted-string string">""" 由 query 生成 sampling_offsets 和 attention_weights """</span>
sampling_offsets <span class="token operator">=</span> self<span class="token punctuation">.</span>sampling_offsets<span class="token punctuation">(</span>query<span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span>
            bs<span class="token punctuation">,</span> num_query<span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_heads<span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_levels<span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_points<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>  <span class="token comment"># (bs, 900, 8, 1, 4, 2)</span>
attention_weights <span class="token operator">=</span> self<span class="token punctuation">.</span>attention_weights<span class="token punctuation">(</span>query<span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span>
            bs<span class="token punctuation">,</span> num_query<span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_heads<span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_levels <span class="token operator">*</span> self<span class="token punctuation">.</span>num_points<span class="token punctuation">)</span>  <span class="token comment"># (bs, 900, 8, 4)</span>
attention_weights <span class="token operator">=</span> attention_weights<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
attention_weights <span class="token operator">=</span> attention_weights<span class="token punctuation">.</span>view<span class="token punctuation">(</span>bs<span class="token punctuation">,</span> num_query<span class="token punctuation">,</span>
                                                   self<span class="token punctuation">.</span>num_heads<span class="token punctuation">,</span>
                                                   self<span class="token punctuation">.</span>num_levels<span class="token punctuation">,</span>
                                                   self<span class="token punctuation">.</span>num_points<span class="token punctuation">)</span>  <span class="token comment"># (bs, 900, 8, 1, 4)</span>

<span class="token triple-quoted-string string">""" sampling_offsets 和 reference_points 得到 sampling_locations """</span>
offset_normalizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>stack<span class="token punctuation">(</span>
               <span class="token punctuation">[</span>spatial_shapes<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> spatial_shapes<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
sampling_locations <span class="token operator">=</span> reference_points<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span> \
               <span class="token operator">+</span> sampling_offsets \
               <span class="token operator">/</span> offset_normalizer<span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>

<span class="token triple-quoted-string string">""" 多尺度可变形注意力模块 """</span>
<span class="token comment"># value: shape = (bs, 40000, 8, 32)</span>
<span class="token comment"># spatial_shapes = (200, 200)</span>
<span class="token comment"># level_start_index = 0</span>
<span class="token comment"># sampling_locations = (bs, 900, 8, 1, 4, 2)</span>
<span class="token comment"># attention_weights = (bs, 900, 8, 1, 4)</span>

<span class="token comment"># output = (bs, 900, 256)</span>
output <span class="token operator">=</span> MultiScaleDeformableAttnFunction<span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span>value<span class="token punctuation">,</span> spatial_shapes<span class="token punctuation">,</span> level_start_index<span class="token punctuation">,</span> sampling_locations<span class="token punctuation">,</span>
               attention_weights<span class="token punctuation">,</span> self<span class="token punctuation">.</span>im2col_step<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<ul>
<li><p>在获得查询到的特征后，会利用回归分支（FFN 网络）对提取的特征计算回归结果，预测 10 个输出；</p>
<ul>
<li>这 10 个维度的含义为：[xc，yc，w，l，zc，h，rot.sin()，rot.cos()，vx，vy]；</li>
<li>[预测框中心位置的x方向偏移，预测框中心位置的y方向偏移，预测框的宽，预测框的长，预测框中心位置的z方向偏移，预测框的高，旋转角的正弦值，旋转角的余弦值，x方向速度，y方向速度]；</li>
</ul>
</li>
<li><p>然后根据预测的偏移量，对参考点的位置进行更新，为级联的下一个 Decoder 提高精修过的参考点位置，核心代码如下：</p>
</li>
</ul>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">if</span> reg_branches <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>  <span class="token comment"># update the reference point.</span>
 tmp <span class="token operator">=</span> reg_branches<span class="token punctuation">[</span>lid<span class="token punctuation">]</span><span class="token punctuation">(</span>output<span class="token punctuation">)</span>  <span class="token comment"># (bs, 900, 256) -> (bs, 900, 10) 回归分支的预测输出</span>
 <span class="token keyword">assert</span> reference_points<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token number">3</span>
 new_reference_points <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros_like<span class="token punctuation">(</span>reference_points<span class="token punctuation">)</span>

 <span class="token comment"># 预测出来的偏移量是绝对量</span>
 new_reference_points<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">=</span> tmp<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">+</span> inverse_sigmoid<span class="token punctuation">(</span>reference_points<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># 框中心处的 x, y 坐标</span>
 new_reference_points<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">:</span><span class="token number">3</span><span class="token punctuation">]</span> <span class="token operator">=</span> tmp<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">:</span><span class="token number">5</span><span class="token punctuation">]</span> <span class="token operator">+</span> inverse_sigmoid<span class="token punctuation">(</span>reference_points<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">:</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># 框中心处的 z 坐标</span>

 <span class="token comment"># 参考点坐标是一个归一化的坐标</span>
 new_reference_points <span class="token operator">=</span> new_reference_points<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span>
 reference_points <span class="token operator">=</span> new_reference_points<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token triple-quoted-string string">""" 
最后将每层 Decoder 产生的特征 = (bs, 900, 256)，以及参考点坐标 = (bs, 900, 3) 保存下来。
"""</span>
<span class="token keyword">if</span> self<span class="token punctuation">.</span>return_intermediate<span class="token punctuation">:</span>
   intermediate<span class="token punctuation">.</span>append<span class="token punctuation">(</span>output<span class="token punctuation">)</span>
   intermediate_reference_points<span class="token punctuation">.</span>append<span class="token punctuation">(</span>reference_points<span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<ul>
<li>然后将层级的 bev_embedding特征以及参考点通过 for loop 的形式，一次计算每个 Decoder 层的分类和回归结果：</li>
</ul>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">bev_embed<span class="token punctuation">,</span> hs<span class="token punctuation">,</span> init_reference<span class="token punctuation">,</span> inter_references <span class="token operator">=</span> outputs
hs <span class="token operator">=</span> hs<span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>  <span class="token comment"># (decoder_level, bs, 900, 256)</span>
outputs_classes <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
outputs_coords <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> lvl <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>hs<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
   <span class="token keyword">if</span> lvl <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
      reference <span class="token operator">=</span> init_reference
   <span class="token keyword">else</span><span class="token punctuation">:</span>
      reference <span class="token operator">=</span> inter_references<span class="token punctuation">[</span>lvl <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">]</span>
   reference <span class="token operator">=</span> inverse_sigmoid<span class="token punctuation">(</span>reference<span class="token punctuation">)</span>
   outputs_class <span class="token operator">=</span> self<span class="token punctuation">.</span>cls_branches<span class="token punctuation">[</span>lvl<span class="token punctuation">]</span><span class="token punctuation">(</span>hs<span class="token punctuation">[</span>lvl<span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># (bs, 900, num_classes)</span>
   tmp <span class="token operator">=</span> self<span class="token punctuation">.</span>reg_branches<span class="token punctuation">[</span>lvl<span class="token punctuation">]</span><span class="token punctuation">(</span>hs<span class="token punctuation">[</span>lvl<span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># (bs, 900, 10)</span>
   <span class="token keyword">assert</span> reference<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token number">3</span>
   tmp<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">+=</span> reference<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span>  <span class="token comment"># (x, y)</span>
   tmp<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">=</span> tmp<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span>
   tmp<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">:</span><span class="token number">5</span><span class="token punctuation">]</span> <span class="token operator">+=</span> reference<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">:</span><span class="token number">3</span><span class="token punctuation">]</span>
   tmp<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">:</span><span class="token number">5</span><span class="token punctuation">]</span> <span class="token operator">=</span> tmp<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">:</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span>
   tmp<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">:</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">(</span>tmp<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">:</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token punctuation">(</span>self<span class="token punctuation">.</span>pc_range<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span> <span class="token operator">-</span> self<span class="token punctuation">.</span>pc_range<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>pc_range<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
   tmp<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">(</span>tmp<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token punctuation">(</span>self<span class="token punctuation">.</span>pc_range<span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">]</span> <span class="token operator">-</span> self<span class="token punctuation">.</span>pc_range<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>pc_range<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
   tmp<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">:</span><span class="token number">5</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">(</span>tmp<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">:</span><span class="token number">5</span><span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token punctuation">(</span>self<span class="token punctuation">.</span>pc_range<span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">]</span> <span class="token operator">-</span> self<span class="token punctuation">.</span>pc_range<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>pc_range<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

   outputs_coord <span class="token operator">=</span> tmp
   outputs_classes<span class="token punctuation">.</span>append<span class="token punctuation">(</span>outputs_class<span class="token punctuation">)</span>
   outputs_coords<span class="token punctuation">.</span>append<span class="token punctuation">(</span>outputs_coord<span class="token punctuation">)</span> 
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<ul>
<li>分类分支的网络结构：</li>
</ul>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">Sequential<span class="token punctuation">(</span>
<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span> Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span> LayerNorm<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> eps<span class="token operator">=</span><span class="token number">1e-05</span><span class="token punctuation">,</span> elementwise_affine<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span> ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">:</span> Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">:</span> LayerNorm<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> eps<span class="token operator">=</span><span class="token number">1e-05</span><span class="token punctuation">,</span> elementwise_affine<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">:</span> ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">:</span> Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<ul>
<li>回归分支的网络结构<pre class="line-numbers language-python" data-language="python"><code class="language-python">Sequential<span class="token punctuation">(</span>
<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span> Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span> ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span> Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">:</span> ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">:</span> Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
</ul>
</li>
</ul>
<h2 id="正负样本的定义"><a href="#正负样本的定义" class="headerlink" title="正负样本的定义"></a>正负样本的定义</h2><p>正负样本的定义用到的就是匈牙利匹配算法，分类损失和类似回归损失的总损失和最小；</p>
<ul>
<li><p>分类损失的计算代码如下：</p>
 <pre class="line-numbers language-python" data-language="python"><code class="language-python">cls_pred <span class="token operator">=</span> cls_pred<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># calculate the neg_cost and pos_cost by focal loss.</span>
neg_cost <span class="token operator">=</span> <span class="token operator">-</span><span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> cls_pred <span class="token operator">+</span> self<span class="token punctuation">.</span>eps<span class="token punctuation">)</span><span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> self<span class="token punctuation">.</span>alpha<span class="token punctuation">)</span> <span class="token operator">*</span> cls_pred<span class="token punctuation">.</span><span class="token builtin">pow</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>gamma<span class="token punctuation">)</span>
pos_cost <span class="token operator">=</span> <span class="token operator">-</span><span class="token punctuation">(</span>cls_pred <span class="token operator">+</span> self<span class="token punctuation">.</span>eps<span class="token punctuation">)</span><span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>alpha <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> cls_pred<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">pow</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>gamma<span class="token punctuation">)</span>
cls_cost <span class="token operator">=</span> pos_cost<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> gt_labels<span class="token punctuation">]</span> <span class="token operator">-</span> neg_cost<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> gt_labels<span class="token punctuation">]</span>
cls_cost <span class="token operator">=</span> cls_cost <span class="token operator">*</span> self<span class="token punctuation">.</span>weight<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
</li>
<li><p>类回归损失的计算代码如下：</p>
<ul>
<li>这里介绍一下，gt_box 的表示方式，gt_box 的维度是九维的，分别是 [xc，yc，zc，w，l，h，rot，vx，vy]；而预测结果框的维度是十维的，所以要对 gt_box 的维度进行转换，转换为的维度表示为 [xc，yc，w，l，cz，h，rot.sin()，rot.cos()，vx，vy]</li>
<li>对应代码如下：</li>
</ul>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">cx <span class="token operator">=</span> bboxes<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">:</span><span class="token number">1</span><span class="token punctuation">]</span>
cy <span class="token operator">=</span> bboxes<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span>
cz <span class="token operator">=</span> bboxes<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">:</span><span class="token number">3</span><span class="token punctuation">]</span>
w <span class="token operator">=</span> bboxes<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">:</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token punctuation">)</span>
l <span class="token operator">=</span> bboxes<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">:</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token punctuation">)</span>
h <span class="token operator">=</span> bboxes<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">:</span><span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token punctuation">)</span>
rot <span class="token operator">=</span> bboxes<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">:</span><span class="token number">7</span><span class="token punctuation">]</span>
vx <span class="token operator">=</span> bboxes<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">:</span><span class="token number">8</span><span class="token punctuation">]</span> 
vy <span class="token operator">=</span> bboxes<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">:</span><span class="token number">9</span><span class="token punctuation">]</span>
normalized_bboxes <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>cx<span class="token punctuation">,</span> cy<span class="token punctuation">,</span> w<span class="token punctuation">,</span> l<span class="token punctuation">,</span> cz<span class="token punctuation">,</span> h<span class="token punctuation">,</span> rot<span class="token punctuation">.</span>sin<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> rot<span class="token punctuation">.</span>cos<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> vx<span class="token punctuation">,</span> vy<span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li><p>计算类回归损失（L1 Loss）</p>
<ul>
<li>这里有一点需要注意的是，在正负样本定义中计算 L1 Loss 的时候，只对前预测框和真值框的前 8 维计算损失：<pre class="line-numbers language-python" data-language="python"><code class="language-python">self<span class="token punctuation">.</span>reg_cost<span class="token punctuation">(</span>bbox_pred<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">,</span> normalized_gt_bboxes<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li>
</ul>
</li>
</ul>
<h2 id="损失的计算"><a href="#损失的计算" class="headerlink" title="损失的计算"></a>损失的计算</h2><p>损失的计算就是分类损失以及 L1 Loss，这里的 L1 Loss 就是对真值框和预测框的10个维度计算 L1 Loss了，计算出来损失，反向传播更新模型的参数。</p>

                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/about" rel="external nofollow noreferrer">oceanechy</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="http://oceanechy.github.io/2023/11/29/bevformer-learning/">http://oceanechy.github.io/2023/11/29/bevformer-learning/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/about" target="_blank">oceanechy</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/bev/">
                                    <span class="chip bg-color">bev</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
                <div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">你的赏识是我前进的动力</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/medias/reward/wechat.png" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>

            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/2023/11/29/weakly-supervised-det/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/10.jpg" class="responsive-img" alt="弱监督下的BEV检测和占据预测(部分汇总)">
                        
                        <span class="card-title">弱监督下的BEV检测和占据预测(部分汇总)</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2023-11-29
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/DL/" class="post-category">
                                    DL
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/bev/">
                        <span class="chip bg-color">bev</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2023/11/28/bev-time-fusion/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/10.jpg" class="responsive-img" alt="BEV感知中的时序融合方法（部分待更新）">
                        
                        <span class="card-title">BEV感知中的时序融合方法（部分待更新）</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2023-11-28
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/DL/" class="post-category">
                                    DL
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/bev/">
                        <span class="chip bg-color">bev</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>


  <!-- 是否加载使用自带的 prismjs. -->
  <script type="text/javascript" src="/libs/prism/prism.min.js"></script>


<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('2'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/libs/aplayer/APlayer.min.js"></script>
<script src="/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 0px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2019-2024</span>
            
            <a href="/about" target="_blank">oceanechy</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">212.4k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/oceanechy" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:1945942166@qq.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>







    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=1945942166" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 1945942166" data-position="top" data-delay="50">
        <i class="fab fa-qq"></i>
    </a>





    <a href="https://www.zhihu.com/people/xiao-hai-38-6-81" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/xiao-hai-38-6-81" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    

    
    
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
     
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/libs/others/star.js"><\/script>');
            }
        </script>
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

</body>

</html>
